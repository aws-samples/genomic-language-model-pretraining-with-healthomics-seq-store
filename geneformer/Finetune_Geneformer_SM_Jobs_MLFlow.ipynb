{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dae519-ea14-40a6-9656-c8239a8efa72",
   "metadata": {},
   "source": [
    "# Fine Tune and Benchmark Geneformer (Single cell RNA-Seq foundation model) For Cell Type/Cell State Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd26c05-794e-4326-8c63-9d86a10bf105",
   "metadata": {},
   "source": [
    "# 0. Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1580651d-bda4-413c-89aa-eda4582f785a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --disable-pip-version-check -q -U 'boto3==1.35.16' 'sagemaker==2.231.0' 'mlflow==2.13.2' 'sagemaker-mlflow==0.1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d286ce9f-cdab-4f76-92e5-455f12f1ed56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "from sagemaker.processing import FrameworkProcessor, ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import (\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    "    HyperbandStrategyConfig,\n",
    "    StrategyConfig\n",
    ")\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d416c2b-8143-49a5-9f5c-a657e665a111",
   "metadata": {},
   "source": [
    "# 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b81cf-898e-4ef5-98db-f6338300906f",
   "metadata": {},
   "source": [
    "## 1.1 Create Some Necessary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f05feca-3c80-40c3-bafd-6d8cbd0548a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed SageMaker role is arn:aws:iam::851725420776:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "s3_boto_client = boto_session.client(\"s3\")\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02069c8-c62f-4e24-9ace-20f9f574c51e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Specify S3 Bucket and Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1485a4c7-2a5d-499b-b58e-b625316b858f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 path is sagemaker-us-west-2-851725420776/scrnaseq-fm-finetune\n"
     ]
    }
   ],
   "source": [
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"scrnaseq-fm-finetune\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c0e2e-8fc7-45da-a3af-0caead6268d7",
   "metadata": {},
   "source": [
    "# 2. Data Preparation with Amazon SageMaker Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93454500",
   "metadata": {},
   "source": [
    "Here we download an example 10x scRNA-Seq dataset, and add cell type annotation using marker gene expression as the ground truth for our classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240dc80-5ddf-4044-bc71-6e17f3f9c066",
   "metadata": {},
   "source": [
    "## 2.1. Define parameters of the SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9a0c69f-1221-4411-a3df-607569526ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing and splitting scRNASeq dataset and saving adata sc-preprocess-hao2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sc-preprocess-hao2021-2024-09-25-20-56-41-979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............\u001b[34mInstalling requirements\u001b[0m\n",
      "\u001b[34mCollecting anndata>=0.9 (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 1))\n",
      "  Downloading anndata-0.9.2-py3-none-any.whl.metadata (6.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting scanpy>=1.9 (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading scanpy-1.9.8-py3-none-any.whl.metadata (6.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting tdigest>=0.5.2 (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 3))\n",
      "  Downloading tdigest-0.5.2.2-py3-none-any.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.65 (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 4))\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas==1.1.3 in /miniconda3/lib/python3.8/site-packages (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 5)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting igraph (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 6))\n",
      "  Downloading igraph-0.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting leidenalg (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 7))\n",
      "  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.3->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 5)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.3->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.3->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 5)) (1.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>1.4 in /miniconda3/lib/python3.8/site-packages (from anndata>=0.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mCollecting h5py>=3 (from anndata>=0.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 1))\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting natsort (from anndata>=0.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 1))\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20 (from anndata>=0.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 1))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting get-annotations (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading get_annotations-0.1.2-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /miniconda3/lib/python3.8/site-packages (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2)) (1.4.2)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=3.6 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting networkx>=2.3 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting numba>=0.41.0 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting patsy (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.24 in /miniconda3/lib/python3.8/site-packages (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2)) (1.2.1)\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.13.0 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting session-info (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting statsmodels>=0.10.0rc2 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting umap-learn>=0.3.10 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting accumulation-tree (from tdigest>=0.5.2->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 3))\n",
      "  Downloading accumulation_tree-0.6.2.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pyudorandom (from tdigest>=0.5.2->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 3))\n",
      "  Downloading pyudorandom-1.0.0.tar.gz (1.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting texttable>=1.6.2 (from igraph->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 6))\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting contourpy>=1.0.1 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2)) (10.4.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.3.1 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=3.2.0 (from matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.41.0->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata (from numba>=0.41.0->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.3->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 5)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2)) (3.5.0)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of seaborn to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.13.0 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading seaborn-0.13.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting scanpy>=1.9 (from -r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading scanpy-1.9.7-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading scanpy-1.9.6-py3-none-any.whl.metadata (6.0 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is still looking at multiple versions of seaborn to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting seaborn!=0.13.0 (from scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting pynndescent>=0.5 (from umap-learn>=0.3.10->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting stdlib_list (from session-info->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib>=3.6->scanpy>=1.9->-r /opt/ml/processing/input/requirements/processing_requirements.txt (line 2))\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading anndata-0.9.2-py3-none-any.whl (104 kB)\u001b[0m\n",
      "\u001b[34mDownloading scanpy-1.9.6-py3-none-any.whl (2.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 60.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\u001b[0m\n",
      "\u001b[34mDownloading tdigest-0.5.2.2-py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading igraph-0.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 115.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 96.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\u001b[0m\n",
      "\u001b[34m   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 121.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 117.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 114.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 107.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.1-py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mDownloading statsmodels-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 129.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34mDownloading get_annotations-0.1.2-py3-none-any.whl (4.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\u001b[0m\n",
      "\u001b[34mDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 135.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mDownloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 85.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 MB 152.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\u001b[0m\n",
      "\u001b[34mDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mDownloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: accumulation-tree, pyudorandom, session-info\n",
      "  Building wheel for accumulation-tree (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for accumulation-tree (setup.py): finished with status 'done'\n",
      "  Created wheel for accumulation-tree: filename=accumulation_tree-0.6.2-cp38-cp38-linux_x86_64.whl size=91196 sha256=d5ed6a162dc6f525333b53887ff8cf2393ad74d1270dd3ba38f5f88990bcf362\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/39/d2/c9a954f11bc1b2f95258a48cbd19b0767fe7d3bb061df95a5f\n",
      "  Building wheel for pyudorandom (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyudorandom (setup.py): finished with status 'done'\n",
      "  Created wheel for pyudorandom: filename=pyudorandom-1.0.0-py3-none-any.whl size=2190 sha256=a0391c4a583807dfbcaf8d93fd0e72bde4d70948c97f9a3f8d865c59039814b9\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/6f/f6/c041bdb344311e31ea28717a6b0ae6106f951f8470329c2cb6\n",
      "  Building wheel for session-info (setup.py): started\n",
      "  Building wheel for session-info (setup.py): finished with status 'done'\n",
      "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=774470a7d8dc64dbdd9ecb788ad868a0c85376e2ba165f949cdfa1f4a6cb8b37\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/1b/4d/111d73980c5c6a8e5e5905a19eccc34296cb359cac54c6c5b9\u001b[0m\n",
      "\u001b[34mSuccessfully built accumulation-tree pyudorandom session-info\u001b[0m\n",
      "\u001b[34mInstalling collected packages: texttable, pyudorandom, accumulation-tree, zipp, tqdm, tdigest, stdlib_list, pyparsing, patsy, packaging, networkx, natsort, llvmlite, kiwisolver, igraph, h5py, get-annotations, fonttools, cycler, contourpy, session-info, leidenalg, importlib-resources, importlib-metadata, statsmodels, numba, matplotlib, anndata, seaborn, pynndescent, umap-learn, scanpy\u001b[0m\n",
      "\u001b[34mSuccessfully installed accumulation-tree-0.6.2 anndata-0.9.2 contourpy-1.1.1 cycler-0.12.1 fonttools-4.54.1 get-annotations-0.1.2 h5py-3.11.0 igraph-0.11.6 importlib-metadata-8.5.0 importlib-resources-6.4.5 kiwisolver-1.4.7 leidenalg-0.10.2 llvmlite-0.41.1 matplotlib-3.7.5 natsort-8.4.0 networkx-3.1 numba-0.58.1 packaging-24.1 patsy-0.5.6 pynndescent-0.5.13 pyparsing-3.1.4 pyudorandom-1.0.0 scanpy-1.9.6 seaborn-0.12.2 session-info-1.0.0 statsmodels-0.14.1 stdlib_list-0.10.0 tdigest-0.5.2.2 texttable-1.7.0 tqdm-4.66.5 umap-learn-0.5.6 zipp-3.20.2\u001b[0m\n",
      "\u001b[34mNamespace(group_key='orig.ident', label_colname='cell_type', local_path='/opt/ml/processing', split_by_group=False, train_size=0.8)\u001b[0m\n",
      "\u001b[34mDownloading data from https://datasets.cellxgene.cziscience.com/55c120dc-6a20-4caf-9513-f5970b24b1be.h5ad\u001b[0m\n",
      "\u001b[34m2024-09-25 20:59:52 URL:https://datasets.cellxgene.cziscience.com/55c120dc-6a20-4caf-9513-f5970b24b1be.h5ad [2665740091/2665740091] -> \"/opt/ml/processing/h5ad_data/hao2021.h5ad\" [1]\u001b[0m\n",
      "\u001b[34muse RAW COUNTS to calculate hvg\u001b[0m\n",
      "\u001b[34mput back raw counts to adata.X\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processing_job_name = \"sc-preprocess-hao2021\"\n",
    "print(\"Preparing and splitting scRNASeq dataset and saving adata\", processing_job_name)\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=sagemaker_execution_role,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    instance_count=1,\n",
    "    base_job_name=processing_job_name\n",
    ")\n",
    "\n",
    "# Run processor \n",
    "sklearn_processor.run(\n",
    "    inputs=[\n",
    "            ProcessingInput(\n",
    "                input_name=\"requirements\",\n",
    "                source=\"scripts/processing/processing_requirements.txt\", #\"requirements/\",\n",
    "                destination=\"/opt/ml/processing/input/requirements/\",\n",
    "            )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"class_labels\",\n",
    "            source=\"/opt/ml/processing/h5ad_data/class_labels\",\n",
    "            destination=os.path.join(\n",
    "                    \"s3://{}\".format(S3_BUCKET),\n",
    "                    S3_PREFIX,\n",
    "                    processing_job_name,\n",
    "                    \"class_labels\",\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/h5ad_data/train\",\n",
    "            destination=os.path.join(\n",
    "                    \"s3://{}\".format(S3_BUCKET),\n",
    "                    S3_PREFIX,\n",
    "                    processing_job_name,\n",
    "                    \"train\",\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/h5ad_data/val\",\n",
    "            destination=os.path.join(\n",
    "                    \"s3://{}\".format(S3_BUCKET),\n",
    "                    S3_PREFIX,\n",
    "                    processing_job_name,\n",
    "                    \"validation\",\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/h5ad_data/test\",\n",
    "            destination=os.path.join(\n",
    "                    \"s3://{}\".format(S3_BUCKET),\n",
    "                    S3_PREFIX,\n",
    "                    processing_job_name,\n",
    "                    \"test\",\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"scripts/processing/process_hao2021.py\",\n",
    "    arguments=[\"--train_size\", \"0.8\", \"--split_by_group\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff6287-19d9-43d3-a542-31a992efa10f",
   "metadata": {},
   "source": [
    "# 3. ML training with SageMaker Training Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfa8ac-fba2-4b16-ae75-c4cc0cd0375c",
   "metadata": {},
   "source": [
    "## 3.1. Using MLflow to track model training experiments\n",
    "Create an MLflow tracking server in SageMaker Studio. Copy the tracking server ARN below.\n",
    "\n",
    "Update the SageMaker service role to have the following policy to enable ML flow tracking:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",    \n",
    "    \"Statement\": [        \n",
    "        {            \n",
    "            \"Effect\": \"Allow\",            \n",
    "            \"Action\": [\n",
    "                \"sagemaker-mlflow:*\",\n",
    "                \"sagemaker:CreateMlflowTrackingServer\",\n",
    "                \"sagemaker:UpdateMlflowTrackingServer\",\n",
    "                \"sagemaker:DeleteMlflowTrackingServer\",\n",
    "                \"sagemaker:StartMlflowTrackingServer\",\n",
    "                \"sagemaker:StopMlflowTrackingServer\",\n",
    "                \"sagemaker:CreatePresignedMlflowTrackingServerUrl\"\n",
    "            ],            \n",
    "            \"Resource\": \"*\"        \n",
    "        }        \n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "65987244-4411-4f30-8763-cab6a8bc46bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracking_server_arn = \"arn:aws:sagemaker:us-west-2:851725420776:mlflow-tracking-server/scrnaseq-ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f6487-ce5e-4252-a11d-bda20093fe8d",
   "metadata": {},
   "source": [
    "## 3.2. Train a Logistic Regression model using normalized counts as the Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d39760",
   "metadata": {},
   "source": [
    "For comparing model performance, it is always good to have a simple baseline. We will use a simple logistic regression model, taking as input the normalized expression counts to predict cell type as the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2277e-0d91-4f3e-9bf3-d12c1c68ca47",
   "metadata": {},
   "source": [
    "### 3.2.1 Define and fit a SKLearn estimator, logging the run to an MLFlow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "628db0e1-e452-4cf6-99a3-f4944ef1ea43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating training-job with name: baseline-LR-2024-09-27-20-38-47-755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-27 20:38:48 Starting - Starting the training job...\n",
      "2024-09-27 20:39:12 Starting - Preparing the instances for training...\n",
      "2024-09-27 20:39:51 Downloading - Downloading the training image...\n",
      "2024-09-27 20:40:22 Training - Training image download completed. Training in progress....\u001b[34m2024-09-27 20:40:42,895 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-09-27 20:40:42,897 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:40:42,899 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:40:42,913 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-09-27 20:40:43,095 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting scanpy==1.9.8 (from -r requirements.txt (line 1))\n",
      "  Downloading scanpy-1.9.8-py3-none-any.whl.metadata (6.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib==3.7.5 (from -r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow==2.13.2 (from -r requirements.txt (line 3))\n",
      "  Downloading mlflow-2.13.2-py3-none-any.whl.metadata (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-mlflow==0.1.0 (from -r requirements.txt (line 4))\n",
      "  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting anndata>=0.7.4 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading anndata-0.9.2-py3-none-any.whl.metadata (6.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting get-annotations (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading get_annotations-0.1.2-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting h5py>=3 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /miniconda3/lib/python3.8/site-packages (from scanpy==1.9.8->-r requirements.txt (line 1)) (1.4.2)\u001b[0m\n",
      "\u001b[34mCollecting natsort (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting networkx>=2.3 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting numba>=0.41.0 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /miniconda3/lib/python3.8/site-packages (from scanpy==1.9.8->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mCollecting packaging (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas!=2.1.2,>=1.1.1 in /miniconda3/lib/python3.8/site-packages (from scanpy==1.9.8->-r requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting patsy (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.24 in /miniconda3/lib/python3.8/site-packages (from scanpy==1.9.8->-r requirements.txt (line 1)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.4 in /miniconda3/lib/python3.8/site-packages (from scanpy==1.9.8->-r requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.13.0 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting session-info (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting statsmodels>=0.10.0rc2 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\u001b[0m\n",
      "\u001b[34mCollecting umap-learn>=0.3.10 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting contourpy>=1.0.1 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 2)) (10.4.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.3.1 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=3.2.0 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask<4 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (1.1.1)\u001b[0m\n",
      "\u001b[34mCollecting alembic!=1.10.0,<2 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6,>=5.0.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting cloudpickle<4 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker<8,>=4.0.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints<1 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython<4,>=3.1.9 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphene<4 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown<4,>=3.3 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-api<3,>=1.0.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-sdk<3,>=1.0.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5,>=3.12.0 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow<16,>=4.0.0 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (14.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz<2025 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (2024.1)\u001b[0m\n",
      "\u001b[34mCollecting pyyaml<7,>=5.1 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser<2 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.17.3 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (2.32.3)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy<3,>=1.4.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading SQLAlchemy-2.0.35-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse<1,>=0.4.0 (from mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2<4,>=2.11 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (3.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gunicorn<23 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.13.2->-r requirements.txt (line 3)) (20.0.4)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.34 (from sagemaker-mlflow==0.1.0->-r requirements.txt (line 4))\n",
      "  Downloading boto3-1.35.29-py3-none-any.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting Mako (from alembic!=1.10.0,<2->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions>=4 (from alembic!=1.10.0,<2->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.36.0,>=1.35.29 (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 4))\n",
      "  Downloading botocore-1.35.29-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 4))\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3>=1.26.0 in /miniconda3/lib/python3.8/site-packages (from docker<8,>=4.0.0->mlflow==2.13.2->-r requirements.txt (line 3)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=0.15 in /miniconda3/lib/python3.8/site-packages (from Flask<4->mlflow==2.13.2->-r requirements.txt (line 3)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=0.24 in /miniconda3/lib/python3.8/site-packages (from Flask<4->mlflow==2.13.2->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting aniso8601<10,>=8 (from graphene<4->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=3.0 in /miniconda3/lib/python3.8/site-packages (from gunicorn<23->mlflow==2.13.2->-r requirements.txt (line 3)) (65.5.1)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5 (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /miniconda3/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow==2.13.2->-r requirements.txt (line 3)) (2.1.1)\u001b[0m\n",
      "\u001b[34mCollecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.41.0->scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.7.5->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2->-r requirements.txt (line 3)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2->-r requirements.txt (line 3)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2->-r requirements.txt (line 3)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->scanpy==1.9.8->-r requirements.txt (line 1)) (3.5.0)\u001b[0m\n",
      "\u001b[34mCollecting pandas!=2.1.2,>=1.1.1 (from scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dateutil>=2.7 (from matplotlib==3.7.5->-r requirements.txt (line 2))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting tzdata>=2022.1 (from pandas!=2.1.2,>=1.1.1->scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /miniconda3/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.13.2->-r requirements.txt (line 3)) (3.0.3)\u001b[0m\n",
      "\u001b[34mCollecting pynndescent>=0.5 (from umap-learn>=0.3.10->scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting stdlib_list (from session-info->scanpy==1.9.8->-r requirements.txt (line 1))\n",
      "  Downloading stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.2->-r requirements.txt (line 3))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading scanpy-1.9.8-py3-none-any.whl (2.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 59.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 136.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.13.2-py3-none-any.whl (25.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.0/25.0 MB 165.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mDownloading anndata-0.9.2-py3-none-any.whl (104 kB)\u001b[0m\n",
      "\u001b[34mDownloading boto3-1.35.29-py3-none-any.whl (139 kB)\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\u001b[0m\n",
      "\u001b[34mDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading docker-7.1.0-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34mDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 170.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\u001b[0m\n",
      "\u001b[34mDownloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 148.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mDownloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 127.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.7-py3-none-any.whl (106 kB)\u001b[0m\n",
      "\u001b[34mDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 146.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 124.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.1-py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 746.5/746.5 kB 99.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\u001b[0m\n",
      "\u001b[34mDownloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 158.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.35-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 154.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34mDownloading statsmodels-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 118.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34mDownloading get_annotations-0.1.2-py3-none-any.whl (4.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.35.29-py3-none-any.whl (12.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.6/12.6 MB 182.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\u001b[0m\n",
      "\u001b[34m   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 MB 135.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\u001b[0m\n",
      "\u001b[34mDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: session-info\n",
      "  Building wheel for session-info (setup.py): started\n",
      "  Building wheel for session-info (setup.py): finished with status 'done'\n",
      "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=cf804586efe72a036eda4ffe1aca75b754e47bf431115d2e5ff4618c612ca6ca\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/1b/4d/111d73980c5c6a8e5e5905a19eccc34296cb359cac54c6c5b9\u001b[0m\n",
      "\u001b[34mSuccessfully built session-info\u001b[0m\n",
      "\u001b[34mInstalling collected packages: aniso8601, zipp, wrapt, tzdata, typing-extensions, tqdm, stdlib_list, sqlparse, smmap, querystring-parser, pyyaml, python-dateutil, pyparsing, patsy, packaging, networkx, natsort, Mako, llvmlite, kiwisolver, h5py, graphql-core, get-annotations, fonttools, entrypoints, cycler, contourpy, cloudpickle, cachetools, sqlalchemy, session-info, pandas, importlib-resources, importlib-metadata, graphql-relay, gitdb, docker, deprecated, botocore, statsmodels, s3transfer, opentelemetry-api, numba, matplotlib, markdown, graphene, gitpython, anndata, alembic, seaborn, pynndescent, opentelemetry-semantic-conventions, boto3, umap-learn, opentelemetry-sdk, scanpy, mlflow, sagemaker-mlflow\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.85\n",
      "    Uninstalling botocore-1.31.85:\n",
      "      Successfully uninstalled botocore-1.31.85\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.7.0\n",
      "    Uninstalling s3transfer-0.7.0:\n",
      "      Successfully uninstalled s3transfer-0.7.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.57\n",
      "    Uninstalling boto3-1.28.57:\n",
      "      Successfully uninstalled boto3-1.28.57\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires boto3==1.28.57, but you have boto3 1.35.29 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires botocore<1.32.0,>=1.31.57, but you have botocore 1.35.29 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires pandas==1.1.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires python-dateutil==2.8.1, but you have python-dateutil 2.9.0.post0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.3.5 alembic-1.13.3 aniso8601-9.0.1 anndata-0.9.2 boto3-1.35.29 botocore-1.35.29 cachetools-5.5.0 cloudpickle-3.0.0 contourpy-1.1.1 cycler-0.12.1 deprecated-1.2.14 docker-7.1.0 entrypoints-0.4 fonttools-4.54.1 get-annotations-0.1.2 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 h5py-3.11.0 importlib-metadata-7.2.1 importlib-resources-6.4.5 kiwisolver-1.4.7 llvmlite-0.41.1 markdown-3.7 matplotlib-3.7.5 mlflow-2.13.2 natsort-8.4.0 networkx-3.1 numba-0.58.1 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 packaging-24.1 pandas-2.0.3 patsy-0.5.6 pynndescent-0.5.13 pyparsing-3.1.4 python-dateutil-2.9.0.post0 pyyaml-6.0.2 querystring-parser-1.2.4 s3transfer-0.10.2 sagemaker-mlflow-0.1.0 scanpy-1.9.8 seaborn-0.13.2 session-info-1.0.0 smmap-5.0.1 sqlalchemy-2.0.35 sqlparse-0.5.1 statsmodels-0.14.1 stdlib_list-0.10.0 tqdm-4.66.5 typing-extensions-4.12.2 tzdata-2024.2 umap-learn-0.5.6 wrapt-1.16.0 zipp-3.20.2\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,419 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,422 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,438 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,440 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,456 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,458 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,471 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"labels\": \"/opt/ml/input/data/labels\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"class_weight\": \"balanced\",\n",
      "        \"dataset_name\": \"pbmc3k\",\n",
      "        \"max_iter\": 1000,\n",
      "        \"penalty\": \"l2\",\n",
      "        \"solver\": \"saga\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"labels\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"baseline-LR-2024-09-27-20-38-47-755\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-851725420776/baseline-LR-2024-09-27-20-38-47-755/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"baseline_lr_train_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"baseline_lr_train_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"class_weight\":\"balanced\",\"dataset_name\":\"pbmc3k\",\"max_iter\":1000,\"penalty\":\"l2\",\"solver\":\"saga\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=baseline_lr_train_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"labels\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"labels\",\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=baseline_lr_train_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-851725420776/baseline-LR-2024-09-27-20-38-47-755/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"labels\":\"/opt/ml/input/data/labels\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"class_weight\":\"balanced\",\"dataset_name\":\"pbmc3k\",\"max_iter\":1000,\"penalty\":\"l2\",\"solver\":\"saga\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"labels\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"baseline-LR-2024-09-27-20-38-47-755\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-851725420776/baseline-LR-2024-09-27-20-38-47-755/source/sourcedir.tar.gz\",\"module_name\":\"baseline_lr_train_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"baseline_lr_train_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--class_weight\",\"balanced\",\"--dataset_name\",\"pbmc3k\",\"--max_iter\",\"1000\",\"--penalty\",\"l2\",\"--solver\",\"saga\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABELS=/opt/ml/input/data/labels\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_WEIGHT=balanced\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_NAME=pbmc3k\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_ITER=1000\u001b[0m\n",
      "\u001b[34mSM_HP_PENALTY=l2\u001b[0m\n",
      "\u001b[34mSM_HP_SOLVER=saga\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python baseline_lr_train_mlflow.py --class_weight balanced --dataset_name pbmc3k --max_iter 1000 --penalty l2 --solver saga\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,472 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-09-27 20:41:06,472 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mscRNASeq-baseline\u001b[0m\n",
      "\u001b[34mtrain dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mtest dir: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mtraining data shape: (2308, 2078)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\u001b[0m\n",
      "\n",
      "2024-09-27 20:42:23 Uploading - Uploading generated training model\u001b[34mtrain_time_per_sample= 0.03004313062753793\u001b[0m\n",
      "\u001b[34msaved model!\u001b[0m\n",
      "\u001b[34mtarget_name_id_dict: {'CD4-positive, alpha-beta T cell (2)': 0, 'B cell (1)': 1, 'CD4-positive, alpha-beta T cell (1)': 2, 'CD14-positive, monocyte': 3, 'natural killer cell': 4, 'CD8-positive, alpha-beta T cell': 5, 'FCGR3A-positive, monocyte': 6, 'dendritic cell': 7, 'megakaryocyte': 8, 'B cell (2)': 9}\u001b[0m\n",
      "\u001b[34mmetrics: {'eval_runtime': 0.0012645721435546875, 'eval_samples_per_second': 213510.95022624434, 'eval_accuracy': 0.8148148148148148, 'eval_class_averaged_accuracy': 0.7580102573508662, 'eval_macro_f1': 0.772846365192094, 'eval_global_f1': 0.8148148148148148, 'eval_class_weighted_f1': 0.8138327322875357}\u001b[0m\n",
      "\u001b[34m2024-09-27 20:42:19,666 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-09-27 20:42:35 Completed - Training job completed\n",
      "Training seconds: 179\n",
      "Billable seconds: 179\n"
     ]
    }
   ],
   "source": [
    "lr_job_name = f\"baseline-LR\"\n",
    "model_output_path = f\"s3://{S3_BUCKET}/{S3_PREFIX}/trained_models/\"\n",
    "experiment_name = \"scRNASeq-baseline\"\n",
    "# Uncomment for setting up MLflow exp\n",
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "dataset_name = \"pbmc3k\" #\"hao2021_pbmc\"\n",
    "processing_job_name = \"sc-preprocess\" # \"sc-preprocess-hao2021\"\n",
    "\n",
    "lr_estimator = SKLearn(\n",
    "    base_job_name=lr_job_name,\n",
    "    enable_sagemaker_metrics=True,\n",
    "    entry_point=\"baseline_lr_train_mlflow.py\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    hyperparameters={\n",
    "        'penalty': 'l2',\n",
    "        'class_weight': 'balanced',\n",
    "        'max_iter': 1000,\n",
    "        'solver': 'saga', #'lbfgs',\n",
    "        'dataset_name': dataset_name\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.4xlarge\",\n",
    "    output_path=model_output_path,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/training/lr/\",\n",
    "    environment={\n",
    "        \"MLFLOW_TRACKING_URI\": tracking_server_arn,\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": experiment.name,\n",
    "        #\"MLFLOW_PARENT_RUN_ID\": run.info.run_id,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "lr_estimator.fit(\n",
    "    {'train': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/train/{dataset_name}_train.h5ad\",\n",
    "     'validation': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/validation/{dataset_name}_val.h5ad\",\n",
    "    'test': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/test/{dataset_name}_test.h5ad\",\n",
    "    'labels': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/class_labels/{dataset_name}_celltype_labels.pkl\"},\n",
    "    #wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72246c15-cc82-4ac3-99aa-c979a18585ca",
   "metadata": {},
   "source": [
    "## 3.3. Fine tune Geneformer scRNA-Seq FM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578b5ce",
   "metadata": {},
   "source": [
    "As mentioned in the Introduction, Geneformer is a foundational transformer model pretrained on a large-scale corpus of single cell transcriptomes to enable context-aware predictions in settings with limited data in network biology.\n",
    "The pretrained model outputs dense vector embeddings of cells. We can fine tune it with a labeled dataset to perform cell type classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db79a32",
   "metadata": {},
   "source": [
    "### 3.3.1. Pre-requisite: Build a docker image using the docker file in `scripts/Dockerfile` and push to your ECR repo, copy the image uri below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "236114de-9e1b-4470-bd29-30acd3a09397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_img_uri = \"851725420776.dkr.ecr.us-west-2.amazonaws.com/geneformerft:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb9552-f315-4a62-933d-5e97b0130278",
   "metadata": {},
   "source": [
    "### 3.3.2 Define a Pytorch estimator with custom image, fit and track metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6b5fa355-c96a-4928-915a-dc15186d7410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating training-job with name: geneformer-ft-testmlflow-2024-09-26-22-12-42-887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-26 22:12:45 Starting - Starting the training job...\n",
      "2024-09-26 22:12:58 Starting - Preparing the instances for training...\n",
      "2024-09-26 22:13:39 Downloading - Downloading input data...\n",
      "2024-09-26 22:13:54 Downloading - Downloading the training image.......................................\n",
      "2024-09-26 22:20:37 Training - Training image download completed. Training in progress......\u001b[34m2024-09-26 22:21:22,505 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,506 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,546 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,547 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,581 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,582 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,592 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"labels\": \"/opt/ml/input/data/labels\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10,\n",
      "        \"freeze_layers\": 6,\n",
      "        \"geneformer_batch_size\": 20,\n",
      "        \"lr_schedule_fn\": \"linear\",\n",
      "        \"max_lr\": 5e-05,\n",
      "        \"model_name\": \"gf-12L-30M-i2048\",\n",
      "        \"num_gpus\": 1,\n",
      "        \"num_proc\": 16,\n",
      "        \"optimizer\": \"adamw\",\n",
      "        \"warmup_steps\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"labels\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"geneformer-ft-testmlflow-2024-09-26-22-12-42-887\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-851725420776/geneformer-ft-testmlflow-2024-09-26-22-12-42-887/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"ft_geneformer_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"ft_geneformer_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10,\"freeze_layers\":6,\"geneformer_batch_size\":20,\"lr_schedule_fn\":\"linear\",\"max_lr\":5e-05,\"model_name\":\"gf-12L-30M-i2048\",\"num_gpus\":1,\"num_proc\":16,\"optimizer\":\"adamw\",\"warmup_steps\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=ft_geneformer_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"labels\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"labels\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=ft_geneformer_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-851725420776/geneformer-ft-testmlflow-2024-09-26-22-12-42-887/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"labels\":\"/opt/ml/input/data/labels\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10,\"freeze_layers\":6,\"geneformer_batch_size\":20,\"lr_schedule_fn\":\"linear\",\"max_lr\":5e-05,\"model_name\":\"gf-12L-30M-i2048\",\"num_gpus\":1,\"num_proc\":16,\"optimizer\":\"adamw\",\"warmup_steps\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"labels\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"geneformer-ft-testmlflow-2024-09-26-22-12-42-887\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-851725420776/geneformer-ft-testmlflow-2024-09-26-22-12-42-887/source/sourcedir.tar.gz\",\"module_name\":\"ft_geneformer_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"ft_geneformer_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\",\"--freeze_layers\",\"6\",\"--geneformer_batch_size\",\"20\",\"--lr_schedule_fn\",\"linear\",\"--max_lr\",\"5e-05\",\"--model_name\",\"gf-12L-30M-i2048\",\"--num_gpus\",\"1\",\"--num_proc\",\"16\",\"--optimizer\",\"adamw\",\"--warmup_steps\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABELS=/opt/ml/input/data/labels\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FREEZE_LAYERS=6\u001b[0m\n",
      "\u001b[34mSM_HP_GENEFORMER_BATCH_SIZE=20\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULE_FN=linear\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LR=5e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=gf-12L-30M-i2048\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_PROC=16\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adamw\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/geneformer/bin:/usr/lib/python312.zip:/usr/lib/python3.12:/usr/lib/python3.12/lib-dynload:/geneformer/lib/python3.12/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/geneformer/bin/python3 ft_geneformer_mlflow.py --epochs 10 --freeze_layers 6 --geneformer_batch_size 20 --lr_schedule_fn linear --max_lr 5e-05 --model_name gf-12L-30M-i2048 --num_gpus 1 --num_proc 16 --optimizer adamw --warmup_steps 200\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,592 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-09-26 22:21:22,592 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mlflow==2.13.2 in /geneformer/lib/python3.12/site-packages (2.13.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker-mlflow==0.1.0 in /geneformer/lib/python3.12/site-packages (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask<4 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: alembic!=1.10.0,<2 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.13.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<6,>=5.0.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (5.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle<4 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docker<8,>=4.0.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (7.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: entrypoints<1 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gitpython<4,>=3.1.9 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.1.43)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: graphene<4 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (6.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown<4,>=3.3 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib<4 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opentelemetry-api<3,>=1.0.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging<25 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas<3 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5,>=3.12.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow<16,>=4.0.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (15.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz<2025 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (2024.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml<7,>=5.1 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: querystring-parser<2 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.17.3 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<2 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (1.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (2.0.35)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sqlparse<1,>=0.4.0 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (0.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2<4,>=2.11 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gunicorn<23 in /geneformer/lib/python3.12/site-packages (from mlflow==2.13.2) (22.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.34 in /geneformer/lib/python3.12/site-packages (from sagemaker-mlflow==0.1.0) (1.35.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Mako in /geneformer/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.2) (1.3.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4 in /geneformer/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.2) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.36.0,>=1.35.16 in /geneformer/lib/python3.12/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (1.35.23)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /geneformer/lib/python3.12/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /geneformer/lib/python3.12/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (0.10.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3>=1.26.0 in /geneformer/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow==2.13.2) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=3.0.0 in /geneformer/lib/python3.12/site-packages (from Flask<4->mlflow==2.13.2) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=2.1.2 in /geneformer/lib/python3.12/site-packages (from Flask<4->mlflow==2.13.2) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: blinker>=1.6.2 in /geneformer/lib/python3.12/site-packages (from Flask<4->mlflow==2.13.2) (1.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gitdb<5,>=4.0.1 in /geneformer/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow==2.13.2) (4.0.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: graphql-core<3.3,>=3.1 in /geneformer/lib/python3.12/site-packages (from graphene<4->mlflow==2.13.2) (3.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: graphql-relay<3.3,>=3.1 in /geneformer/lib/python3.12/site-packages (from graphene<4->mlflow==2.13.2) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aniso8601<10,>=8 in /geneformer/lib/python3.12/site-packages (from graphene<4->mlflow==2.13.2) (9.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /geneformer/lib/python3.12/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.2) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /geneformer/lib/python3.12/site-packages (from Jinja2<4,>=2.11->mlflow==2.13.2) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (4.53.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (1.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (10.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /geneformer/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.13.2) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: deprecated>=1.2.6 in /geneformer/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.2) (1.2.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /geneformer/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.2) (0.48b0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /geneformer/lib/python3.12/site-packages (from pandas<3->mlflow==2.13.2) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /geneformer/lib/python3.12/site-packages (from querystring-parser<2->mlflow==2.13.2) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /geneformer/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /geneformer/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /geneformer/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (2024.8.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.2.0 in /geneformer/lib/python3.12/site-packages (from scikit-learn<2->mlflow==2.13.2) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /geneformer/lib/python3.12/site-packages (from scikit-learn<2->mlflow==2.13.2) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /geneformer/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.13.2) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt<2,>=1.10 in /geneformer/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.2) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smmap<6,>=3.0.1 in /geneformer/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.2) (5.0.1)\u001b[0m\n",
      "\u001b[34mInstalling mlflow dependencies\u001b[0m\n",
      "\u001b[34mscRNASeq-fm\u001b[0m\n",
      "\u001b[34mNamespace(num_gpus=1, num_proc=16, model_name='gf-12L-30M-i2048', max_lr=5e-05, freeze_layers=6, geneformer_batch_size=20, lr_schedule_fn='linear', warmup_steps=200, epochs=10, optimizer='adamw', label_colname='label', output_data_dir='/opt/ml/output/data', model_dir='/opt/ml/model', train='/opt/ml/input/data/train', test='/opt/ml/input/data/test', class_label='/opt/ml/input/data/labels')\u001b[0m\n",
      "\u001b[34m2048\u001b[0m\n",
      "\u001b[34mFalse\u001b[0m\n",
      "\u001b[34mTokenizing /opt/ml/input/data/train/pbmc3k_train.h5ad\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015 20%|██        | 1/5 [00:08<00:35,  9.00s/it]#015 40%|████      | 2/5 [00:18<00:27,  9.01s/it]#015 60%|██████    | 3/5 [00:27<00:18,  9.03s/it]#015 80%|████████  | 4/5 [00:36<00:09,  9.05s/it]#015100%|██████████| 5/5 [00:41<00:00,  7.70s/it]#015100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/anndata/_core/anndata.py:796: ImplicitModificationWarning: Trying to modify index of attribute `.obs` of view, initializing view as actual.\n",
      "  getattr(self, attr).index = value\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/geneformer/tokenizer.py:473: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/geneformer/tokenizer.py:476: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/pbmc3k_train.h5ad has no column attribute 'filter_pass'; tokenizing all cells.\u001b[0m\n",
      "\u001b[34mCreating dataset.\u001b[0m\n",
      "\u001b[34mTokenizing /opt/ml/input/data/test/pbmc3k_test.h5ad\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:05<00:00,  5.02s/it]#015100%|██████████| 1/1 [00:05<00:00,  5.02s/it]\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/anndata/_core/anndata.py:796: ImplicitModificationWarning: Trying to modify index of attribute `.obs` of view, initializing view as actual.\n",
      "  getattr(self, attr).index = value\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/geneformer/tokenizer.py:473: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/geneformer/tokenizer.py:476: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/test/pbmc3k_test.h5ad has no column attribute 'filter_pass'; tokenizing all cells.\u001b[0m\n",
      "\u001b[34mCreating dataset.\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /Geneformer/gf-12L-30M-i2048 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m{'CD4-positive, alpha-beta T cell (2)': 0, 'B cell (1)': 1, 'CD4-positive, alpha-beta T cell (1)': 2, 'CD14-positive, monocyte': 3, 'natural killer cell': 4, 'CD8-positive, alpha-beta T cell': 5, 'FCGR3A-positive, monocyte': 6, 'dendritic cell': 7, 'megakaryocyte': 8, 'B cell (2)': 9}\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /Geneformer/gf-12L-30M-i2048 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1160 [00:00<?, ?it/s]/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'loss': 2.3484, 'grad_norm': 4.370233058929443, 'learning_rate': 3e-06, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2579, 'grad_norm': 4.919787883758545, 'learning_rate': 6e-06, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2657, 'grad_norm': 5.004633903503418, 'learning_rate': 9e-06, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1452, 'grad_norm': 5.763916015625, 'learning_rate': 1.2e-05, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1466, 'grad_norm': 4.6127238273620605, 'learning_rate': 1.5e-05, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9923, 'grad_norm': 2.960000991821289, 'learning_rate': 1.8e-05, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 1/1160 [00:05<1:53:10,  5.86s/it]#015  0%|          | 2/1160 [00:08<1:21:20,  4.21s/it]#015  0%|          | 3/1160 [00:11<1:04:31,  3.35s/it]#015  0%|          | 4/1160 [00:13<55:35,  2.89s/it]  #015  0%|          | 5/1160 [00:15<48:04,  2.50s/it]#015  1%|          | 6/1160 [00:16<42:35,  2.21s/it]#015  1%|          | 7/1160 [00:18<38:29,  2.00s/it]#015  1%|          | 8/1160 [00:19<35:27,  1.85s/it]#015  1%|          | 9/1160 [00:21<32:29,  1.69s/it]#015  1%|          | 10/1160 [00:22<30:36,  1.60s/it]#015  1%|          | 11/1160 [00:24<28:57,  1.51s/it]#015  1%|          | 12/1160 [00:25<27:32,  1.44s/it]#015                                                 #015#015  1%|          | 12/1160 [00:25<27:32,  1.44s/it]#015  1%|          | 13/1160 [00:26<26:20,  1.38s/it]#015  1%|          | 14/1160 [00:27<25:32,  1.34s/it]#015  1%|▏         | 15/1160 [00:28<24:36,  1.29s/it]#015  1%|▏         | 16/1160 [00:30<23:40,  1.24s/it]#015  1%|▏         | 17/1160 [00:31<22:47,  1.20s/it]#015  2%|▏         | 18/1160 [00:32<22:11,  1.17s/it]#015  2%|▏         | 19/1160 [00:33<21:36,  1.14s/it]#015  2%|▏         | 20/1160 [00:34<20:48,  1.09s/it]#015  2%|▏         | 21/1160 [00:35<19:57,  1.05s/it]#015  2%|▏         | 22/1160 [00:36<19:15,  1.02s/it]#015  2%|▏         | 23/1160 [00:37<18:20,  1.03it/s]#015  2%|▏         | 24/1160 [00:37<17:25,  1.09it/s]#015                                                 #015#015  2%|▏         | 24/1160 [00:37<17:25,  1.09it/s]#015  2%|▏         | 25/1160 [00:38<16:22,  1.16it/s]#015  2%|▏         | 26/1160 [00:39<15:11,  1.24it/s]#015  2%|▏         | 27/1160 [00:39<13:37,  1.39it/s]#015  2%|▏         | 28/1160 [00:40<11:55,  1.58it/s]#015  2%|▎         | 29/1160 [00:45<40:13,  2.13s/it]#015  3%|▎         | 30/1160 [00:48<44:49,  2.38s/it]#015  3%|▎         | 31/1160 [00:51<44:08,  2.35s/it]#015  3%|▎         | 32/1160 [00:53<41:45,  2.22s/it]#015  3%|▎         | 33/1160 [00:54<38:32,  2.05s/it]#015  3%|▎         | 34/1160 [00:56<35:54,  1.91s/it]#015  3%|▎         | 35/1160 [00:57<33:58,  1.81s/it]#015  3%|▎         | 36/1160 [00:59<31:55,  1.70s/it]#015                                                 #015#015  3%|▎         | 36/1160 [00:59<31:55,  1.70s/it]#015  3%|▎         | 37/1160 [01:00<30:07,  1.61s/it]#015  3%|▎         | 38/1160 [01:02<28:51,  1.54s/it]#015  3%|▎         | 39/1160 [01:03<27:21,  1.46s/it]#015  3%|▎         | 40/1160 [01:04<26:09,  1.40s/it]#015  4%|▎         | 41/1160 [01:05<25:09,  1.35s/it]#015  4%|▎         | 42/1160 [01:07<24:06,  1.29s/it]#015  4%|▎         | 43/1160 [01:08<23:02,  1.24s/it]#015  4%|▍         | 44/1160 [01:09<22:15,  1.20s/it]#015  4%|▍         | 45/1160 [01:10<21:42,  1.17s/it]#015  4%|▍         | 46/1160 [01:11<21:05,  1.14s/it]#015  4%|▍         | 47/1160 [01:12<20:23,  1.10s/it]#015  4%|▍         | 48/1160 [01:13<19:40,  1.06s/it]#015                                                 #015#015  4%|▍         | 48/1160 [01:13<19:40,  1.06s/it]#015  4%|▍         | 49/1160 [01:14<19:07,  1.03s/it]#015  4%|▍         | 50/1160 [01:15<18:18,  1.01it/s]#015  4%|▍         | 51/1160 [01:16<17:30,  1.06it/s]#015  4%|▍         | 52/1160 [01:16<16:29,  1.12it/s]#015  5%|▍         | 53/1160 [01:17<15:26,  1.19it/s]#015  5%|▍         | 54/1160 [01:18<14:08,  1.30it/s]#015  5%|▍         | 55/1160 [01:18<12:47,  1.44it/s]#015  5%|▍         | 56/1160 [01:19<11:15,  1.63it/s]#015  5%|▍         | 57/1160 [01:24<39:02,  2.12s/it]#015  5%|▌         | 58/1160 [01:27<42:54,  2.34s/it]#015  5%|▌         | 59/1160 [01:29<42:16,  2.30s/it]#015  5%|▌         | 60/1160 [01:31<40:22,  2.20s/it]#015                                                 #015#015  5%|▌         | 60/1160 [01:31<40:22,  2.20s/it]#015  5%|▌         | 61/1160 [01:33<38:06,  2.08s/it]#015  5%|▌         | 62/1160 [01:35<35:36,  1.95s/it]#015  5%|▌         | 63/1160 [01:36<33:33,  1.84s/it]#015  6%|▌         | 64/1160 [01:38<31:39,  1.73s/it]#015  6%|▌         | 65/1160 [01:39<29:40,  1.63s/it]#015  6%|▌         | 66/1160 [01:41<28:16,  1.55s/it]#015  6%|▌         | 67/1160 [01:42<26:50,  1.47s/it]#015  6%|▌         | 68/1160 [01:43<25:33,  1.40s/it]#015  6%|▌         | 69/1160 [01:44<24:45,  1.36s/it]#015  6%|▌         | 70/1160 [01:46<23:53,  1.31s/it]#015  6%|▌         | 71/1160 [01:47<22:55,  1.26s/it]#015  6%|▌         | 72/1160 [01:48<22:03,  1.22s/it]#015                                                 #015#015  6%|▌         | 72/1160 [01:48<22:03,  1.22s/it]#015  6%|▋         | 73/1160 [01:49<21:27,  1.18s/it]#015  6%|▋         | 74/1160 [01:50<20:42,  1.14s/it]#015  6%|▋         | 75/1160 [01:51<19:51,  1.10s/it]#015  7%|▋         | 76/1160 [01:52<19:07,  1.06s/it]#015  7%|▋         | 77/1160 [01:53<18:25,  1.02s/it]#015  7%|▋         | 78/1160 [01:54<17:31,  1.03it/s]#015  7%|▋         | 79/1160 [01:54<16:38,  1.08it/s]#015  7%|▋         | 80/1160 [01:55<15:46,  1.14it/s]#015  7%|▋         | 81/1160 [01:56<14:52,  1.21it/s]#015  7%|▋         | 82/1160 [01:57<13:48,  1.30it/s]#015  7%|▋         | 83/1160 [01:57<12:39,  1.42it/s]#015  7%|▋         | 84/1160 [01:58<11:21,  1.58it/s]#015                                                 #015#015  7%|▋         | 84/1160 [01:58<11:21,  1.58it/s]#015  7%|▋         | 85/1160 [02:02<33:10,  1.85s/it]#015  7%|▋         | 86/1160 [02:05<38:04,  2.13s/it]#015  8%|▊         | 87/1160 [02:08<39:36,  2.22s/it]#015  8%|▊         | 88/1160 [02:10<38:49,  2.17s/it]#015  8%|▊         | 89/1160 [02:11<37:14,  2.09s/it]#015  8%|▊         | 90/1160 [02:13<34:59,  1.96s/it]#015  8%|▊         | 91/1160 [02:15<32:40,  1.83s/it]#015  8%|▊         | 92/1160 [02:16<30:51,  1.73s/it]#015  8%|▊         | 93/1160 [02:18<29:16,  1.65s/it]#015  8%|▊         | 94/1160 [02:19<28:03,  1.58s/it]#015  8%|▊         | 95/1160 [02:20<26:48,  1.51s/it]#015  8%|▊         | 96/1160 [02:22<25:37,  1.44s/it]#015                                                 #015#015  8%|▊         | 96/1160 [02:22<25:37,  1.44s/it]#015  8%|▊         | 97/1160 [02:23<24:37,  1.39s/it]#015  8%|▊         | 98/1160 [02:24<23:52,  1.35s/it]#015  9%|▊         | 99/1160 [02:25<23:06,  1.31s/it]#015  9%|▊         | 100/1160 [02:27<22:20,  1.26s/it]#015  9%|▊         | 101/1160 [02:28<21:34,  1.22s/it]#015  9%|▉         | 102/1160 [02:29<20:57,  1.19s/it]#015  9%|▉         | 103/1160 [02:30<20:23,  1.16s/it]#015  9%|▉         | 104/1160 [02:31<19:33,  1.11s/it]#015  9%|▉         | 105/1160 [02:32<18:47,  1.07s/it]#015  9%|▉         | 106/1160 [02:33<18:02,  1.03s/it]#015  9%|▉         | 107/1160 [02:34<17:08,  1.02it/s]#015  9%|▉         | 108/1160 [02:34<16:15,  1.08it/s]#015                                                  #015#015  9%|▉         | 108/1160 [02:34<16:15,  1.08it/s]#015  9%|▉         | 109/1160 [02:35<15:25,  1.14it/s]#015  9%|▉         | 110/1160 [02:36<14:26,  1.21it/s]#015 10%|▉         | 111/1160 [02:36<12:59,  1.35it/s]#015 10%|▉         | 112/1160 [02:37<11:18,  1.55it/s]#015 10%|▉         | 113/1160 [02:41<27:35,  1.58s/it]#015 10%|▉         | 114/1160 [02:42<25:55,  1.49s/it]#015 10%|▉         | 115/1160 [02:43<23:35,  1.35s/it]#015 10%|█         | 116/1160 [02:43<18:02,  1.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.965, 'grad_norm': 4.959230422973633, 'learning_rate': 2.1e-05, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2139, 'grad_norm': 6.701599597930908, 'learning_rate': 2.4e-05, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8601, 'grad_norm': 4.210190296173096, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 10%|█         | 116/1160 [02:54<18:02,  1.04s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.979583740234375, 'eval_accuracy': 0.2037037037037037, 'eval_class_averaged_accuracy': 0.10294117647058823, 'eval_macro_f1': 0.03915081822202565, 'eval_global_f1': 0.2037037037037037, 'eval_class_weighted_f1': 0.07406883221124706, 'eval_runtime': 10.7337, 'eval_samples_per_second': 25.154, 'eval_steps_per_second': 1.304, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m#015 10%|█         | 117/1160 [03:00<1:41:47,  5.86s/it]#015 10%|█         | 118/1160 [03:03<1:25:37,  4.93s/it]#015 10%|█         | 119/1160 [03:05<1:10:33,  4.07s/it]#015 10%|█         | 120/1160 [03:07<58:59,  3.40s/it]  #015                                                  #015#015 10%|█         | 120/1160 [03:07<58:59,  3.40s/it]#015 10%|█         | 121/1160 [03:09<50:56,  2.94s/it]#015 11%|█         | 122/1160 [03:11<44:05,  2.55s/it]#015 11%|█         | 123/1160 [03:12<39:01,  2.26s/it]#015 11%|█         | 124/1160 [03:14<34:51,  2.02s/it]#015 11%|█         | 125/1160 [03:15<31:29,  1.83s/it]#015 11%|█         | 126/1160 [03:16<29:08,  1.69s/it]#015 11%|█         | 127/1160 [03:18<27:10,  1.58s/it]#015 11%|█         | 128/1160 [03:19<25:30,  1.48s/it]#015 11%|█         | 129/1160 [03:20<24:20,  1.42s/it]#015 11%|█         | 130/1160 [03:21<23:13,  1.35s/it]#015 11%|█▏        | 131/1160 [03:23<22:11,  1.29s/it]#015 11%|█▏        | 132/1160 [03:24<21:17,  1.24s/it]#015                                                  #015#015 11%|█▏        | 132/1160 [03:24<21:17,  1.24s/it]#015 11%|█▏        | 133/1160 [03:25<20:37,  1.21s/it]#015 12%|█▏        | 134/1160 [03:26<19:58,  1.17s/it]#015 12%|█▏        | 135/1160 [03:27<19:16,  1.13s/it]#015 12%|█▏        | 136/1160 [03:28<18:31,  1.09s/it]#015 12%|█▏        | 137/1160 [03:29<17:54,  1.05s/it]#015 12%|█▏        | 138/1160 [03:30<17:18,  1.02s/it]#015 12%|█▏        | 139/1160 [03:31<16:27,  1.03it/s]#015 12%|█▏        | 140/1160 [03:31<15:42,  1.08it/s]#015 12%|█▏        | 141/1160 [03:32<14:55,  1.14it/s]#015 12%|█▏        | 142/1160 [03:33<14:02,  1.21it/s]#015 12%|█▏        | 143/1160 [03:34<12:44,  1.33it/s]#015 12%|█▏        | 144/1160 [03:34<11:05,  1.53it/s]#015                                                  #015#015 12%|█▏        | 144/1160 [03:34<11:05,  1.53it/s]#015 12%|█▎        | 145/1160 [03:40<36:44,  2.17s/it]#015 13%|█▎        | 146/1160 [03:43<40:37,  2.40s/it]#015 13%|█▎        | 147/1160 [03:45<40:36,  2.41s/it]#015 13%|█▎        | 148/1160 [03:47<39:13,  2.33s/it]#015 13%|█▎        | 149/1160 [03:49<37:20,  2.22s/it]#015 13%|█▎        | 150/1160 [03:51<34:42,  2.06s/it]#015 13%|█▎        | 151/1160 [03:52<31:58,  1.90s/it]#015 13%|█▎        | 152/1160 [03:54<29:48,  1.77s/it]#015 13%|█▎        | 153/1160 [03:55<27:53,  1.66s/it]#015 13%|█▎        | 154/1160 [03:57<26:35,  1.59s/it]#015 13%|█▎        | 155/1160 [03:58<25:11,  1.50s/it]#015 13%|█▎        | 156/1160 [03:59<23:56,  1.43s/it]#015                                                  #015#015 13%|█▎        | 156/1160 [03:59<23:56,  1.43s/it]#015 14%|█▎        | 157/1160 [04:00<23:06,  1.38s/it]#015 14%|█▎        | 158/1160 [04:02<22:11,  1.33s/it]#015 14%|█▎        | 159/1160 [04:03<21:16,  1.28s/it]#015 14%|█▍        | 160/1160 [04:04<20:27,  1.23s/it]#015 14%|█▍        | 161/1160 [04:05<19:50,  1.19s/it]#015 14%|█▍        | 162/1160 [04:06<19:16,  1.16s/it]#015 14%|█▍        | 163/1160 [04:07<18:35,  1.12s/it]#015 14%|█▍        | 164/1160 [04:08<17:52,  1.08s/it]#015 14%|█▍        | 165/1160 [04:09<17:15,  1.04s/it]#015 14%|█▍        | 166/1160 [04:10<16:24,  1.01it/s]#015 14%|█▍        | 167/1160 [04:11<15:26,  1.07it/s]#015 14%|█▍        | 168/1160 [04:12<14:32,  1.14it/s]#015                                                  #015#015 14%|█▍        | 168/1160 [04:12<14:32,  1.14it/s]#015 15%|█▍        | 169/1160 [04:12<13:30,  1.22it/s]#015 15%|█▍        | 170/1160 [04:13<12:24,  1.33it/s]#015 15%|█▍        | 171/1160 [04:13<11:16,  1.46it/s]#015 15%|█▍        | 172/1160 [04:14<09:55,  1.66it/s]#015 15%|█▍        | 173/1160 [04:19<34:58,  2.13s/it]#015 15%|█▌        | 174/1160 [04:22<38:53,  2.37s/it]#015 15%|█▌        | 175/1160 [04:25<38:41,  2.36s/it]#015 15%|█▌        | 176/1160 [04:27<37:28,  2.29s/it]#015 15%|█▌        | 177/1160 [04:29<35:49,  2.19s/it]#015 15%|█▌        | 178/1160 [04:30<33:35,  2.05s/it]#015 15%|█▌        | 179/1160 [04:32<31:21,  1.92s/it]#015 16%|█▌        | 180/1160 [04:34<29:34,  1.81s/it]#015                                                  #015#015 16%|█▌        | 180/1160 [04:34<29:34,  1.81s/it]#015 16%|█▌        | 181/1160 [04:35<27:51,  1.71s/it]#015 16%|█▌        | 182/1160 [04:37<26:26,  1.62s/it]#015 16%|█▌        | 183/1160 [04:38<25:04,  1.54s/it]#015 16%|█▌        | 184/1160 [04:39<23:41,  1.46s/it]#015 16%|█▌        | 185/1160 [04:40<22:47,  1.40s/it]#015 16%|█▌        | 186/1160 [04:42<22:03,  1.36s/it]#015 16%|█▌        | 187/1160 [04:43<21:16,  1.31s/it]#015 16%|█▌        | 188/1160 [04:44<20:33,  1.27s/it]#015 16%|█▋        | 189/1160 [04:45<19:50,  1.23s/it]#015 16%|█▋        | 190/1160 [04:46<19:16,  1.19s/it]#015 16%|█▋        | 191/1160 [04:47<18:44,  1.16s/it]#015 17%|█▋        | 192/1160 [04:48<17:57,  1.11s/it]#015                                                  #015#015 17%|█▋        | 192/1160 [04:48<17:57,  1.11s/it]#015 17%|█▋        | 193/1160 [04:49<17:22,  1.08s/it]#015 17%|█▋        | 194/1160 [04:50<16:40,  1.04s/it]#015 17%|█▋        | 195/1160 [04:51<15:47,  1.02it/s]#015 17%|█▋        | 196/1160 [04:52<14:54,  1.08it/s]#015 17%|█▋        | 197/1160 [04:53<14:00,  1.15it/s]#015 17%|█▋        | 198/1160 [04:53<12:52,  1.25it/s]#015 17%|█▋        | 199/1160 [04:54<11:35,  1.38it/s]#015 17%|█▋        | 200/1160 [04:54<10:24,  1.54it/s]#015 17%|█▋        | 201/1160 [05:00<34:31,  2.16s/it]#015 17%|█▋        | 202/1160 [05:03<38:28,  2.41s/it]#015 18%|█▊        | 203/1160 [05:05<38:07,  2.39s/it]#015 18%|█▊        | 204/1160 [05:08<36:49,  2.31s/it]#015                                                  #015#015 18%|█▊        | 204/1160 [05:08<36:49,  2.31s/it]#015 18%|█▊        | 205/1160 [05:09<34:21,  2.16s/it]#015 18%|█▊        | 206/1160 [05:11<31:40,  1.99s/it]#015 18%|█▊        | 207/1160 [05:13<29:39,  1.87s/it]#015 18%|█▊        | 208/1160 [05:14<27:54,  1.76s/it]#015 18%|█▊        | 209/1160 [05:15<26:09,  1.65s/it]#015 18%|█▊        | 210/1160 [05:17<24:57,  1.58s/it]#015 18%|█▊        | 211/1160 [05:18<23:41,  1.50s/it]#015 18%|█▊        | 212/1160 [05:19<22:29,  1.42s/it]#015 18%|█▊        | 213/1160 [05:21<21:48,  1.38s/it]#015 18%|█▊        | 214/1160 [05:22<21:04,  1.34s/it]#015 19%|█▊        | 215/1160 [05:23<20:27,  1.30s/it]#015 19%|█▊        | 216/1160 [05:24<19:44,  1.25s/it]#015                                                  #015#015 19%|█▊        | 216/1160 [05:24<19:44,  1.25s/it]#015 19%|█▊        | 217/1160 [05:25<19:06,  1.22s/it]#015 19%|█▉        | 218/1160 [05:26<18:28,  1.18s/it]#015 19%|█▉        | 219/1160 [05:27<17:39,  1.13s/it]#015 19%|█▉        | 220/1160 [05:28<17:00,  1.09s/it]#015 19%|█▉        | 221/1160 [05:29<16:18,  1.04s/it]#015 19%|█▉        | 222/1160 [05:30<15:31,  1.01it/s]#015 19%|█▉        | 223/1160 [05:31<14:43,  1.06it/s]#015 19%|█▉        | 224/1160 [05:32<14:00,  1.11it/s]#015 19%|█▉        | 225/1160 [05:33<13:15,  1.18it/s]#015 19%|█▉        | 226/1160 [05:33<12:22,  1.26it/s]#015 20%|█▉        | 227/1160 [05:34<11:14,  1.38it/s]#015 20%|█▉        | 228/1160 [05:34<10:01,  1.55it/s]#015                                                  #015#015 20%|█▉        | 228/1160 [05:34<10:01,  1.55it/s]#015 20%|█▉        | 229/1160 [05:37<20:27,  1.32s/it]#015 20%|█▉        | 230/1160 [05:39<20:20,  1.31s/it]#015 20%|█▉        | 231/1160 [05:40<18:50,  1.22s/it]#015 20%|██        | 232/1160 [05:40<14:32,  1.06it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1166, 'grad_norm': 5.505807876586914, 'learning_rate': 3e-05, 'epoch': 1.03}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9173, 'grad_norm': 2.9969992637634277, 'learning_rate': 3.3e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8661, 'grad_norm': 5.317523002624512, 'learning_rate': 3.6e-05, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2641, 'grad_norm': 4.8821868896484375, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8061, 'grad_norm': 5.716905117034912, 'learning_rate': 4.2e-05, 'epoch': 1.45}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1974, 'grad_norm': 4.8014445304870605, 'learning_rate': 4.5e-05, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8235, 'grad_norm': 3.5042295455932617, 'learning_rate': 4.8e-05, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1673, 'grad_norm': 6.066188812255859, 'learning_rate': 4.979166666666667e-05, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8483, 'grad_norm': 3.643220901489258, 'learning_rate': 4.9166666666666665e-05, 'epoch': 1.86}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7509, 'grad_norm': 6.885418891906738, 'learning_rate': 4.854166666666667e-05, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 20%|██        | 232/1160 [05:51<14:32,  1.06it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.6544950008392334, 'eval_accuracy': 0.3851851851851852, 'eval_class_averaged_accuracy': 0.20367521367521366, 'eval_macro_f1': 0.13714035696923396, 'eval_global_f1': 0.3851851851851852, 'eval_class_weighted_f1': 0.26031992962474243, 'eval_runtime': 10.732, 'eval_samples_per_second': 25.158, 'eval_steps_per_second': 1.305, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8295, 'grad_norm': 6.0565314292907715, 'learning_rate': 4.791666666666667e-05, 'epoch': 2.07}\u001b[0m\n",
      "\u001b[34m{'loss': 1.422, 'grad_norm': 4.221190929412842, 'learning_rate': 4.7291666666666666e-05, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m{'loss': 1.619, 'grad_norm': 4.804064750671387, 'learning_rate': 4.666666666666667e-05, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5341, 'grad_norm': 3.393643617630005, 'learning_rate': 4.604166666666666e-05, 'epoch': 2.38}\u001b[0m\n",
      "\u001b[34m{'loss': 1.417, 'grad_norm': 5.136352062225342, 'learning_rate': 4.541666666666667e-05, 'epoch': 2.48}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5338, 'grad_norm': 6.79495096206665, 'learning_rate': 4.4791666666666673e-05, 'epoch': 2.59}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4078, 'grad_norm': 3.8076541423797607, 'learning_rate': 4.4166666666666665e-05, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m#015 20%|██        | 233/1160 [05:57<1:29:19,  5.78s/it]#015 20%|██        | 234/1160 [06:00<1:16:19,  4.95s/it]#015 20%|██        | 235/1160 [06:02<1:04:48,  4.20s/it]#015 20%|██        | 236/1160 [06:04<54:41,  3.55s/it]  #015 20%|██        | 237/1160 [06:06<46:27,  3.02s/it]#015 21%|██        | 238/1160 [06:08<39:33,  2.57s/it]#015 21%|██        | 239/1160 [06:09<34:41,  2.26s/it]#015 21%|██        | 240/1160 [06:11<30:38,  2.00s/it]#015                                                  #015#015 21%|██        | 240/1160 [06:11<30:38,  2.00s/it]#015 21%|██        | 241/1160 [06:12<28:01,  1.83s/it]#015 21%|██        | 242/1160 [06:13<25:48,  1.69s/it]#015 21%|██        | 243/1160 [06:15<23:57,  1.57s/it]#015 21%|██        | 244/1160 [06:16<22:29,  1.47s/it]#015 21%|██        | 245/1160 [06:17<21:30,  1.41s/it]#015 21%|██        | 246/1160 [06:18<20:35,  1.35s/it]#015 21%|██▏       | 247/1160 [06:20<19:44,  1.30s/it]#015 21%|██▏       | 248/1160 [06:21<18:53,  1.24s/it]#015 21%|██▏       | 249/1160 [06:22<18:17,  1.20s/it]#015 22%|██▏       | 250/1160 [06:23<17:47,  1.17s/it]#015 22%|██▏       | 251/1160 [06:24<17:07,  1.13s/it]#015 22%|██▏       | 252/1160 [06:25<16:27,  1.09s/it]#015                                                  #015#015 22%|██▏       | 252/1160 [06:25<16:27,  1.09s/it]#015 22%|██▏       | 253/1160 [06:26<15:54,  1.05s/it]#015 22%|██▏       | 254/1160 [06:27<15:17,  1.01s/it]#015 22%|██▏       | 255/1160 [06:28<14:33,  1.04it/s]#015 22%|██▏       | 256/1160 [06:28<13:47,  1.09it/s]#015 22%|██▏       | 257/1160 [06:29<12:59,  1.16it/s]#015 22%|██▏       | 258/1160 [06:30<12:01,  1.25it/s]#015 22%|██▏       | 259/1160 [06:30<10:55,  1.38it/s]#015 22%|██▏       | 260/1160 [06:31<09:47,  1.53it/s]#015 22%|██▎       | 261/1160 [06:36<31:28,  2.10s/it]#015 23%|██▎       | 262/1160 [06:39<34:31,  2.31s/it]#015 23%|██▎       | 263/1160 [06:42<35:15,  2.36s/it]#015 23%|██▎       | 264/1160 [06:44<33:39,  2.25s/it]#015                                                  #015#015 23%|██▎       | 264/1160 [06:44<33:39,  2.25s/it]#015 23%|██▎       | 265/1160 [06:46<32:14,  2.16s/it]#015 23%|██▎       | 266/1160 [06:47<30:11,  2.03s/it]#015 23%|██▎       | 267/1160 [06:49<28:00,  1.88s/it]#015 23%|██▎       | 268/1160 [06:50<26:28,  1.78s/it]#015 23%|██▎       | 269/1160 [06:52<24:55,  1.68s/it]#015 23%|██▎       | 270/1160 [06:53<23:36,  1.59s/it]#015 23%|██▎       | 271/1160 [06:55<22:39,  1.53s/it]#015 23%|██▎       | 272/1160 [06:56<21:33,  1.46s/it]#015 24%|██▎       | 273/1160 [06:57<20:44,  1.40s/it]#015 24%|██▎       | 274/1160 [06:58<19:57,  1.35s/it]#015 24%|██▎       | 275/1160 [07:00<19:05,  1.29s/it]#015 24%|██▍       | 276/1160 [07:01<18:27,  1.25s/it]#015                                                  #015#015 24%|██▍       | 276/1160 [07:01<18:27,  1.25s/it]#015 24%|██▍       | 277/1160 [07:02<17:51,  1.21s/it]#015 24%|██▍       | 278/1160 [07:03<17:21,  1.18s/it]#015 24%|██▍       | 279/1160 [07:04<16:49,  1.15s/it]#015 24%|██▍       | 280/1160 [07:05<16:11,  1.10s/it]#015 24%|██▍       | 281/1160 [07:06<15:37,  1.07s/it]#015 24%|██▍       | 282/1160 [07:07<15:07,  1.03s/it]#015 24%|██▍       | 283/1160 [07:08<14:26,  1.01it/s]#015 24%|██▍       | 284/1160 [07:09<13:41,  1.07it/s]#015 25%|██▍       | 285/1160 [07:09<12:52,  1.13it/s]#015 25%|██▍       | 286/1160 [07:10<11:54,  1.22it/s]#015 25%|██▍       | 287/1160 [07:11<10:44,  1.35it/s]#015 25%|██▍       | 288/1160 [07:11<09:30,  1.53it/s]#015                                                  #015#015 25%|██▍       | 288/1160 [07:11<09:30,  1.53it/s]#015 25%|██▍       | 289/1160 [07:17<31:27,  2.17s/it]#015 25%|██▌       | 290/1160 [07:20<33:53,  2.34s/it]#015 25%|██▌       | 291/1160 [07:22<32:25,  2.24s/it]#015 25%|██▌       | 292/1160 [07:23<30:43,  2.12s/it]#015 25%|██▌       | 293/1160 [07:25<29:06,  2.01s/it]#015 25%|██▌       | 294/1160 [07:27<27:23,  1.90s/it]#015 25%|██▌       | 295/1160 [07:28<25:58,  1.80s/it]#015 26%|██▌       | 296/1160 [07:30<24:25,  1.70s/it]#015 26%|██▌       | 297/1160 [07:31<23:15,  1.62s/it]#015 26%|██▌       | 298/1160 [07:33<22:04,  1.54s/it]#015 26%|██▌       | 299/1160 [07:34<21:02,  1.47s/it]#015 26%|██▌       | 300/1160 [07:35<20:06,  1.40s/it]#015                                                  #015#015 26%|██▌       | 300/1160 [07:35<20:06,  1.40s/it]#015 26%|██▌       | 301/1160 [07:36<19:31,  1.36s/it]#015 26%|██▌       | 302/1160 [07:38<18:50,  1.32s/it]#015 26%|██▌       | 303/1160 [07:39<18:08,  1.27s/it]#015 26%|██▌       | 304/1160 [07:40<17:27,  1.22s/it]#015 26%|██▋       | 305/1160 [07:41<16:55,  1.19s/it]#015 26%|██▋       | 306/1160 [07:42<16:13,  1.14s/it]#015 26%|██▋       | 307/1160 [07:43<15:32,  1.09s/it]#015 27%|██▋       | 308/1160 [07:44<14:57,  1.05s/it]#015 27%|██▋       | 309/1160 [07:45<14:15,  1.01s/it]#015 27%|██▋       | 310/1160 [07:46<13:38,  1.04it/s]#015 27%|██▋       | 311/1160 [07:47<13:01,  1.09it/s]#015 27%|██▋       | 312/1160 [07:47<12:20,  1.15it/s]#015                                                  #015#015 27%|██▋       | 312/1160 [07:47<12:20,  1.15it/s]#015 27%|██▋       | 313/1160 [07:48<11:41,  1.21it/s]#015 27%|██▋       | 314/1160 [07:49<10:49,  1.30it/s]#015 27%|██▋       | 315/1160 [07:49<09:52,  1.43it/s]#015 27%|██▋       | 316/1160 [07:50<08:44,  1.61it/s]#015 27%|██▋       | 317/1160 [07:55<30:04,  2.14s/it]#015 27%|██▋       | 318/1160 [07:58<33:30,  2.39s/it]#015 28%|██▊       | 319/1160 [08:01<33:20,  2.38s/it]#015 28%|██▊       | 320/1160 [08:03<31:44,  2.27s/it]#015 28%|██▊       | 321/1160 [08:05<30:09,  2.16s/it]#015 28%|██▊       | 322/1160 [08:06<28:05,  2.01s/it]#015 28%|██▊       | 323/1160 [08:08<26:09,  1.88s/it]#015 28%|██▊       | 324/1160 [08:09<24:44,  1.78s/it]#015                                                  #015#015 28%|██▊       | 324/1160 [08:09<24:44,  1.78s/it]#015 28%|██▊       | 325/1160 [08:11<23:19,  1.68s/it]#015 28%|██▊       | 326/1160 [08:12<22:09,  1.59s/it]#015 28%|██▊       | 327/1160 [08:14<21:00,  1.51s/it]#015 28%|██▊       | 328/1160 [08:15<19:56,  1.44s/it]#015 28%|██▊       | 329/1160 [08:16<19:14,  1.39s/it]#015 28%|██▊       | 330/1160 [08:17<18:34,  1.34s/it]#015 29%|██▊       | 331/1160 [08:18<17:50,  1.29s/it]#015 29%|██▊       | 332/1160 [08:20<17:14,  1.25s/it]#015 29%|██▊       | 333/1160 [08:21<16:41,  1.21s/it]#015 29%|██▉       | 334/1160 [08:22<16:17,  1.18s/it]#015 29%|██▉       | 335/1160 [08:23<15:51,  1.15s/it]#015 29%|██▉       | 336/1160 [08:24<15:16,  1.11s/it]#015                                                  #015#015 29%|██▉       | 336/1160 [08:24<15:16,  1.11s/it]#015 29%|██▉       | 337/1160 [08:25<14:46,  1.08s/it]#015 29%|██▉       | 338/1160 [08:26<14:11,  1.04s/it]#015 29%|██▉       | 339/1160 [08:27<13:26,  1.02it/s]#015 29%|██▉       | 340/1160 [08:28<12:40,  1.08it/s]#015 29%|██▉       | 341/1160 [08:28<11:54,  1.15it/s]#015 29%|██▉       | 342/1160 [08:29<11:02,  1.23it/s]#015 30%|██▉       | 343/1160 [08:29<09:53,  1.38it/s]#015 30%|██▉       | 344/1160 [08:30<08:37,  1.58it/s]#015 30%|██▉       | 345/1160 [08:36<29:00,  2.14s/it]#015 30%|██▉       | 346/1160 [08:37<27:50,  2.05s/it]#015 30%|██▉       | 347/1160 [08:38<23:24,  1.73s/it]#015 30%|███       | 348/1160 [08:39<17:16,  1.28s/it]#015                                                  #015#015 30%|███       | 348/1160 [08:39<17:16,  1.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.321, 'grad_norm': 7.92453670501709, 'learning_rate': 4.354166666666667e-05, 'epoch': 2.79}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3702, 'grad_norm': 6.499910831451416, 'learning_rate': 4.291666666666667e-05, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2485, 'grad_norm': 7.3273186683654785, 'learning_rate': 4.229166666666667e-05, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 30%|███       | 348/1160 [08:49<17:16,  1.28s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.1975064277648926, 'eval_accuracy': 0.5481481481481482, 'eval_class_averaged_accuracy': 0.3118809197713863, 'eval_macro_f1': 0.2751349189945681, 'eval_global_f1': 0.5481481481481482, 'eval_class_weighted_f1': 0.481022062698476, 'eval_runtime': 10.7561, 'eval_samples_per_second': 25.102, 'eval_steps_per_second': 1.302, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3306, 'grad_norm': 4.808965682983398, 'learning_rate': 4.166666666666667e-05, 'epoch': 3.1}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0868, 'grad_norm': 4.640140056610107, 'learning_rate': 4.104166666666667e-05, 'epoch': 3.21}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2027, 'grad_norm': 12.3211088180542, 'learning_rate': 4.041666666666667e-05, 'epoch': 3.31}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2838, 'grad_norm': 8.505637168884277, 'learning_rate': 3.979166666666667e-05, 'epoch': 3.41}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0028, 'grad_norm': 7.832167148590088, 'learning_rate': 3.9166666666666665e-05, 'epoch': 3.52}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1222, 'grad_norm': 5.450376510620117, 'learning_rate': 3.854166666666667e-05, 'epoch': 3.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9396, 'grad_norm': 6.093672275543213, 'learning_rate': 3.791666666666667e-05, 'epoch': 3.72}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0529, 'grad_norm': 4.240692615509033, 'learning_rate': 3.729166666666667e-05, 'epoch': 3.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9593, 'grad_norm': 5.936456680297852, 'learning_rate': 3.6666666666666666e-05, 'epoch': 3.93}\u001b[0m\n",
      "\u001b[34m#015 30%|███       | 349/1160 [08:56<1:21:30,  6.03s/it]#015 30%|███       | 350/1160 [08:59<1:09:08,  5.12s/it]#015 30%|███       | 351/1160 [09:01<58:20,  4.33s/it]  #015 30%|███       | 352/1160 [09:03<49:32,  3.68s/it]#015 30%|███       | 353/1160 [09:05<42:11,  3.14s/it]#015 31%|███       | 354/1160 [09:07<36:46,  2.74s/it]#015 31%|███       | 355/1160 [09:09<32:25,  2.42s/it]#015 31%|███       | 356/1160 [09:10<29:05,  2.17s/it]#015 31%|███       | 357/1160 [09:12<26:05,  1.95s/it]#015 31%|███       | 358/1160 [09:13<23:51,  1.79s/it]#015 31%|███       | 359/1160 [09:14<21:57,  1.65s/it]#015 31%|███       | 360/1160 [09:16<20:23,  1.53s/it]#015                                                  #015#015 31%|███       | 360/1160 [09:16<20:23,  1.53s/it]#015 31%|███       | 361/1160 [09:17<19:22,  1.45s/it]#015 31%|███       | 362/1160 [09:18<18:30,  1.39s/it]#015 31%|███▏      | 363/1160 [09:19<17:44,  1.34s/it]#015 31%|███▏      | 364/1160 [09:21<17:01,  1.28s/it]#015 31%|███▏      | 365/1160 [09:22<16:20,  1.23s/it]#015 32%|███▏      | 366/1160 [09:23<15:48,  1.19s/it]#015 32%|███▏      | 367/1160 [09:24<15:15,  1.15s/it]#015 32%|███▏      | 368/1160 [09:25<14:33,  1.10s/it]#015 32%|███▏      | 369/1160 [09:26<14:01,  1.06s/it]#015 32%|███▏      | 370/1160 [09:27<13:35,  1.03s/it]#015 32%|███▏      | 371/1160 [09:28<12:57,  1.01it/s]#015 32%|███▏      | 372/1160 [09:29<12:19,  1.07it/s]#015                                                  #015#015 32%|███▏      | 372/1160 [09:29<12:19,  1.07it/s]#015 32%|███▏      | 373/1160 [09:29<11:36,  1.13it/s]#015 32%|███▏      | 374/1160 [09:30<10:44,  1.22it/s]#015 32%|███▏      | 375/1160 [09:30<09:44,  1.34it/s]#015 32%|███▏      | 376/1160 [09:31<08:41,  1.50it/s]#015 32%|███▎      | 377/1160 [09:37<28:18,  2.17s/it]#015 33%|███▎      | 378/1160 [09:39<30:39,  2.35s/it]#015 33%|███▎      | 379/1160 [09:42<30:11,  2.32s/it]#015 33%|███▎      | 380/1160 [09:44<29:09,  2.24s/it]#015 33%|███▎      | 381/1160 [09:46<27:22,  2.11s/it]#015 33%|███▎      | 382/1160 [09:47<25:23,  1.96s/it]#015 33%|███▎      | 383/1160 [09:49<23:53,  1.84s/it]#015 33%|███▎      | 384/1160 [09:50<22:15,  1.72s/it]#015                                                  #015#015 33%|███▎      | 384/1160 [09:50<22:15,  1.72s/it]#015 33%|███▎      | 385/1160 [09:52<21:00,  1.63s/it]#015 33%|███▎      | 386/1160 [09:53<19:55,  1.54s/it]#015 33%|███▎      | 387/1160 [09:54<19:01,  1.48s/it]#015 33%|███▎      | 388/1160 [09:55<18:08,  1.41s/it]#015 34%|███▎      | 389/1160 [09:57<17:27,  1.36s/it]#015 34%|███▎      | 390/1160 [09:58<16:51,  1.31s/it]#015 34%|███▎      | 391/1160 [09:59<16:13,  1.27s/it]#015 34%|███▍      | 392/1160 [10:00<15:39,  1.22s/it]#015 34%|███▍      | 393/1160 [10:01<15:11,  1.19s/it]#015 34%|███▍      | 394/1160 [10:02<14:50,  1.16s/it]#015 34%|███▍      | 395/1160 [10:03<14:19,  1.12s/it]#015 34%|███▍      | 396/1160 [10:04<13:48,  1.08s/it]#015                                                  #015#015 34%|███▍      | 396/1160 [10:04<13:48,  1.08s/it]#015 34%|███▍      | 397/1160 [10:05<13:22,  1.05s/it]#015 34%|███▍      | 398/1160 [10:06<12:51,  1.01s/it]#015 34%|███▍      | 399/1160 [10:07<12:17,  1.03it/s]#015 34%|███▍      | 400/1160 [10:08<11:37,  1.09it/s]#015 35%|███▍      | 401/1160 [10:09<10:57,  1.15it/s]#015 35%|███▍      | 402/1160 [10:09<10:12,  1.24it/s]#015 35%|███▍      | 403/1160 [10:10<09:10,  1.38it/s]#015 35%|███▍      | 404/1160 [10:10<08:01,  1.57it/s]#015 35%|███▍      | 405/1160 [10:15<22:37,  1.80s/it]#015 35%|███▌      | 406/1160 [10:18<28:00,  2.23s/it]#015 35%|███▌      | 407/1160 [10:21<28:44,  2.29s/it]#015 35%|███▌      | 408/1160 [10:23<27:26,  2.19s/it]#015                                                  #015#015 35%|███▌      | 408/1160 [10:23<27:26,  2.19s/it]#015 35%|███▌      | 409/1160 [10:24<25:33,  2.04s/it]#015 35%|███▌      | 410/1160 [10:26<23:54,  1.91s/it]#015 35%|███▌      | 411/1160 [10:27<22:38,  1.81s/it]#015 36%|███▌      | 412/1160 [10:29<21:16,  1.71s/it]#015 36%|███▌      | 413/1160 [10:30<20:05,  1.61s/it]#015 36%|███▌      | 414/1160 [10:32<19:13,  1.55s/it]#015 36%|███▌      | 415/1160 [10:33<18:18,  1.47s/it]#015 36%|███▌      | 416/1160 [10:34<17:32,  1.41s/it]#015 36%|███▌      | 417/1160 [10:35<16:51,  1.36s/it]#015 36%|███▌      | 418/1160 [10:37<16:08,  1.30s/it]#015 36%|███▌      | 419/1160 [10:38<15:27,  1.25s/it]#015 36%|███▌      | 420/1160 [10:39<14:55,  1.21s/it]#015                                                  #015#015 36%|███▌      | 420/1160 [10:39<14:55,  1.21s/it]#015 36%|███▋      | 421/1160 [10:40<14:33,  1.18s/it]#015 36%|███▋      | 422/1160 [10:41<14:10,  1.15s/it]#015 36%|███▋      | 423/1160 [10:42<13:32,  1.10s/it]#015 37%|███▋      | 424/1160 [10:43<13:00,  1.06s/it]#015 37%|███▋      | 425/1160 [10:44<12:20,  1.01s/it]#015 37%|███▋      | 426/1160 [10:45<11:45,  1.04it/s]#015 37%|███▋      | 427/1160 [10:46<11:09,  1.09it/s]#015 37%|███▋      | 428/1160 [10:46<10:32,  1.16it/s]#015 37%|███▋      | 429/1160 [10:47<09:52,  1.23it/s]#015 37%|███▋      | 430/1160 [10:48<09:07,  1.33it/s]#015 37%|███▋      | 431/1160 [10:48<08:19,  1.46it/s]#015 37%|███▋      | 432/1160 [10:49<07:24,  1.64it/s]#015                                                  #015#015 37%|███▋      | 432/1160 [10:49<07:24,  1.64it/s]#015 37%|███▋      | 433/1160 [10:54<25:56,  2.14s/it]#015 37%|███▋      | 434/1160 [10:57<28:05,  2.32s/it]#015 38%|███▊      | 435/1160 [10:59<28:04,  2.32s/it]#015 38%|███▊      | 436/1160 [11:01<26:43,  2.22s/it]#015 38%|███▊      | 437/1160 [11:03<25:10,  2.09s/it]#015 38%|███▊      | 438/1160 [11:05<23:30,  1.95s/it]#015 38%|███▊      | 439/1160 [11:06<22:05,  1.84s/it]#015 38%|███▊      | 440/1160 [11:08<20:53,  1.74s/it]#015 38%|███▊      | 441/1160 [11:09<19:47,  1.65s/it]#015 38%|███▊      | 442/1160 [11:11<18:57,  1.58s/it]#015 38%|███▊      | 443/1160 [11:12<18:06,  1.51s/it]#015 38%|███▊      | 444/1160 [11:13<17:18,  1.45s/it]#015                                                  #015#015 38%|███▊      | 444/1160 [11:13<17:18,  1.45s/it]#015 38%|███▊      | 445/1160 [11:15<16:36,  1.39s/it]#015 38%|███▊      | 446/1160 [11:16<16:08,  1.36s/it]#015 39%|███▊      | 447/1160 [11:17<15:35,  1.31s/it]#015 39%|███▊      | 448/1160 [11:18<15:01,  1.27s/it]#015 39%|███▊      | 449/1160 [11:19<14:28,  1.22s/it]#015 39%|███▉      | 450/1160 [11:20<14:02,  1.19s/it]#015 39%|███▉      | 451/1160 [11:22<13:35,  1.15s/it]#015 39%|███▉      | 452/1160 [11:23<12:59,  1.10s/it]#015 39%|███▉      | 453/1160 [11:24<12:30,  1.06s/it]#015 39%|███▉      | 454/1160 [11:24<11:59,  1.02s/it]#015 39%|███▉      | 455/1160 [11:25<11:24,  1.03it/s]#015 39%|███▉      | 456/1160 [11:26<10:47,  1.09it/s]#015                                                  #015#015 39%|███▉      | 456/1160 [11:26<10:47,  1.09it/s]#015 39%|███▉      | 457/1160 [11:27<10:10,  1.15it/s]#015 39%|███▉      | 458/1160 [11:28<09:27,  1.24it/s]#015 40%|███▉      | 459/1160 [11:28<08:33,  1.37it/s]#015 40%|███▉      | 460/1160 [11:28<07:28,  1.56it/s]#015 40%|███▉      | 461/1160 [11:32<18:29,  1.59s/it]#015 40%|███▉      | 462/1160 [11:34<17:25,  1.50s/it]#015 40%|███▉      | 463/1160 [11:35<15:58,  1.38s/it]#015 40%|████      | 464/1160 [11:35<11:54,  1.03s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 40%|████      | 464/1160 [11:46<11:54,  1.03s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.0173134803771973, 'eval_accuracy': 0.6185185185185185, 'eval_class_averaged_accuracy': 0.3961665236386332, 'eval_macro_f1': 0.39047150925342355, 'eval_global_f1': 0.6185185185185185, 'eval_class_weighted_f1': 0.5839023530137882, 'eval_runtime': 10.7558, 'eval_samples_per_second': 25.103, 'eval_steps_per_second': 1.302, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m#015 40%|████      | 465/1160 [11:52<1:07:46,  5.85s/it]#015 40%|████      | 466/1160 [11:55<57:30,  4.97s/it]  #015 40%|████      | 467/1160 [11:57<47:12,  4.09s/it]#015 40%|████      | 468/1160 [11:59<39:14,  3.40s/it]#015                                                  #015#015 40%|████      | 468/1160 [11:59<39:14,  3.40s/it]#015 40%|████      | 469/1160 [12:00<33:03,  2.87s/it]#015 41%|████      | 470/1160 [12:02<28:35,  2.49s/it]#015 41%|████      | 471/1160 [12:03<25:03,  2.18s/it]#015 41%|████      | 472/1160 [12:05<22:16,  1.94s/it]#015 41%|████      | 473/1160 [12:06<20:13,  1.77s/it]#015 41%|████      | 474/1160 [12:07<18:26,  1.61s/it]#015 41%|████      | 475/1160 [12:09<17:16,  1.51s/it]#015 41%|████      | 476/1160 [12:10<16:22,  1.44s/it]#015 41%|████      | 477/1160 [12:11<15:34,  1.37s/it]#015 41%|████      | 478/1160 [12:12<14:52,  1.31s/it]#015 41%|████▏     | 479/1160 [12:13<14:13,  1.25s/it]#015 41%|████▏     | 480/1160 [12:15<13:44,  1.21s/it]#015                                                  #015#015 41%|████▏     | 480/1160 [12:15<13:44,  1.21s/it]#015 41%|████▏     | 481/1160 [12:16<13:18,  1.18s/it]#015 42%|████▏     | 482/1160 [12:17<12:47,  1.13s/it]#015 42%|████▏     | 483/1160 [12:18<12:17,  1.09s/it]#015 42%|████▏     | 484/1160 [12:19<11:51,  1.05s/it]#015 42%|████▏     | 485/1160 [12:20<11:25,  1.02s/it]#015 42%|████▏     | 486/1160 [12:20<10:54,  1.03it/s]#015 42%|████▏     | 487/1160 [12:21<10:23,  1.08it/s]#015 42%|████▏     | 488/1160 [12:22<09:49,  1.14it/s]#015 42%|████▏     | 489/1160 [12:23<09:17,  1.20it/s]#015 42%|████▏     | 490/1160 [12:23<08:37,  1.29it/s]#015 42%|████▏     | 491/1160 [12:24<07:51,  1.42it/s]#015 42%|████▏     | 492/1160 [12:24<07:00,  1.59it/s]#015                                                  #015#015 42%|████▏     | 492/1160 [12:24<07:00,  1.59it/s]#015 42%|████▎     | 493/1160 [12:30<23:57,  2.16s/it]#015 43%|████▎     | 494/1160 [12:33<27:25,  2.47s/it]#015 43%|████▎     | 495/1160 [12:36<27:10,  2.45s/it]#015 43%|████▎     | 496/1160 [12:38<26:26,  2.39s/it]#015 43%|████▎     | 497/1160 [12:40<25:14,  2.28s/it]#015 43%|████▎     | 498/1160 [12:42<23:47,  2.16s/it]#015 43%|████▎     | 499/1160 [12:44<22:02,  2.00s/it]#015 43%|████▎     | 500/1160 [12:45<20:27,  1.86s/it]#015 43%|████▎     | 501/1160 [12:47<19:19,  1.76s/it]#015 43%|████▎     | 502/1160 [12:48<18:15,  1.67s/it]#015 43%|████▎     | 503/1160 [12:49<17:23,  1.59s/it]#015 43%|████▎     | 504/1160 [12:51<16:35,  1.52s/it]#015                                                  #015#015 43%|████▎     | 504/1160 [12:51<16:35,  1.52s/it]#015 44%|████▎     | 505/1160 [12:52<15:52,  1.45s/it]#015 44%|████▎     | 506/1160 [12:53<15:10,  1.39s/it]#015 44%|████▎     | 507/1160 [12:55<14:39,  1.35s/it]#015 44%|████▍     | 508/1160 [12:56<14:10,  1.30s/it]#015 44%|████▍     | 509/1160 [12:57<13:34,  1.25s/it]#015 44%|████▍     | 510/1160 [12:58<13:07,  1.21s/it]#015 44%|████▍     | 511/1160 [12:59<12:40,  1.17s/it]#015 44%|████▍     | 512/1160 [13:00<12:08,  1.12s/it]#015 44%|████▍     | 513/1160 [13:01<11:37,  1.08s/it]#015 44%|████▍     | 514/1160 [13:02<11:02,  1.03s/it]#015 44%|████▍     | 515/1160 [13:03<10:27,  1.03it/s]#015 44%|████▍     | 516/1160 [13:04<09:54,  1.08it/s]#015                                                  #015#015 44%|████▍     | 516/1160 [13:04<09:54,  1.08it/s]#015 45%|████▍     | 517/1160 [13:04<09:23,  1.14it/s]#015 45%|████▍     | 518/1160 [13:05<08:41,  1.23it/s]#015 45%|████▍     | 519/1160 [13:06<07:51,  1.36it/s]#015 45%|████▍     | 520/1160 [13:06<06:59,  1.53it/s]#015 45%|████▍     | 521/1160 [13:12<23:02,  2.16s/it]#015 45%|████▌     | 522/1160 [13:15<25:33,  2.40s/it]#015 45%|████▌     | 523/1160 [13:17<25:19,  2.39s/it]#015 45%|████▌     | 524/1160 [13:19<24:17,  2.29s/it]#015 45%|████▌     | 525/1160 [13:21<22:54,  2.16s/it]#015 45%|████▌     | 526/1160 [13:23<21:18,  2.02s/it]#015 45%|████▌     | 527/1160 [13:24<19:55,  1.89s/it]#015 46%|████▌     | 528/1160 [13:26<18:33,  1.76s/it]#015                                                  #015#015 46%|████▌     | 528/1160 [13:26<18:33,  1.76s/it]#015 46%|████▌     | 529/1160 [13:27<17:20,  1.65s/it]#015 46%|████▌     | 530/1160 [13:29<16:33,  1.58s/it]#015 46%|████▌     | 531/1160 [13:30<15:42,  1.50s/it]#015 46%|████▌     | 532/1160 [13:31<14:54,  1.42s/it]#015 46%|████▌     | 533/1160 [13:32<14:23,  1.38s/it]#015 46%|████▌     | 534/1160 [13:34<13:55,  1.33s/it]#015 46%|████▌     | 535/1160 [13:35<13:23,  1.29s/it]#015 46%|████▌     | 536/1160 [13:36<12:52,  1.24s/it]#015 46%|████▋     | 537/1160 [13:37<12:28,  1.20s/it]#015 46%|████▋     | 538/1160 [13:38<12:10,  1.17s/it]#015 46%|████▋     | 539/1160 [13:39<11:47,  1.14s/it]#015 47%|████▋     | 540/1160 [13:40<11:18,  1.09s/it]#015                                                  #015#015 47%|████▋     | 540/1160 [13:40<11:18,  1.09s/it]#015 47%|████▋     | 541/1160 [13:41<10:56,  1.06s/it]#015 47%|████▋     | 542/1160 [13:42<10:30,  1.02s/it]#015 47%|████▋     | 543/1160 [13:43<09:58,  1.03it/s]#015 47%|████▋     | 544/1160 [13:44<09:26,  1.09it/s]#015 47%|████▋     | 545/1160 [13:44<08:52,  1.15it/s]#015 47%|████▋     | 546/1160 [13:45<08:09,  1.25it/s]#015 47%|████▋     | 547/1160 [13:46<07:21,  1.39it/s]#015 47%|████▋     | 548/1160 [13:46<06:27,  1.58it/s]#015 47%|████▋     | 549/1160 [13:52<21:52,  2.15s/it]#015 47%|████▋     | 550/1160 [13:55<24:01,  2.36s/it]#015 48%|████▊     | 551/1160 [13:57<23:58,  2.36s/it]#015 48%|████▊     | 552/1160 [13:59<22:55,  2.26s/it]#015                                                  #015#015 48%|████▊     | 552/1160 [13:59<22:55,  2.26s/it]#015 48%|████▊     | 553/1160 [14:01<21:43,  2.15s/it]#015 48%|████▊     | 554/1160 [14:03<20:20,  2.01s/it]#015 48%|████▊     | 555/1160 [14:04<18:52,  1.87s/it]#015 48%|████▊     | 556/1160 [14:06<17:44,  1.76s/it]#015 48%|████▊     | 557/1160 [14:07<16:39,  1.66s/it]#015 48%|████▊     | 558/1160 [14:08<15:54,  1.59s/it]#015 48%|████▊     | 559/1160 [14:10<15:03,  1.50s/it]#015 48%|████▊     | 560/1160 [14:11<14:16,  1.43s/it]#015 48%|████▊     | 561/1160 [14:12<13:44,  1.38s/it]#015 48%|████▊     | 562/1160 [14:14<13:12,  1.32s/it]#015 49%|████▊     | 563/1160 [14:15<12:40,  1.27s/it]#015 49%|████▊     | 564/1160 [14:16<12:12,  1.23s/it]#015                                                  #015#015 49%|████▊     | 564/1160 [14:16<12:12,  1.23s/it]#015 49%|████▊     | 565/1160 [14:17<11:51,  1.20s/it]#015 49%|████▉     | 566/1160 [14:18<11:34,  1.17s/it]#015 49%|████▉     | 567/1160 [14:19<11:09,  1.13s/it]#015 49%|████▉     | 568/1160 [14:20<10:42,  1.09s/it]#015 49%|████▉     | 569/1160 [14:21<10:20,  1.05s/it]#015 49%|████▉     | 570/1160 [14:22<09:57,  1.01s/it]#015 49%|████▉     | 571/1160 [14:23<09:29,  1.03it/s]#015 49%|████▉     | 572/1160 [14:24<08:59,  1.09it/s]#015 49%|████▉     | 573/1160 [14:24<08:25,  1.16it/s]#015 49%|████▉     | 574/1160 [14:25<07:46,  1.26it/s]#015 50%|████▉     | 575/1160 [14:26<06:59,  1.39it/s]#015 50%|████▉     | 576/1160 [14:26<06:06,  1.59it/s]#015                                                  #015#015 50%|████▉     | 576/1160 [14:26<06:06,  1.59it/s]#015 50%|████▉     | 577/1160 [14:30<17:17,  1.78s/it]#015 50%|████▉     | 578/1160 [14:32<15:54,  1.64s/it]#015 50%|████▉     | 579/1160 [14:33<14:19,  1.48s/it]#015 50%|█████     | 580/1160 [14:33<10:52,  1.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8711, 'grad_norm': 5.961299419403076, 'learning_rate': 3.604166666666667e-05, 'epoch': 4.03}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9753, 'grad_norm': 5.066308975219727, 'learning_rate': 3.541666666666667e-05, 'epoch': 4.14}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7661, 'grad_norm': 7.321825981140137, 'learning_rate': 3.479166666666667e-05, 'epoch': 4.24}\u001b[0m\n",
      "\u001b[34m{'loss': 1.034, 'grad_norm': 12.668020248413086, 'learning_rate': 3.4166666666666666e-05, 'epoch': 4.34}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0242, 'grad_norm': 9.330024719238281, 'learning_rate': 3.3541666666666664e-05, 'epoch': 4.45}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8888, 'grad_norm': 7.659533500671387, 'learning_rate': 3.291666666666667e-05, 'epoch': 4.55}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8792, 'grad_norm': 7.555296421051025, 'learning_rate': 3.229166666666667e-05, 'epoch': 4.66}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9649, 'grad_norm': 8.618627548217773, 'learning_rate': 3.1666666666666666e-05, 'epoch': 4.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8857, 'grad_norm': 5.51176643371582, 'learning_rate': 3.104166666666667e-05, 'epoch': 4.86}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9104, 'grad_norm': 15.020705223083496, 'learning_rate': 3.0416666666666666e-05, 'epoch': 4.97}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 50%|█████     | 580/1160 [14:44<10:52,  1.13s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.9448226094245911, 'eval_accuracy': 0.6481481481481481, 'eval_class_averaged_accuracy': 0.43506685400172945, 'eval_macro_f1': 0.43331038901503527, 'eval_global_f1': 0.6481481481481481, 'eval_class_weighted_f1': 0.6269462315641243, 'eval_runtime': 10.7506, 'eval_samples_per_second': 25.115, 'eval_steps_per_second': 1.302, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8566, 'grad_norm': 28.719608306884766, 'learning_rate': 2.9791666666666668e-05, 'epoch': 5.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.891, 'grad_norm': 6.008835792541504, 'learning_rate': 2.916666666666667e-05, 'epoch': 5.17}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9255, 'grad_norm': 12.89116096496582, 'learning_rate': 2.8541666666666668e-05, 'epoch': 5.28}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7338, 'grad_norm': 6.712375640869141, 'learning_rate': 2.791666666666667e-05, 'epoch': 5.38}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7809, 'grad_norm': 7.402006149291992, 'learning_rate': 2.7291666666666665e-05, 'epoch': 5.48}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9646, 'grad_norm': 10.507079124450684, 'learning_rate': 2.6666666666666667e-05, 'epoch': 5.59}\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 581/1160 [14:50<57:01,  5.91s/it]#015 50%|█████     | 582/1160 [14:53<48:15,  5.01s/it]#015 50%|█████     | 583/1160 [14:56<40:43,  4.23s/it]#015 50%|█████     | 584/1160 [14:58<34:18,  3.57s/it]#015 50%|█████     | 585/1160 [14:59<29:18,  3.06s/it]#015 51%|█████     | 586/1160 [15:01<25:16,  2.64s/it]#015 51%|█████     | 587/1160 [15:03<22:06,  2.32s/it]#015 51%|█████     | 588/1160 [15:04<19:51,  2.08s/it]#015                                                  #015#015 51%|█████     | 588/1160 [15:04<19:51,  2.08s/it]#015 51%|█████     | 589/1160 [15:06<17:59,  1.89s/it]#015 51%|█████     | 590/1160 [15:07<16:37,  1.75s/it]#015 51%|█████     | 591/1160 [15:08<15:27,  1.63s/it]#015 51%|█████     | 592/1160 [15:10<14:21,  1.52s/it]#015 51%|█████     | 593/1160 [15:11<13:36,  1.44s/it]#015 51%|█████     | 594/1160 [15:12<12:54,  1.37s/it]#015 51%|█████▏    | 595/1160 [15:13<12:20,  1.31s/it]#015 51%|█████▏    | 596/1160 [15:14<11:47,  1.25s/it]#015 51%|█████▏    | 597/1160 [15:16<11:22,  1.21s/it]#015 52%|█████▏    | 598/1160 [15:17<11:03,  1.18s/it]#015 52%|█████▏    | 599/1160 [15:18<10:42,  1.14s/it]#015 52%|█████▏    | 600/1160 [15:19<10:17,  1.10s/it]#015                                                  #015#015 52%|█████▏    | 600/1160 [15:19<10:17,  1.10s/it]#015 52%|█████▏    | 601/1160 [15:20<09:55,  1.06s/it]#015 52%|█████▏    | 602/1160 [15:21<09:32,  1.03s/it]#015 52%|█████▏    | 603/1160 [15:21<09:03,  1.02it/s]#015 52%|█████▏    | 604/1160 [15:22<08:37,  1.07it/s]#015 52%|█████▏    | 605/1160 [15:23<08:09,  1.13it/s]#015 52%|█████▏    | 606/1160 [15:24<07:30,  1.23it/s]#015 52%|█████▏    | 607/1160 [15:24<06:47,  1.36it/s]#015 52%|█████▏    | 608/1160 [15:25<05:55,  1.55it/s]#015 52%|█████▎    | 609/1160 [15:30<17:57,  1.96s/it]#015 53%|█████▎    | 610/1160 [15:33<20:25,  2.23s/it]#015 53%|█████▎    | 611/1160 [15:35<20:33,  2.25s/it]#015 53%|█████▎    | 612/1160 [15:37<20:13,  2.21s/it]#015                                                  #015#015 53%|█████▎    | 612/1160 [15:37<20:13,  2.21s/it]#015 53%|█████▎    | 613/1160 [15:39<19:20,  2.12s/it]#015 53%|█████▎    | 614/1160 [15:41<17:57,  1.97s/it]#015 53%|█████▎    | 615/1160 [15:42<16:52,  1.86s/it]#015 53%|█████▎    | 616/1160 [15:44<15:48,  1.74s/it]#015 53%|█████▎    | 617/1160 [15:45<14:49,  1.64s/it]#015 53%|█████▎    | 618/1160 [15:46<14:10,  1.57s/it]#015 53%|█████▎    | 619/1160 [15:48<13:26,  1.49s/it]#015 53%|█████▎    | 620/1160 [15:49<12:47,  1.42s/it]#015 54%|█████▎    | 621/1160 [15:50<12:23,  1.38s/it]#015 54%|█████▎    | 622/1160 [15:52<12:04,  1.35s/it]#015 54%|█████▎    | 623/1160 [15:53<11:40,  1.31s/it]#015 54%|█████▍    | 624/1160 [15:54<11:15,  1.26s/it]#015                                                  #015#015 54%|█████▍    | 624/1160 [15:54<11:15,  1.26s/it]#015 54%|█████▍    | 625/1160 [15:55<10:52,  1.22s/it]#015 54%|█████▍    | 626/1160 [15:56<10:33,  1.19s/it]#015 54%|█████▍    | 627/1160 [15:57<10:11,  1.15s/it]#015 54%|█████▍    | 628/1160 [15:58<09:48,  1.11s/it]#015 54%|█████▍    | 629/1160 [15:59<09:25,  1.07s/it]#015 54%|█████▍    | 630/1160 [16:00<09:04,  1.03s/it]#015 54%|█████▍    | 631/1160 [16:01<08:39,  1.02it/s]#015 54%|█████▍    | 632/1160 [16:02<08:13,  1.07it/s]#015 55%|█████▍    | 633/1160 [16:03<07:43,  1.14it/s]#015 55%|█████▍    | 634/1160 [16:03<07:16,  1.21it/s]#015 55%|█████▍    | 635/1160 [16:04<06:36,  1.32it/s]#015 55%|█████▍    | 636/1160 [16:04<05:52,  1.49it/s]#015                                                  #015#015 55%|█████▍    | 636/1160 [16:04<05:52,  1.49it/s]#015 55%|█████▍    | 637/1160 [16:10<19:01,  2.18s/it]#015 55%|█████▌    | 638/1160 [16:13<21:45,  2.50s/it]#015 55%|█████▌    | 639/1160 [16:16<21:23,  2.46s/it]#015 55%|█████▌    | 640/1160 [16:18<20:28,  2.36s/it]#015 55%|█████▌    | 641/1160 [16:20<19:14,  2.22s/it]#015 55%|█████▌    | 642/1160 [16:21<17:39,  2.05s/it]#015 55%|█████▌    | 643/1160 [16:23<16:23,  1.90s/it]#015 56%|█████▌    | 644/1160 [16:24<15:12,  1.77s/it]#015 56%|█████▌    | 645/1160 [16:26<14:18,  1.67s/it]#015 56%|█████▌    | 646/1160 [16:27<13:28,  1.57s/it]#015 56%|█████▌    | 647/1160 [16:28<12:42,  1.49s/it]#015 56%|█████▌    | 648/1160 [16:30<12:03,  1.41s/it]#015                                                  #015#015 56%|█████▌    | 648/1160 [16:30<12:03,  1.41s/it]#015 56%|█████▌    | 649/1160 [16:31<11:42,  1.38s/it]#015 56%|█████▌    | 650/1160 [16:32<11:15,  1.32s/it]#015 56%|█████▌    | 651/1160 [16:33<10:49,  1.28s/it]#015 56%|█████▌    | 652/1160 [16:34<10:25,  1.23s/it]#015 56%|█████▋    | 653/1160 [16:36<10:06,  1.20s/it]#015 56%|█████▋    | 654/1160 [16:37<09:50,  1.17s/it]#015 56%|█████▋    | 655/1160 [16:38<09:33,  1.14s/it]#015 57%|█████▋    | 656/1160 [16:39<09:09,  1.09s/it]#015 57%|█████▋    | 657/1160 [16:40<08:45,  1.05s/it]#015 57%|█████▋    | 658/1160 [16:40<08:19,  1.01it/s]#015 57%|█████▋    | 659/1160 [16:41<07:53,  1.06it/s]#015 57%|█████▋    | 660/1160 [16:42<07:26,  1.12it/s]#015                                                  #015#015 57%|█████▋    | 660/1160 [16:42<07:26,  1.12it/s]#015 57%|█████▋    | 661/1160 [16:43<07:02,  1.18it/s]#015 57%|█████▋    | 662/1160 [16:43<06:32,  1.27it/s]#015 57%|█████▋    | 663/1160 [16:44<05:53,  1.41it/s]#015 57%|█████▋    | 664/1160 [16:44<05:09,  1.60it/s]#015 57%|█████▋    | 665/1160 [16:50<17:43,  2.15s/it]#015 57%|█████▋    | 666/1160 [16:53<19:46,  2.40s/it]#015 57%|█████▊    | 667/1160 [16:55<19:20,  2.35s/it]#015 58%|█████▊    | 668/1160 [16:57<18:20,  2.24s/it]#015 58%|█████▊    | 669/1160 [16:59<17:12,  2.10s/it]#015 58%|█████▊    | 670/1160 [17:01<16:01,  1.96s/it]#015 58%|█████▊    | 671/1160 [17:02<15:04,  1.85s/it]#015 58%|█████▊    | 672/1160 [17:04<14:07,  1.74s/it]#015                                                  #015#015 58%|█████▊    | 672/1160 [17:04<14:07,  1.74s/it]#015 58%|█████▊    | 673/1160 [17:05<13:14,  1.63s/it]#015 58%|█████▊    | 674/1160 [17:07<12:35,  1.56s/it]#015 58%|█████▊    | 675/1160 [17:08<11:57,  1.48s/it]#015 58%|█████▊    | 676/1160 [17:09<11:22,  1.41s/it]#015 58%|█████▊    | 677/1160 [17:10<10:58,  1.36s/it]#015 58%|█████▊    | 678/1160 [17:12<10:37,  1.32s/it]#015 59%|█████▊    | 679/1160 [17:13<10:12,  1.27s/it]#015 59%|█████▊    | 680/1160 [17:14<09:50,  1.23s/it]#015 59%|█████▊    | 681/1160 [17:15<09:32,  1.19s/it]#015 59%|█████▉    | 682/1160 [17:16<09:14,  1.16s/it]#015 59%|█████▉    | 683/1160 [17:17<08:51,  1.12s/it]#015 59%|█████▉    | 684/1160 [17:18<08:29,  1.07s/it]#015                                                  #015#015 59%|█████▉    | 684/1160 [17:18<08:29,  1.07s/it]#015 59%|█████▉    | 685/1160 [17:19<08:10,  1.03s/it]#015 59%|█████▉    | 686/1160 [17:20<07:45,  1.02it/s]#015 59%|█████▉    | 687/1160 [17:21<07:20,  1.07it/s]#015 59%|█████▉    | 688/1160 [17:21<06:54,  1.14it/s]#015 59%|█████▉    | 689/1160 [17:22<06:30,  1.21it/s]#015 59%|█████▉    | 690/1160 [17:23<06:00,  1.30it/s]#015 60%|█████▉    | 691/1160 [17:23<05:26,  1.44it/s]#015 60%|█████▉    | 692/1160 [17:24<04:46,  1.64it/s]#015 60%|█████▉    | 693/1160 [17:27<11:32,  1.48s/it]#015 60%|█████▉    | 694/1160 [17:29<11:27,  1.48s/it]#015 60%|█████▉    | 695/1160 [17:30<10:32,  1.36s/it]#015 60%|██████    | 696/1160 [17:30<07:51,  1.02s/it]#015                                                  #015#015 60%|██████    | 696/1160 [17:30<07:51,  1.02s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7674, 'grad_norm': 4.770938873291016, 'learning_rate': 2.604166666666667e-05, 'epoch': 5.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8317, 'grad_norm': 11.06684684753418, 'learning_rate': 2.5416666666666667e-05, 'epoch': 5.79}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8301, 'grad_norm': 4.560700416564941, 'learning_rate': 2.479166666666667e-05, 'epoch': 5.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7848, 'grad_norm': 15.717187881469727, 'learning_rate': 2.4166666666666667e-05, 'epoch': 6.0}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 60%|██████    | 696/1160 [17:41<07:51,  1.02s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8869046568870544, 'eval_accuracy': 0.6555555555555556, 'eval_class_averaged_accuracy': 0.44127588352470754, 'eval_macro_f1': 0.446273214299546, 'eval_global_f1': 0.6555555555555556, 'eval_class_weighted_f1': 0.6427399573620066, 'eval_runtime': 10.7488, 'eval_samples_per_second': 25.119, 'eval_steps_per_second': 1.302, 'epoch': 6.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7107, 'grad_norm': 6.67836856842041, 'learning_rate': 2.354166666666667e-05, 'epoch': 6.1}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7002, 'grad_norm': 9.353055953979492, 'learning_rate': 2.2916666666666667e-05, 'epoch': 6.21}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8368, 'grad_norm': 7.091604232788086, 'learning_rate': 2.229166666666667e-05, 'epoch': 6.31}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8409, 'grad_norm': 9.964533805847168, 'learning_rate': 2.1666666666666667e-05, 'epoch': 6.41}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8271, 'grad_norm': 13.722021102905273, 'learning_rate': 2.104166666666667e-05, 'epoch': 6.52}\u001b[0m\n",
      "\u001b[34m{'loss': 0.722, 'grad_norm': 10.338919639587402, 'learning_rate': 2.0416666666666667e-05, 'epoch': 6.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6208, 'grad_norm': 6.077561855316162, 'learning_rate': 1.9791666666666665e-05, 'epoch': 6.72}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8581, 'grad_norm': 12.634814262390137, 'learning_rate': 1.9166666666666667e-05, 'epoch': 6.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6667, 'grad_norm': 7.3484697341918945, 'learning_rate': 1.854166666666667e-05, 'epoch': 6.93}\u001b[0m\n",
      "\u001b[34m#015 60%|██████    | 697/1160 [17:47<45:03,  5.84s/it]#015 60%|██████    | 698/1160 [17:50<37:52,  4.92s/it]#015 60%|██████    | 699/1160 [17:52<31:37,  4.12s/it]#015 60%|██████    | 700/1160 [17:54<26:34,  3.47s/it]#015 60%|██████    | 701/1160 [17:56<22:41,  2.97s/it]#015 61%|██████    | 702/1160 [17:58<19:40,  2.58s/it]#015 61%|██████    | 703/1160 [17:59<17:21,  2.28s/it]#015 61%|██████    | 704/1160 [18:01<15:28,  2.04s/it]#015 61%|██████    | 705/1160 [18:02<14:00,  1.85s/it]#015 61%|██████    | 706/1160 [18:03<13:00,  1.72s/it]#015 61%|██████    | 707/1160 [18:05<12:03,  1.60s/it]#015 61%|██████    | 708/1160 [18:06<11:16,  1.50s/it]#015                                                  #015#015 61%|██████    | 708/1160 [18:06<11:16,  1.50s/it]#015 61%|██████    | 709/1160 [18:07<10:45,  1.43s/it]#015 61%|██████    | 710/1160 [18:08<10:16,  1.37s/it]#015 61%|██████▏   | 711/1160 [18:10<09:49,  1.31s/it]#015 61%|██████▏   | 712/1160 [18:11<09:25,  1.26s/it]#015 61%|██████▏   | 713/1160 [18:12<09:04,  1.22s/it]#015 62%|██████▏   | 714/1160 [18:13<08:48,  1.18s/it]#015 62%|██████▏   | 715/1160 [18:14<08:31,  1.15s/it]#015 62%|██████▏   | 716/1160 [18:15<08:11,  1.11s/it]#015 62%|██████▏   | 717/1160 [18:16<07:52,  1.07s/it]#015 62%|██████▏   | 718/1160 [18:17<07:35,  1.03s/it]#015 62%|██████▏   | 719/1160 [18:18<07:13,  1.02it/s]#015 62%|██████▏   | 720/1160 [18:19<06:49,  1.07it/s]#015                                                  #015#015 62%|██████▏   | 720/1160 [18:19<06:49,  1.07it/s]#015 62%|██████▏   | 721/1160 [18:19<06:24,  1.14it/s]#015 62%|██████▏   | 722/1160 [18:20<06:01,  1.21it/s]#015 62%|██████▏   | 723/1160 [18:21<05:30,  1.32it/s]#015 62%|██████▏   | 724/1160 [18:21<04:52,  1.49it/s]#015 62%|██████▎   | 725/1160 [18:27<15:47,  2.18s/it]#015 63%|██████▎   | 726/1160 [18:30<17:26,  2.41s/it]#015 63%|██████▎   | 727/1160 [18:32<17:33,  2.43s/it]#015 63%|██████▎   | 728/1160 [18:34<16:45,  2.33s/it]#015 63%|██████▎   | 729/1160 [18:36<15:42,  2.19s/it]#015 63%|██████▎   | 730/1160 [18:38<14:34,  2.03s/it]#015 63%|██████▎   | 731/1160 [18:40<13:35,  1.90s/it]#015 63%|██████▎   | 732/1160 [18:41<12:35,  1.77s/it]#015                                                  #015#015 63%|██████▎   | 732/1160 [18:41<12:35,  1.77s/it]#015 63%|██████▎   | 733/1160 [18:42<11:49,  1.66s/it]#015 63%|██████▎   | 734/1160 [18:44<11:16,  1.59s/it]#015 63%|██████▎   | 735/1160 [18:45<10:40,  1.51s/it]#015 63%|██████▎   | 736/1160 [18:46<10:08,  1.43s/it]#015 64%|██████▎   | 737/1160 [18:48<09:45,  1.38s/it]#015 64%|██████▎   | 738/1160 [18:49<09:25,  1.34s/it]#015 64%|██████▎   | 739/1160 [18:50<09:03,  1.29s/it]#015 64%|██████▍   | 740/1160 [18:51<08:41,  1.24s/it]#015 64%|██████▍   | 741/1160 [18:52<08:23,  1.20s/it]#015 64%|██████▍   | 742/1160 [18:53<08:10,  1.17s/it]#015 64%|██████▍   | 743/1160 [18:55<07:51,  1.13s/it]#015 64%|██████▍   | 744/1160 [18:56<07:34,  1.09s/it]#015                                                  #015#015 64%|██████▍   | 744/1160 [18:56<07:34,  1.09s/it]#015 64%|██████▍   | 745/1160 [18:56<07:18,  1.06s/it]#015 64%|██████▍   | 746/1160 [18:57<07:03,  1.02s/it]#015 64%|██████▍   | 747/1160 [18:58<06:43,  1.02it/s]#015 64%|██████▍   | 748/1160 [18:59<06:23,  1.08it/s]#015 65%|██████▍   | 749/1160 [19:00<05:57,  1.15it/s]#015 65%|██████▍   | 750/1160 [19:00<05:28,  1.25it/s]#015 65%|██████▍   | 751/1160 [19:01<04:54,  1.39it/s]#015 65%|██████▍   | 752/1160 [19:01<04:17,  1.59it/s]#015 65%|██████▍   | 753/1160 [19:07<14:33,  2.15s/it]#015 65%|██████▌   | 754/1160 [19:10<16:15,  2.40s/it]#015 65%|██████▌   | 755/1160 [19:12<16:10,  2.40s/it]#015 65%|██████▌   | 756/1160 [19:15<15:21,  2.28s/it]#015                                                  #015#015 65%|██████▌   | 756/1160 [19:15<15:21,  2.28s/it]#015 65%|██████▌   | 757/1160 [19:16<14:42,  2.19s/it]#015 65%|██████▌   | 758/1160 [19:18<13:47,  2.06s/it]#015 65%|██████▌   | 759/1160 [19:20<12:44,  1.91s/it]#015 66%|██████▌   | 760/1160 [19:21<11:57,  1.79s/it]#015 66%|██████▌   | 761/1160 [19:23<11:06,  1.67s/it]#015 66%|██████▌   | 762/1160 [19:24<10:30,  1.58s/it]#015 66%|██████▌   | 763/1160 [19:25<09:54,  1.50s/it]#015 66%|██████▌   | 764/1160 [19:27<09:24,  1.43s/it]#015 66%|██████▌   | 765/1160 [19:28<09:04,  1.38s/it]#015 66%|██████▌   | 766/1160 [19:29<08:43,  1.33s/it]#015 66%|██████▌   | 767/1160 [19:30<08:24,  1.28s/it]#015 66%|██████▌   | 768/1160 [19:31<08:04,  1.24s/it]#015                                                  #015#015 66%|██████▌   | 768/1160 [19:31<08:04,  1.24s/it]#015 66%|██████▋   | 769/1160 [19:33<07:50,  1.20s/it]#015 66%|██████▋   | 770/1160 [19:34<07:37,  1.17s/it]#015 66%|██████▋   | 771/1160 [19:35<07:19,  1.13s/it]#015 67%|██████▋   | 772/1160 [19:36<07:02,  1.09s/it]#015 67%|██████▋   | 773/1160 [19:37<06:46,  1.05s/it]#015 67%|██████▋   | 774/1160 [19:38<06:26,  1.00s/it]#015 67%|██████▋   | 775/1160 [19:38<06:08,  1.05it/s]#015 67%|██████▋   | 776/1160 [19:39<05:49,  1.10it/s]#015 67%|██████▋   | 777/1160 [19:40<05:28,  1.16it/s]#015 67%|██████▋   | 778/1160 [19:41<05:01,  1.27it/s]#015 67%|██████▋   | 779/1160 [19:41<04:32,  1.40it/s]#015 67%|██████▋   | 780/1160 [19:42<04:02,  1.57it/s]#015                                                  #015#015 67%|██████▋   | 780/1160 [19:42<04:02,  1.57it/s]#015 67%|██████▋   | 781/1160 [19:47<13:37,  2.16s/it]#015 67%|██████▋   | 782/1160 [19:50<15:11,  2.41s/it]#015 68%|██████▊   | 783/1160 [19:53<14:59,  2.38s/it]#015 68%|██████▊   | 784/1160 [19:55<14:23,  2.30s/it]#015 68%|██████▊   | 785/1160 [19:56<13:25,  2.15s/it]#015 68%|██████▊   | 786/1160 [19:58<12:22,  1.98s/it]#015 68%|██████▊   | 787/1160 [20:00<11:35,  1.87s/it]#015 68%|██████▊   | 788/1160 [20:01<10:45,  1.74s/it]#015 68%|██████▊   | 789/1160 [20:03<10:08,  1.64s/it]#015 68%|██████▊   | 790/1160 [20:04<09:37,  1.56s/it]#015 68%|██████▊   | 791/1160 [20:05<09:09,  1.49s/it]#015 68%|██████▊   | 792/1160 [20:06<08:41,  1.42s/it]#015                                                  #015#015 68%|██████▊   | 792/1160 [20:06<08:41,  1.42s/it]#015 68%|██████▊   | 793/1160 [20:08<08:24,  1.37s/it]#015 68%|██████▊   | 794/1160 [20:09<08:04,  1.32s/it]#015 69%|██████▊   | 795/1160 [20:10<07:45,  1.27s/it]#015 69%|██████▊   | 796/1160 [20:11<07:26,  1.23s/it]#015 69%|██████▊   | 797/1160 [20:12<07:12,  1.19s/it]#015 69%|██████▉   | 798/1160 [20:13<06:57,  1.15s/it]#015 69%|██████▉   | 799/1160 [20:14<06:38,  1.10s/it]#015 69%|██████▉   | 800/1160 [20:15<06:22,  1.06s/it]#015 69%|██████▉   | 801/1160 [20:16<06:03,  1.01s/it]#015 69%|██████▉   | 802/1160 [20:17<05:46,  1.03it/s]#015 69%|██████▉   | 803/1160 [20:18<05:29,  1.08it/s]#015 69%|██████▉   | 804/1160 [20:19<05:10,  1.15it/s]#015                                                  #015#015 69%|██████▉   | 804/1160 [20:19<05:10,  1.15it/s]#015 69%|██████▉   | 805/1160 [20:19<04:54,  1.20it/s]#015 69%|██████▉   | 806/1160 [20:20<04:33,  1.30it/s]#015 70%|██████▉   | 807/1160 [20:21<04:08,  1.42it/s]#015 70%|██████▉   | 808/1160 [20:21<03:41,  1.59it/s]#015 70%|██████▉   | 809/1160 [20:25<10:20,  1.77s/it]#015 70%|██████▉   | 810/1160 [20:27<09:40,  1.66s/it]#015 70%|██████▉   | 811/1160 [20:28<08:37,  1.48s/it]#015 70%|███████   | 812/1160 [20:28<06:27,  1.11s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 70%|███████   | 812/1160 [20:39<06:27,  1.11s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8953897953033447, 'eval_accuracy': 0.6407407407407407, 'eval_class_averaged_accuracy': 0.40958930728200504, 'eval_macro_f1': 0.4202771001530012, 'eval_global_f1': 0.6407407407407407, 'eval_class_weighted_f1': 0.6153774025487997, 'eval_runtime': 10.7432, 'eval_samples_per_second': 25.132, 'eval_steps_per_second': 1.303, 'epoch': 7.0}\u001b[0m\n",
      "\u001b[34m#015 70%|███████   | 813/1160 [20:45<34:05,  5.90s/it]#015 70%|███████   | 814/1160 [20:48<28:36,  4.96s/it]#015 70%|███████   | 815/1160 [20:50<23:39,  4.11s/it]#015 70%|███████   | 816/1160 [20:52<19:51,  3.46s/it]#015                                                  #015#015 70%|███████   | 816/1160 [20:52<19:51,  3.46s/it]#015 70%|███████   | 817/1160 [20:54<16:52,  2.95s/it]#015 71%|███████   | 818/1160 [20:55<14:26,  2.53s/it]#015 71%|███████   | 819/1160 [20:57<12:42,  2.24s/it]#015 71%|███████   | 820/1160 [20:58<11:19,  2.00s/it]#015 71%|███████   | 821/1160 [21:00<10:20,  1.83s/it]#015 71%|███████   | 822/1160 [21:01<09:30,  1.69s/it]#015 71%|███████   | 823/1160 [21:02<08:49,  1.57s/it]#015 71%|███████   | 824/1160 [21:04<08:15,  1.47s/it]#015 71%|███████   | 825/1160 [21:05<07:54,  1.42s/it]#015 71%|███████   | 826/1160 [21:06<07:34,  1.36s/it]#015 71%|███████▏  | 827/1160 [21:07<07:14,  1.30s/it]#015 71%|███████▏  | 828/1160 [21:09<06:57,  1.26s/it]#015                                                  #015#015 71%|███████▏  | 828/1160 [21:09<06:57,  1.26s/it]#015 71%|███████▏  | 829/1160 [21:10<06:43,  1.22s/it]#015 72%|███████▏  | 830/1160 [21:11<06:32,  1.19s/it]#015 72%|███████▏  | 831/1160 [21:12<06:22,  1.16s/it]#015 72%|███████▏  | 832/1160 [21:13<06:08,  1.12s/it]#015 72%|███████▏  | 833/1160 [21:14<05:54,  1.08s/it]#015 72%|███████▏  | 834/1160 [21:15<05:40,  1.04s/it]#015 72%|███████▏  | 835/1160 [21:16<05:23,  1.01it/s]#015 72%|███████▏  | 836/1160 [21:17<05:03,  1.07it/s]#015 72%|███████▏  | 837/1160 [21:17<04:44,  1.14it/s]#015 72%|███████▏  | 838/1160 [21:18<04:21,  1.23it/s]#015 72%|███████▏  | 839/1160 [21:19<03:53,  1.37it/s]#015 72%|███████▏  | 840/1160 [21:19<03:28,  1.54it/s]#015                                                  #015#015 72%|███████▏  | 840/1160 [21:19<03:28,  1.54it/s]#015 72%|███████▎  | 841/1160 [21:25<11:31,  2.17s/it]#015 73%|███████▎  | 842/1160 [21:28<12:44,  2.40s/it]#015 73%|███████▎  | 843/1160 [21:30<12:57,  2.45s/it]#015 73%|███████▎  | 844/1160 [21:32<12:19,  2.34s/it]#015 73%|███████▎  | 845/1160 [21:34<11:40,  2.22s/it]#015 73%|███████▎  | 846/1160 [21:36<10:50,  2.07s/it]#015 73%|███████▎  | 847/1160 [21:38<10:01,  1.92s/it]#015 73%|███████▎  | 848/1160 [21:39<09:24,  1.81s/it]#015 73%|███████▎  | 849/1160 [21:41<08:48,  1.70s/it]#015 73%|███████▎  | 850/1160 [21:42<08:20,  1.61s/it]#015 73%|███████▎  | 851/1160 [21:43<07:54,  1.54s/it]#015 73%|███████▎  | 852/1160 [21:45<07:26,  1.45s/it]#015                                                  #015#015 73%|███████▎  | 852/1160 [21:45<07:26,  1.45s/it]#015 74%|███████▎  | 853/1160 [21:46<07:09,  1.40s/it]#015 74%|███████▎  | 854/1160 [21:47<06:50,  1.34s/it]#015 74%|███████▎  | 855/1160 [21:48<06:32,  1.29s/it]#015 74%|███████▍  | 856/1160 [21:49<06:15,  1.24s/it]#015 74%|███████▍  | 857/1160 [21:50<06:02,  1.20s/it]#015 74%|███████▍  | 858/1160 [21:51<05:46,  1.15s/it]#015 74%|███████▍  | 859/1160 [21:52<05:30,  1.10s/it]#015 74%|███████▍  | 860/1160 [21:53<05:18,  1.06s/it]#015 74%|███████▍  | 861/1160 [21:54<05:06,  1.02s/it]#015 74%|███████▍  | 862/1160 [21:55<04:51,  1.02it/s]#015 74%|███████▍  | 863/1160 [21:56<04:36,  1.07it/s]#015 74%|███████▍  | 864/1160 [21:57<04:23,  1.12it/s]#015                                                  #015#015 74%|███████▍  | 864/1160 [21:57<04:23,  1.12it/s]#015 75%|███████▍  | 865/1160 [21:58<04:06,  1.20it/s]#015 75%|███████▍  | 866/1160 [21:58<03:45,  1.30it/s]#015 75%|███████▍  | 867/1160 [21:59<03:23,  1.44it/s]#015 75%|███████▍  | 868/1160 [21:59<02:59,  1.63it/s]#015 75%|███████▍  | 869/1160 [22:05<10:21,  2.13s/it]#015 75%|███████▌  | 870/1160 [22:08<11:34,  2.39s/it]#015 75%|███████▌  | 871/1160 [22:10<11:26,  2.38s/it]#015 75%|███████▌  | 872/1160 [22:12<11:02,  2.30s/it]#015 75%|███████▌  | 873/1160 [22:14<10:26,  2.18s/it]#015 75%|███████▌  | 874/1160 [22:16<09:47,  2.05s/it]#015 75%|███████▌  | 875/1160 [22:17<09:02,  1.90s/it]#015 76%|███████▌  | 876/1160 [22:19<08:27,  1.79s/it]#015                                                  #015#015 76%|███████▌  | 876/1160 [22:19<08:27,  1.79s/it]#015 76%|███████▌  | 877/1160 [22:20<07:57,  1.69s/it]#015 76%|███████▌  | 878/1160 [22:22<07:32,  1.60s/it]#015 76%|███████▌  | 879/1160 [22:23<07:06,  1.52s/it]#015 76%|███████▌  | 880/1160 [22:24<06:43,  1.44s/it]#015 76%|███████▌  | 881/1160 [22:26<06:27,  1.39s/it]#015 76%|███████▌  | 882/1160 [22:27<06:13,  1.34s/it]#015 76%|███████▌  | 883/1160 [22:28<06:00,  1.30s/it]#015 76%|███████▌  | 884/1160 [22:29<05:44,  1.25s/it]#015 76%|███████▋  | 885/1160 [22:30<05:32,  1.21s/it]#015 76%|███████▋  | 886/1160 [22:31<05:22,  1.18s/it]#015 76%|███████▋  | 887/1160 [22:33<05:11,  1.14s/it]#015 77%|███████▋  | 888/1160 [22:33<04:57,  1.09s/it]#015                                                  #015#015 77%|███████▋  | 888/1160 [22:34<04:57,  1.09s/it]#015 77%|███████▋  | 889/1160 [22:34<04:46,  1.06s/it]#015 77%|███████▋  | 890/1160 [22:35<04:31,  1.00s/it]#015 77%|███████▋  | 891/1160 [22:36<04:15,  1.05it/s]#015 77%|███████▋  | 892/1160 [22:37<04:00,  1.12it/s]#015 77%|███████▋  | 893/1160 [22:38<03:46,  1.18it/s]#015 77%|███████▋  | 894/1160 [22:38<03:30,  1.26it/s]#015 77%|███████▋  | 895/1160 [22:39<03:12,  1.38it/s]#015 77%|███████▋  | 896/1160 [22:39<02:49,  1.55it/s]#015 77%|███████▋  | 897/1160 [22:45<09:29,  2.17s/it]#015 77%|███████▋  | 898/1160 [22:48<10:29,  2.40s/it]#015 78%|███████▊  | 899/1160 [22:51<10:33,  2.43s/it]#015 78%|███████▊  | 900/1160 [22:53<10:08,  2.34s/it]#015                                                  #015#015 78%|███████▊  | 900/1160 [22:53<10:08,  2.34s/it]#015 78%|███████▊  | 901/1160 [22:55<09:36,  2.23s/it]#015 78%|███████▊  | 902/1160 [22:56<08:48,  2.05s/it]#015 78%|███████▊  | 903/1160 [22:58<08:10,  1.91s/it]#015 78%|███████▊  | 904/1160 [22:59<07:35,  1.78s/it]#015 78%|███████▊  | 905/1160 [23:01<07:04,  1.67s/it]#015 78%|███████▊  | 906/1160 [23:02<06:44,  1.59s/it]#015 78%|███████▊  | 907/1160 [23:03<06:21,  1.51s/it]#015 78%|███████▊  | 908/1160 [23:05<06:01,  1.44s/it]#015 78%|███████▊  | 909/1160 [23:06<05:48,  1.39s/it]#015 78%|███████▊  | 910/1160 [23:07<05:35,  1.34s/it]#015 79%|███████▊  | 911/1160 [23:08<05:21,  1.29s/it]#015 79%|███████▊  | 912/1160 [23:10<05:08,  1.24s/it]#015                                                  #015#015 79%|███████▊  | 912/1160 [23:10<05:08,  1.24s/it]#015 79%|███████▊  | 913/1160 [23:11<04:58,  1.21s/it]#015 79%|███████▉  | 914/1160 [23:12<04:49,  1.18s/it]#015 79%|███████▉  | 915/1160 [23:13<04:38,  1.14s/it]#015 79%|███████▉  | 916/1160 [23:14<04:26,  1.09s/it]#015 79%|███████▉  | 917/1160 [23:15<04:16,  1.06s/it]#015 79%|███████▉  | 918/1160 [23:16<04:07,  1.02s/it]#015 79%|███████▉  | 919/1160 [23:17<03:54,  1.03it/s]#015 79%|███████▉  | 920/1160 [23:17<03:41,  1.08it/s]#015 79%|███████▉  | 921/1160 [23:18<03:28,  1.14it/s]#015 79%|███████▉  | 922/1160 [23:19<03:16,  1.21it/s]#015 80%|███████▉  | 923/1160 [23:19<02:56,  1.34it/s]#015 80%|███████▉  | 924/1160 [23:20<02:35,  1.52it/s]#015                                                  #015#015 80%|███████▉  | 924/1160 [23:20<02:35,  1.52it/s]#015 80%|███████▉  | 925/1160 [23:23<05:46,  1.47s/it]#015 80%|███████▉  | 926/1160 [23:25<05:40,  1.46s/it]#015 80%|███████▉  | 927/1160 [23:26<05:05,  1.31s/it]#015 80%|████████  | 928/1160 [23:26<03:49,  1.01it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7243, 'grad_norm': 6.65165901184082, 'learning_rate': 1.7916666666666667e-05, 'epoch': 7.03}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6762, 'grad_norm': 6.433553218841553, 'learning_rate': 1.7291666666666666e-05, 'epoch': 7.14}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6563, 'grad_norm': 11.13778018951416, 'learning_rate': 1.6666666666666667e-05, 'epoch': 7.24}\u001b[0m\n",
      "\u001b[34m{'loss': 0.722, 'grad_norm': 6.03223180770874, 'learning_rate': 1.604166666666667e-05, 'epoch': 7.34}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5937, 'grad_norm': 8.371694564819336, 'learning_rate': 1.5416666666666668e-05, 'epoch': 7.45}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6636, 'grad_norm': 10.494392395019531, 'learning_rate': 1.4791666666666668e-05, 'epoch': 7.55}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6405, 'grad_norm': 9.05643081665039, 'learning_rate': 1.4166666666666668e-05, 'epoch': 7.66}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6654, 'grad_norm': 9.902438163757324, 'learning_rate': 1.3541666666666666e-05, 'epoch': 7.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6663, 'grad_norm': 7.8953046798706055, 'learning_rate': 1.2916666666666668e-05, 'epoch': 7.86}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6445, 'grad_norm': 7.157031536102295, 'learning_rate': 1.2291666666666666e-05, 'epoch': 7.97}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 80%|████████  | 928/1160 [23:37<03:49,  1.01it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8626336455345154, 'eval_accuracy': 0.662962962962963, 'eval_class_averaged_accuracy': 0.44855729623715473, 'eval_macro_f1': 0.4559133242443917, 'eval_global_f1': 0.662962962962963, 'eval_class_weighted_f1': 0.6482321491972582, 'eval_runtime': 10.7656, 'eval_samples_per_second': 25.08, 'eval_steps_per_second': 1.3, 'epoch': 8.0}\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 929/1160 [23:43<22:25,  5.83s/it]#015 80%|████████  | 930/1160 [23:46<19:01,  4.96s/it]#015 80%|████████  | 931/1160 [23:48<15:57,  4.18s/it]#015 80%|████████  | 932/1160 [23:50<13:27,  3.54s/it]#015 80%|████████  | 933/1160 [23:52<11:30,  3.04s/it]#015 81%|████████  | 934/1160 [23:54<09:54,  2.63s/it]#015 81%|████████  | 935/1160 [23:55<08:42,  2.32s/it]#015 81%|████████  | 936/1160 [23:57<07:42,  2.06s/it]#015                                                  #015#015 81%|████████  | 936/1160 [23:57<07:42,  2.06s/it]#015 81%|████████  | 937/1160 [23:58<06:58,  1.88s/it]#015 81%|████████  | 938/1160 [24:00<06:22,  1.72s/it]#015 81%|████████  | 939/1160 [24:01<05:52,  1.59s/it]#015 81%|████████  | 940/1160 [24:02<05:29,  1.50s/it]#015 81%|████████  | 941/1160 [24:04<05:13,  1.43s/it]#015 81%|████████  | 942/1160 [24:05<04:58,  1.37s/it]#015 81%|████████▏ | 943/1160 [24:06<04:44,  1.31s/it]#015 81%|████████▏ | 944/1160 [24:07<04:31,  1.26s/it]#015 81%|████████▏ | 945/1160 [24:08<04:21,  1.22s/it]#015 82%|████████▏ | 946/1160 [24:09<04:13,  1.19s/it]#015 82%|████████▏ | 947/1160 [24:10<04:04,  1.15s/it]#015 82%|████████▏ | 948/1160 [24:11<03:54,  1.11s/it]#015                                                  #015#015 82%|████████▏ | 948/1160 [24:11<03:54,  1.11s/it]#015 82%|████████▏ | 949/1160 [24:12<03:45,  1.07s/it]#015 82%|████████▏ | 950/1160 [24:13<03:35,  1.03s/it]#015 82%|████████▏ | 951/1160 [24:14<03:23,  1.03it/s]#015 82%|████████▏ | 952/1160 [24:15<03:11,  1.09it/s]#015 82%|████████▏ | 953/1160 [24:16<02:59,  1.15it/s]#015 82%|████████▏ | 954/1160 [24:16<02:46,  1.24it/s]#015 82%|████████▏ | 955/1160 [24:17<02:29,  1.37it/s]#015 82%|████████▏ | 956/1160 [24:17<02:12,  1.54it/s]#015 82%|████████▎ | 957/1160 [24:23<07:06,  2.10s/it]#015 83%|████████▎ | 958/1160 [24:26<07:43,  2.30s/it]#015 83%|████████▎ | 959/1160 [24:28<07:49,  2.33s/it]#015 83%|████████▎ | 960/1160 [24:30<07:37,  2.29s/it]#015                                                  #015#015 83%|████████▎ | 960/1160 [24:30<07:37,  2.29s/it]#015 83%|████████▎ | 961/1160 [24:32<07:16,  2.19s/it]#015 83%|████████▎ | 962/1160 [24:34<06:54,  2.09s/it]#015 83%|████████▎ | 963/1160 [24:36<06:25,  1.96s/it]#015 83%|████████▎ | 964/1160 [24:37<05:59,  1.83s/it]#015 83%|████████▎ | 965/1160 [24:39<05:43,  1.76s/it]#015 83%|████████▎ | 966/1160 [24:40<05:24,  1.67s/it]#015 83%|████████▎ | 967/1160 [24:42<05:07,  1.59s/it]#015 83%|████████▎ | 968/1160 [24:43<04:50,  1.51s/it]#015 84%|████████▎ | 969/1160 [24:44<04:34,  1.44s/it]#015 84%|████████▎ | 970/1160 [24:46<04:24,  1.39s/it]#015 84%|████████▎ | 971/1160 [24:47<04:12,  1.33s/it]#015 84%|████████▍ | 972/1160 [24:48<04:01,  1.29s/it]#015                                                  #015#015 84%|████████▍ | 972/1160 [24:48<04:01,  1.29s/it]#015 84%|████████▍ | 973/1160 [24:49<03:51,  1.24s/it]#015 84%|████████▍ | 974/1160 [24:50<03:43,  1.20s/it]#015 84%|████████▍ | 975/1160 [24:51<03:37,  1.17s/it]#015 84%|████████▍ | 976/1160 [24:52<03:29,  1.14s/it]#015 84%|████████▍ | 977/1160 [24:53<03:20,  1.09s/it]#015 84%|████████▍ | 978/1160 [24:54<03:12,  1.06s/it]#015 84%|████████▍ | 979/1160 [24:55<03:01,  1.00s/it]#015 84%|████████▍ | 980/1160 [24:56<02:51,  1.05it/s]#015 85%|████████▍ | 981/1160 [24:57<02:39,  1.12it/s]#015 85%|████████▍ | 982/1160 [24:57<02:28,  1.20it/s]#015 85%|████████▍ | 983/1160 [24:58<02:13,  1.33it/s]#015 85%|████████▍ | 984/1160 [24:58<01:56,  1.51it/s]#015                                                  #015#015 85%|████████▍ | 984/1160 [24:59<01:56,  1.51it/s]#015 85%|████████▍ | 985/1160 [25:04<06:20,  2.18s/it]#015 85%|████████▌ | 986/1160 [25:07<06:53,  2.38s/it]#015 85%|████████▌ | 987/1160 [25:09<06:50,  2.37s/it]#015 85%|████████▌ | 988/1160 [25:11<06:27,  2.26s/it]#015 85%|████████▌ | 989/1160 [25:13<06:00,  2.11s/it]#015 85%|████████▌ | 990/1160 [25:15<05:29,  1.94s/it]#015 85%|████████▌ | 991/1160 [25:16<05:04,  1.80s/it]#015 86%|████████▌ | 992/1160 [25:18<04:42,  1.68s/it]#015 86%|████████▌ | 993/1160 [25:19<04:27,  1.60s/it]#015 86%|████████▌ | 994/1160 [25:20<04:13,  1.53s/it]#015 86%|████████▌ | 995/1160 [25:22<03:58,  1.45s/it]#015 86%|████████▌ | 996/1160 [25:23<03:48,  1.39s/it]#015                                                  #015#015 86%|████████▌ | 996/1160 [25:23<03:48,  1.39s/it]#015 86%|████████▌ | 997/1160 [25:24<03:40,  1.35s/it]#015 86%|████████▌ | 998/1160 [25:25<03:30,  1.30s/it]#015 86%|████████▌ | 999/1160 [25:26<03:21,  1.25s/it]#015 86%|████████▌ | 1000/1160 [25:28<03:13,  1.21s/it]#015 86%|████████▋ | 1001/1160 [25:29<03:07,  1.18s/it]#015 86%|████████▋ | 1002/1160 [25:30<02:59,  1.14s/it]#015 86%|████████▋ | 1003/1160 [25:31<02:51,  1.09s/it]#015 87%|████████▋ | 1004/1160 [25:32<02:45,  1.06s/it]#015 87%|████████▋ | 1005/1160 [25:33<02:38,  1.02s/it]#015 87%|████████▋ | 1006/1160 [25:33<02:30,  1.02it/s]#015 87%|████████▋ | 1007/1160 [25:34<02:22,  1.07it/s]#015 87%|████████▋ | 1008/1160 [25:35<02:15,  1.12it/s]#015                                                   #015#015 87%|████████▋ | 1008/1160 [25:35<02:15,  1.12it/s]#015 87%|████████▋ | 1009/1160 [25:36<02:06,  1.19it/s]#015 87%|████████▋ | 1010/1160 [25:36<01:56,  1.29it/s]#015 87%|████████▋ | 1011/1160 [25:37<01:45,  1.42it/s]#015 87%|████████▋ | 1012/1160 [25:37<01:32,  1.61it/s]#015 87%|████████▋ | 1013/1160 [25:43<05:15,  2.15s/it]#015 87%|████████▋ | 1014/1160 [25:46<05:51,  2.40s/it]#015 88%|████████▊ | 1015/1160 [25:49<05:46,  2.39s/it]#015 88%|████████▊ | 1016/1160 [25:50<05:25,  2.26s/it]#015 88%|████████▊ | 1017/1160 [25:52<04:59,  2.09s/it]#015 88%|████████▊ | 1018/1160 [25:54<04:34,  1.93s/it]#015 88%|████████▊ | 1019/1160 [25:55<04:16,  1.82s/it]#015 88%|████████▊ | 1020/1160 [25:57<03:59,  1.71s/it]#015                                                   #015#015 88%|████████▊ | 1020/1160 [25:57<03:59,  1.71s/it]#015 88%|████████▊ | 1021/1160 [25:58<03:44,  1.62s/it]#015 88%|████████▊ | 1022/1160 [26:00<03:33,  1.55s/it]#015 88%|████████▊ | 1023/1160 [26:01<03:22,  1.48s/it]#015 88%|████████▊ | 1024/1160 [26:02<03:12,  1.41s/it]#015 88%|████████▊ | 1025/1160 [26:03<03:04,  1.37s/it]#015 88%|████████▊ | 1026/1160 [26:05<02:57,  1.33s/it]#015 89%|████████▊ | 1027/1160 [26:06<02:50,  1.28s/it]#015 89%|████████▊ | 1028/1160 [26:07<02:42,  1.23s/it]#015 89%|████████▊ | 1029/1160 [26:08<02:36,  1.19s/it]#015 89%|████████▉ | 1030/1160 [26:09<02:30,  1.16s/it]#015 89%|████████▉ | 1031/1160 [26:10<02:23,  1.12s/it]#015 89%|████████▉ | 1032/1160 [26:11<02:17,  1.07s/it]#015                                                   #015#015 89%|████████▉ | 1032/1160 [26:11<02:17,  1.07s/it]#015 89%|████████▉ | 1033/1160 [26:12<02:11,  1.03s/it]#015 89%|████████▉ | 1034/1160 [26:13<02:04,  1.01it/s]#015 89%|████████▉ | 1035/1160 [26:14<01:58,  1.06it/s]#015 89%|████████▉ | 1036/1160 [26:15<01:52,  1.11it/s]#015 89%|████████▉ | 1037/1160 [26:15<01:44,  1.18it/s]#015 89%|████████▉ | 1038/1160 [26:16<01:35,  1.28it/s]#015 90%|████████▉ | 1039/1160 [26:16<01:25,  1.41it/s]#015 90%|████████▉ | 1040/1160 [26:17<01:16,  1.57it/s]#015 90%|████████▉ | 1041/1160 [26:21<03:08,  1.58s/it]#015 90%|████████▉ | 1042/1160 [26:22<02:59,  1.52s/it]#015 90%|████████▉ | 1043/1160 [26:23<02:38,  1.36s/it]#015 90%|█████████ | 1044/1160 [26:23<01:57,  1.01s/it]#015                                                   #015#015 90%|█████████ | 1044/1160 [26:23<01:57,  1.01s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.636, 'grad_norm': 4.850460052490234, 'learning_rate': 1.1666666666666668e-05, 'epoch': 8.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6586, 'grad_norm': 8.106110572814941, 'learning_rate': 1.1041666666666666e-05, 'epoch': 8.17}\u001b[0m\n",
      "\u001b[34m{'loss': 0.66, 'grad_norm': 2.9818382263183594, 'learning_rate': 1.0416666666666668e-05, 'epoch': 8.28}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6456, 'grad_norm': 7.265944004058838, 'learning_rate': 9.791666666666666e-06, 'epoch': 8.38}\u001b[0m\n",
      "\u001b[34m{'loss': 0.599, 'grad_norm': 16.82126808166504, 'learning_rate': 9.166666666666666e-06, 'epoch': 8.48}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6469, 'grad_norm': 4.857451438903809, 'learning_rate': 8.541666666666666e-06, 'epoch': 8.59}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6038, 'grad_norm': 5.253511428833008, 'learning_rate': 7.916666666666667e-06, 'epoch': 8.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5457, 'grad_norm': 10.543214797973633, 'learning_rate': 7.2916666666666674e-06, 'epoch': 8.79}\u001b[0m\n",
      "\u001b[34m{'loss': 0.643, 'grad_norm': 14.287437438964844, 'learning_rate': 6.666666666666667e-06, 'epoch': 8.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5098, 'grad_norm': 12.680659294128418, 'learning_rate': 6.041666666666667e-06, 'epoch': 9.0}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                   #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 90%|█████████ | 1044/1160 [26:34<01:57,  1.01s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m#015 90%|█████████ | 1045/1160 [26:40<11:12,  5.84s/it]#015 90%|█████████ | 1046/1160 [26:43<09:21,  4.92s/it]#015 90%|█████████ | 1047/1160 [26:45<07:38,  4.06s/it]#015 90%|█████████ | 1048/1160 [26:47<06:20,  3.40s/it]#015 90%|█████████ | 1049/1160 [26:49<05:18,  2.87s/it]#015 91%|█████████ | 1050/1160 [26:50<04:33,  2.49s/it]#015 91%|█████████ | 1051/1160 [26:52<03:57,  2.18s/it]#015 91%|█████████ | 1052/1160 [26:53<03:29,  1.94s/it]#015 91%|█████████ | 1053/1160 [26:54<03:09,  1.77s/it]#015 91%|█████████ | 1054/1160 [26:56<02:53,  1.64s/it]#015 91%|█████████ | 1055/1160 [26:57<02:39,  1.52s/it]#015 91%|█████████ | 1056/1160 [26:58<02:30,  1.45s/it]#015                                                   #015#015 91%|█████████ | 1056/1160 [26:58<02:30,  1.45s/it]#015 91%|█████████ | 1057/1160 [27:00<02:22,  1.38s/it]#015 91%|█████████ | 1058/1160 [27:01<02:15,  1.32s/it]#015 91%|█████████▏| 1059/1160 [27:02<02:07,  1.26s/it]#015 91%|█████████▏| 1060/1160 [27:03<02:02,  1.22s/it]#015 91%|█████████▏| 1061/1160 [27:04<01:57,  1.19s/it]#015 92%|█████████▏| 1062/1160 [27:05<01:51,  1.14s/it]#015 92%|█████████▏| 1063/1160 [27:06<01:46,  1.10s/it]#015 92%|█████████▏| 1064/1160 [27:07<01:41,  1.06s/it]#015 92%|█████████▏| 1065/1160 [27:08<01:36,  1.01s/it]#015 92%|█████████▏| 1066/1160 [27:09<01:30,  1.03it/s]#015 92%|█████████▏| 1067/1160 [27:10<01:26,  1.08it/s]#015 92%|█████████▏| 1068/1160 [27:10<01:20,  1.14it/s]#015                                                   #015#015 92%|█████████▏| 1068/1160 [27:10<01:20,  1.14it/s]#015 92%|█████████▏| 1069/1160 [27:11<01:15,  1.20it/s]#015 92%|█████████▏| 1070/1160 [27:12<01:09,  1.29it/s]#015 92%|█████████▏| 1071/1160 [27:12<01:03,  1.41it/s]#015 92%|█████████▏| 1072/1160 [27:13<00:55,  1.57it/s]#015 92%|█████████▎| 1073/1160 [27:19<03:07,  2.16s/it]#015 93%|█████████▎| 1074/1160 [27:22<03:27,  2.41s/it]#015 93%|█████████▎| 1075/1160 [27:24<03:23,  2.39s/it]#015 93%|█████████▎| 1076/1160 [27:26<03:12,  2.29s/it]#015 93%|█████████▎| 1077/1160 [27:28<03:00,  2.17s/it]#015 93%|█████████▎| 1078/1160 [27:30<02:46,  2.03s/it]#015 93%|█████████▎| 1079/1160 [27:31<02:33,  1.89s/it]#015 93%|█████████▎| 1080/1160 [27:33<02:23,  1.79s/it]#015                                                   #015#015 93%|█████████▎| 1080/1160 [27:33<02:23,  1.79s/it]#015 93%|█████████▎| 1081/1160 [27:34<02:11,  1.67s/it]#015 93%|█████████▎| 1082/1160 [27:35<02:04,  1.60s/it]#015 93%|█████████▎| 1083/1160 [27:37<01:56,  1.51s/it]#015 93%|█████████▎| 1084/1160 [27:38<01:49,  1.44s/it]#015 94%|█████████▎| 1085/1160 [27:39<01:44,  1.39s/it]#015 94%|█████████▎| 1086/1160 [27:41<01:39,  1.34s/it]#015 94%|█████████▎| 1087/1160 [27:42<01:35,  1.31s/it]#015 94%|█████████▍| 1088/1160 [27:43<01:31,  1.27s/it]#015 94%|█████████▍| 1089/1160 [27:44<01:27,  1.23s/it]#015 94%|█████████▍| 1090/1160 [27:45<01:23,  1.19s/it]#015 94%|█████████▍| 1091/1160 [27:46<01:20,  1.17s/it]#015 94%|█████████▍| 1092/1160 [27:47<01:16,  1.12s/it]#015                                                   #015#015 94%|█████████▍| 1092/1160 [27:47<01:16,  1.12s/it]#015 94%|█████████▍| 1093/1160 [27:48<01:12,  1.08s/it]#015 94%|█████████▍| 1094/1160 [27:49<01:09,  1.05s/it]#015 94%|█████████▍| 1095/1160 [27:50<01:04,  1.01it/s]#015 94%|█████████▍| 1096/1160 [27:51<01:00,  1.07it/s]#015 95%|█████████▍| 1097/1160 [27:52<00:55,  1.14it/s]#015 95%|█████████▍| 1098/1160 [27:52<00:50,  1.24it/s]#015 95%|█████████▍| 1099/1160 [27:53<00:44,  1.38it/s]#015 95%|█████████▍| 1100/1160 [27:53<00:37,  1.59it/s]#015 95%|█████████▍| 1101/1160 [27:59<02:06,  2.15s/it]#015 95%|█████████▌| 1102/1160 [28:02<02:18,  2.39s/it]#015 95%|█████████▌| 1103/1160 [28:04<02:15,  2.38s/it]#015 95%|█████████▌| 1104/1160 [28:06<02:04,  2.22s/it]#015                                                   #015#015 95%|█████████▌| 1104/1160 [28:06<02:04,  2.22s/it]#015 95%|█████████▌| 1105/1160 [28:08<01:54,  2.08s/it]#015 95%|█████████▌| 1106/1160 [28:09<01:43,  1.92s/it]#015 95%|█████████▌| 1107/1160 [28:11<01:36,  1.82s/it]#015 96%|█████████▌| 1108/1160 [28:12<01:28,  1.71s/it]#015 96%|█████████▌| 1109/1160 [28:14<01:22,  1.61s/it]#015 96%|█████████▌| 1110/1160 [28:15<01:17,  1.54s/it]#015 96%|█████████▌| 1111/1160 [28:17<01:12,  1.47s/it]#015 96%|█████████▌| 1112/1160 [28:18<01:07,  1.41s/it]#015 96%|█████████▌| 1113/1160 [28:19<01:04,  1.37s/it]#015 96%|█████████▌| 1114/1160 [28:20<01:00,  1.32s/it]#015 96%|█████████▌| 1115/1160 [28:21<00:57,  1.28s/it]#015 96%|█████████▌| 1116/1160 [28:23<00:54,  1.23s/it]#015                                                   #015#015 96%|█████████▌| 1116/1160 [28:23<00:54,  1.23s/it]#015 96%|█████████▋| 1117/1160 [28:24<00:51,  1.20s/it]#015 96%|█████████▋| 1118/1160 [28:25<00:49,  1.17s/it]#015 96%|█████████▋| 1119/1160 [28:26<00:46,  1.13s/it]#015 97%|█████████▋| 1120/1160 [28:27<00:43,  1.09s/it]#015 97%|█████████▋| 1121/1160 [28:28<00:41,  1.05s/it]#015 97%|█████████▋| 1122/1160 [28:29<00:38,  1.02s/it]#015 97%|█████████▋| 1123/1160 [28:30<00:35,  1.03it/s]#015 97%|█████████▋| 1124/1160 [28:30<00:33,  1.08it/s]#015 97%|█████████▋| 1125/1160 [28:31<00:30,  1.15it/s]#015 97%|█████████▋| 1126/1160 [28:32<00:27,  1.24it/s]#015 97%|█████████▋| 1127/1160 [28:32<00:23,  1.38it/s]#015 97%|█████████▋| 1128/1160 [28:33<00:20,  1.55it/s]#015                                                   #015#015 97%|█████████▋| 1128/1160 [28:33<00:20,  1.55it/s]#015 97%|█████████▋| 1129/1160 [28:38<01:05,  2.10s/it]#015 97%|█████████▋| 1130/1160 [28:42<01:12,  2.43s/it]#015 98%|█████████▊| 1131/1160 [28:44<01:10,  2.42s/it]#015 98%|█████████▊| 1132/1160 [28:46<01:06,  2.38s/it]#015 98%|█████████▊| 1133/1160 [28:48<01:01,  2.28s/it]#015 98%|█████████▊| 1134/1160 [28:50<00:56,  2.17s/it]#015 98%|█████████▊| 1135/1160 [28:52<00:50,  2.02s/it]#015 98%|█████████▊| 1136/1160 [28:53<00:45,  1.88s/it]#015 98%|█████████▊| 1137/1160 [28:55<00:40,  1.76s/it]#015 98%|█████████▊| 1138/1160 [28:56<00:36,  1.65s/it]#015 98%|█████████▊| 1139/1160 [28:58<00:33,  1.58s/it]#015 98%|█████████▊| 1140/1160 [28:59<00:29,  1.50s/it]#015                                                   #015#015 98%|█████████▊| 1140/1160 [28:59<00:29,  1.50s/it]#015 98%|█████████▊| 1141/1160 [29:00<00:27,  1.43s/it]#015 98%|█████████▊| 1142/1160 [29:02<00:24,  1.38s/it]#015 99%|█████████▊| 1143/1160 [29:03<00:22,  1.33s/it]#015 99%|█████████▊| 1144/1160 [29:04<00:20,  1.27s/it]#015 99%|█████████▊| 1145/1160 [29:05<00:18,  1.22s/it]#015 99%|█████████▉| 1146/1160 [29:06<00:16,  1.18s/it]#015 99%|█████████▉| 1147/1160 [29:07<00:14,  1.14s/it]#015 99%|█████████▉| 1148/1160 [29:08<00:13,  1.10s/it]#015 99%|█████████▉| 1149/1160 [29:09<00:11,  1.05s/it]#015 99%|█████████▉| 1150/1160 [29:10<00:10,  1.01s/it]#015 99%|█████████▉| 1151/1160 [29:11<00:08,  1.05it/s]#015 99%|█████████▉| 1152/1160 [29:12<00:07,  1.10it/s]#015                                                   #015#015 99%|█████████▉| 1152/1160 [29:12<00:07,  1.10it/s]#015 99%|█████████▉| 1153/1160 [29:12<00:06,  1.16it/s]#015 99%|█████████▉| 1154/1160 [29:13<00:04,  1.24it/s]#015100%|█████████▉| 1155/1160 [29:14<00:03,  1.38it/s]#015100%|█████████▉| 1156/1160 [29:14<00:02,  1.56it/s]#015100%|█████████▉| 1157/1160 [29:18<00:04,  1.63s/it]#015100%|█████████▉| 1158/1160 [29:19<00:03,  1.61s/it]#015100%|█████████▉| 1159/1160 [29:21<00:01,  1.44s/it]#015100%|██████████| 1160/1160 [29:21<00:00,  1.10s/it]/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8474463820457458, 'eval_accuracy': 0.6444444444444445, 'eval_class_averaged_accuracy': 0.43300942663248987, 'eval_macro_f1': 0.42859645670022317, 'eval_global_f1': 0.6444444444444445, 'eval_class_weighted_f1': 0.6261166080481063, 'eval_runtime': 10.7754, 'eval_samples_per_second': 25.057, 'eval_steps_per_second': 1.299, 'epoch': 9.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.685, 'grad_norm': 10.084040641784668, 'learning_rate': 5.416666666666667e-06, 'epoch': 9.1}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5132, 'grad_norm': 4.556028842926025, 'learning_rate': 4.791666666666667e-06, 'epoch': 9.21}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5923, 'grad_norm': 7.917794227600098, 'learning_rate': 4.166666666666667e-06, 'epoch': 9.31}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6516, 'grad_norm': 5.0655436515808105, 'learning_rate': 3.541666666666667e-06, 'epoch': 9.41}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6193, 'grad_norm': 6.08036994934082, 'learning_rate': 2.916666666666667e-06, 'epoch': 9.52}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6193, 'grad_norm': 11.515045166015625, 'learning_rate': 2.2916666666666666e-06, 'epoch': 9.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5436, 'grad_norm': 13.40764045715332, 'learning_rate': 1.6666666666666667e-06, 'epoch': 9.72}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6239, 'grad_norm': 6.477023124694824, 'learning_rate': 1.0416666666666667e-06, 'epoch': 9.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5381, 'grad_norm': 5.827277183532715, 'learning_rate': 4.1666666666666667e-07, 'epoch': 9.93}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 2/14 [00:00<00:04,  2.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██▏       | 3/14 [00:01<00:05,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▊       | 4/14 [00:02<00:05,  1.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 5/14 [00:02<00:06,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|████▎     | 6/14 [00:03<00:05,  1.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 7/14 [00:04<00:04,  1.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|█████▋    | 8/14 [00:04<00:03,  1.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████▏  | 10/14 [00:06<00:03,  1.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A#015                                                   #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 1160/1160 [29:32<00:00,  1.10s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [00:10<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015                                                   #015#015100%|██████████| 1160/1160 [29:33<00:00,  1.10s/it]#015100%|██████████| 1160/1160 [29:33<00:00,  1.53s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8432327508926392, 'eval_accuracy': 0.6333333333333333, 'eval_class_averaged_accuracy': 0.42259378772045475, 'eval_macro_f1': 0.41953952502074987, 'eval_global_f1': 0.6333333333333333, 'eval_class_weighted_f1': 0.6138101414926743, 'eval_runtime': 10.745, 'eval_samples_per_second': 25.128, 'eval_steps_per_second': 1.303, 'epoch': 10.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1773.6804, 'train_samples_per_second': 13.012, 'train_steps_per_second': 0.654, 'train_loss': 1.1014652840022383, 'epoch': 10.0}\u001b[0m\n",
      "\u001b[34mtrain_time_per_sample= 0.07688020675393077\u001b[0m\n",
      "\u001b[34m/geneformer/lib/python3.12/site-packages/geneformer/collator_for_classification.py:644: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/14 [00:00<?, ?it/s]#015 14%|█▍        | 2/14 [00:00<00:03,  3.52it/s]#015 21%|██▏       | 3/14 [00:01<00:05,  2.16it/s]#015 29%|██▊       | 4/14 [00:01<00:04,  2.00it/s]#015 36%|███▌      | 5/14 [00:02<00:05,  1.51it/s]#015 43%|████▎     | 6/14 [00:03<00:05,  1.45it/s]#015 50%|█████     | 7/14 [00:04<00:04,  1.48it/s]#015 57%|█████▋    | 8/14 [00:04<00:03,  1.64it/s]#015 64%|██████▍   | 9/14 [00:05<00:03,  1.34it/s]#015 71%|███████▏  | 10/14 [00:06<00:03,  1.29it/s]#015 79%|███████▊  | 11/14 [00:07<00:02,  1.14it/s]#015 86%|████████▌ | 12/14 [00:08<00:01,  1.26it/s]#015 93%|█████████▎| 13/14 [00:09<00:00,  1.05it/s]#015100%|██████████| 14/14 [00:09<00:00,  1.31it/s]#015100%|██████████| 14/14 [00:09<00:00,  1.41it/s]\u001b[0m\n",
      "\u001b[34m2024-09-26 22:53:34,996 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-09-26 22:53:40 Uploading - Uploading generated training model\n",
      "2024-09-26 22:54:08 Completed - Training job completed\n",
      "Training seconds: 2430\n",
      "Billable seconds: 2430\n"
     ]
    }
   ],
   "source": [
    "model_output_path = f\"s3://{S3_BUCKET}/{S3_PREFIX}/trained_models/\"\n",
    "gf_training_job_name = 'geneformer-ft-testmlflow'\n",
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    'model_name': 'gf-12L-30M-i2048',\n",
    "    'max_lr': 5e-05,\n",
    "    'freeze_layers': 6,\n",
    "    'num_gpus': 1,\n",
    "    'num_proc': 16,\n",
    "    'geneformer_batch_size': 20,\n",
    "    'lr_schedule_fn': 'linear',\n",
    "    'warmup_steps': 200,\n",
    "    'epochs': 10,\n",
    "    'optimizer': 'adamw'\n",
    "}\n",
    "\n",
    "experiment_name = \"scRNASeq-fm\"\n",
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "geneformer_estimator = PyTorch(\n",
    "    base_job_name=gf_training_job_name,\n",
    "    entry_point=\"ft_geneformer_mlflow.py\",\n",
    "    source_dir=\"scripts/training/geneformer\",\n",
    "    output_path=model_output_path,\n",
    "    instance_type=\"ml.g4dn.4xlarge\", #\"ml.g5.4xlarge\", \"local\", \"local-gpu\"\n",
    "    instance_count=1,\n",
    "    image_uri=training_img_uri,\n",
    "    role=sagemaker_execution_role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    #distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"scrnaseq-fm-finetune\"}],\n",
    "    environment={\n",
    "        \"MLFLOW_TRACKING_URI\": tracking_server_arn,\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": experiment.name,\n",
    "        #\"MLFLOW_PARENT_RUN_ID\": run.info.run_id,\n",
    "    }\n",
    "    #keep_alive_period_in_seconds=1800,  #Failed - Instances not retained as a result of warmpool resource limits being exceeded\n",
    ")\n",
    "\n",
    "processing_job_name = \"sc-preprocess\"\n",
    "geneformer_estimator.fit({'train': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/train/pbmc3k_train.h5ad\",\n",
    "                   'test': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/test/pbmc3k_test.h5ad\",\n",
    "                     'labels': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/class_labels/pbmc3k_celltype_labels.pkl\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce51cf5-bde6-4811-b78f-d9d7de466d59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3.3. Display experiment and run metrics logged by mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7d54d22a-5467-41ef-b586-2b07174e863d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.train_loss</th>\n",
       "      <th>metrics.grad_norm</th>\n",
       "      <th>metrics.train_samples_per_second</th>\n",
       "      <th>metrics.eval_global_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>params.include_inputs_for_metrics</th>\n",
       "      <th>params.class_weight</th>\n",
       "      <th>params.dataset_name</th>\n",
       "      <th>params.max_iter</th>\n",
       "      <th>params.solver</th>\n",
       "      <th>params.penalty</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7f0919f381104694a6daf1e576cedfd2</td>\n",
       "      <td>34</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>s3://sagemaker-studio-851725420776-tx0da5flyzo...</td>\n",
       "      <td>2024-09-26 22:23:16.124000+00:00</td>\n",
       "      <td>2024-09-26 22:53:32.768000+00:00</td>\n",
       "      <td>1.101465</td>\n",
       "      <td>5.827277</td>\n",
       "      <td>13.012</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>root</td>\n",
       "      <td>ft_geneformer_mlflow.py</td>\n",
       "      <td>caring-hound-246</td>\n",
       "      <td>LOCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3499df45a33d4f788903312de24689ee</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>s3://sagemaker-studio-851725420776-tx0da5flyzo...</td>\n",
       "      <td>2024-09-26 21:51:05.500000+00:00</td>\n",
       "      <td>2024-09-26 21:52:16.591000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>balanced</td>\n",
       "      <td>pbmc3k</td>\n",
       "      <td>1000</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>root</td>\n",
       "      <td>baseline_lr_train_mlflow.py</td>\n",
       "      <td>adaptable-gull-947</td>\n",
       "      <td>LOCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d614805549464fed8f3d364191dff7d9</td>\n",
       "      <td>34</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>s3://sagemaker-studio-851725420776-tx0da5flyzo...</td>\n",
       "      <td>2024-09-26 05:41:09.954000+00:00</td>\n",
       "      <td>2024-09-26 06:11:18.372000+00:00</td>\n",
       "      <td>1.469274</td>\n",
       "      <td>6.025624</td>\n",
       "      <td>13.767</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>root</td>\n",
       "      <td>ft_geneformer_mlflow.py</td>\n",
       "      <td>intelligent-boar-55</td>\n",
       "      <td>LOCAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  7f0919f381104694a6daf1e576cedfd2            34  FINISHED   \n",
       "1  3499df45a33d4f788903312de24689ee             1  FINISHED   \n",
       "2  d614805549464fed8f3d364191dff7d9            34  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  s3://sagemaker-studio-851725420776-tx0da5flyzo...   \n",
       "1  s3://sagemaker-studio-851725420776-tx0da5flyzo...   \n",
       "2  s3://sagemaker-studio-851725420776-tx0da5flyzo...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2024-09-26 22:23:16.124000+00:00 2024-09-26 22:53:32.768000+00:00   \n",
       "1 2024-09-26 21:51:05.500000+00:00 2024-09-26 21:52:16.591000+00:00   \n",
       "2 2024-09-26 05:41:09.954000+00:00 2024-09-26 06:11:18.372000+00:00   \n",
       "\n",
       "   metrics.train_loss  metrics.grad_norm  metrics.train_samples_per_second  \\\n",
       "0            1.101465           5.827277                            13.012   \n",
       "1                 NaN                NaN                               NaN   \n",
       "2            1.469274           6.025624                            13.767   \n",
       "\n",
       "   metrics.eval_global_f1  ...  params.include_inputs_for_metrics  \\\n",
       "0                0.633333  ...                              False   \n",
       "1                0.814815  ...                               None   \n",
       "2                0.559259  ...                              False   \n",
       "\n",
       "   params.class_weight  params.dataset_name  params.max_iter  params.solver  \\\n",
       "0                 None                 None             None           None   \n",
       "1             balanced               pbmc3k             1000           saga   \n",
       "2                 None                 None             None           None   \n",
       "\n",
       "   params.penalty  tags.mlflow.user      tags.mlflow.source.name  \\\n",
       "0            None              root      ft_geneformer_mlflow.py   \n",
       "1              l2              root  baseline_lr_train_mlflow.py   \n",
       "2            None              root      ft_geneformer_mlflow.py   \n",
       "\n",
       "   tags.mlflow.runName  tags.mlflow.source.type  \n",
       "0     caring-hound-246                    LOCAL  \n",
       "1   adaptable-gull-947                    LOCAL  \n",
       "2  intelligent-boar-55                    LOCAL  \n",
       "\n",
       "[3 rows x 250 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[\"scRNASeq-baseline\", \"scRNASeq-fm\"],\n",
    "    filter_string=\"attributes.status='FINISHED' and tags.mlflow.user='root'\",\n",
    "    max_results=3, \n",
    ")\n",
    "display(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c7d096b-d5ce-48c7-b984-48a5101ef5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>metrics.eval_global_f1</th>\n",
       "      <th>metrics.eval_samples_per_second</th>\n",
       "      <th>metrics.eval_accuracy</th>\n",
       "      <th>metrics.eval_runtime</th>\n",
       "      <th>metrics.eval_loss</th>\n",
       "      <th>metrics.eval_class_weighted_f1</th>\n",
       "      <th>metrics.eval_class_averaged_accuracy</th>\n",
       "      <th>metrics.eval_macro_f1</th>\n",
       "      <th>metrics.eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3499df45a33d4f788903312de24689ee</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>205640.472126</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813833</td>\n",
       "      <td>0.758010</td>\n",
       "      <td>0.772846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7f0919f381104694a6daf1e576cedfd2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>25.128000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>10.745000</td>\n",
       "      <td>0.843233</td>\n",
       "      <td>0.613810</td>\n",
       "      <td>0.422594</td>\n",
       "      <td>0.419540</td>\n",
       "      <td>1.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d614805549464fed8f3d364191dff7d9</td>\n",
       "      <td>34</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>25.331000</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>10.658700</td>\n",
       "      <td>1.154671</td>\n",
       "      <td>0.498224</td>\n",
       "      <td>0.323888</td>\n",
       "      <td>0.297480</td>\n",
       "      <td>1.313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id  metrics.eval_global_f1  \\\n",
       "1  3499df45a33d4f788903312de24689ee             1                0.814815   \n",
       "0  7f0919f381104694a6daf1e576cedfd2            34                0.633333   \n",
       "2  d614805549464fed8f3d364191dff7d9            34                0.559259   \n",
       "\n",
       "   metrics.eval_samples_per_second  metrics.eval_accuracy  \\\n",
       "1                    205640.472126               0.814815   \n",
       "0                        25.128000               0.633333   \n",
       "2                        25.331000               0.559259   \n",
       "\n",
       "   metrics.eval_runtime  metrics.eval_loss  metrics.eval_class_weighted_f1  \\\n",
       "1              0.001313                NaN                        0.813833   \n",
       "0             10.745000           0.843233                        0.613810   \n",
       "2             10.658700           1.154671                        0.498224   \n",
       "\n",
       "   metrics.eval_class_averaged_accuracy  metrics.eval_macro_f1  \\\n",
       "1                              0.758010               0.772846   \n",
       "0                              0.422594               0.419540   \n",
       "2                              0.323888               0.297480   \n",
       "\n",
       "   metrics.eval_steps_per_second  \n",
       "1                            NaN  \n",
       "0                          1.303  \n",
       "2                          1.313  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[['run_id', 'experiment_id']+[c for c in runs.columns if 'metrics.eval' in c]].sort_values('experiment_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b889d7a",
   "metadata": {},
   "source": [
    "### 3.3.4. Compare baseline LR classifier and fine-tuned Geneformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd945c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='./images/Logistic regression classifier prediction on test set.png', width=400></td><td><img src='./images/Finetuned mdl prediction on test set.png', width=400></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<table><tr><td><img src='./images/Logistic regression classifier prediction on test set.png', width=400></td><td><img src='./images/Finetuned mdl prediction on test set.png', width=400></td></tr></table>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a94f19-cbc4-41c8-8dde-a99c9e3ad96b",
   "metadata": {},
   "source": [
    "### How to get better performance for FM on celltype classification\n",
    "\n",
    "- Hyperparameter optimization for fine tuning task \n",
    "- Use larger finetuning datasets\n",
    "- Benchmark baseline model and FM on complex datasets for OOD predictions (e.g. batch effects, different donors etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb3a1e-92ff-4006-aefc-66d534019d94",
   "metadata": {},
   "source": [
    "### 3.3.4. Hyperparameter optimization for the fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecbc0b-e5ea-40b4-9544-bdef4cf0f7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: geneformerft-240927-0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "processing_job_name = \"sc-preprocess\"\n",
    "experiment_name = \"scRNASeq-fm-hpo\"\n",
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_name': 'gf-12L-30M-i2048',\n",
    "    'max_lr': 5e-05,\n",
    "    'freeze_layers': 6,\n",
    "    'num_gpus': 1,\n",
    "    'num_proc': 16,\n",
    "    'geneformer_batch_size': 20,\n",
    "    'lr_schedule_fn': 'linear',\n",
    "    'warmup_steps': 200,\n",
    "    'epochs': 10,\n",
    "    'optimizer': 'adamw'\n",
    "}\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"loss\", \"Regex\": \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"learning_rate\", \"Regex\": \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_f1\", \"Regex\": \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_precision\", \"Regex\": \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_recall\", \"Regex\": \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_runtime\", \"Regex\": \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\n",
    "        \"Name\": \"eval_samples_per_second\",\n",
    "        \"Regex\": \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\",\n",
    "    },\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "]\n",
    "geneformer_estimator = PyTorch(\n",
    "    base_job_name=gf_training_job_name,\n",
    "    entry_point=\"ft_geneformer_mlflow.py\",\n",
    "    source_dir=\"scripts/training/geneformer\",\n",
    "    output_path=model_output_path,\n",
    "    instance_type=\"ml.g4dn.4xlarge\", #\"ml.c5.4xlarge\",  #\"ml.g4dn.4xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=training_img_uri,\n",
    "    role=sagemaker_execution_role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    #distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"scrnaseq-fm-finetune-hpo\"}],\n",
    "    environment={\n",
    "        \"MLFLOW_TRACKING_URI\": tracking_server_arn,\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": experiment.name,\n",
    "        #\"MLFLOW_PARENT_RUN_ID\": run.info.run_id,\n",
    "    },\n",
    "    metric_definitions=metric_definitions\n",
    "    #keep_alive_period_in_seconds=1800,  #Failed - Instances not retained as a result of warmpool resource limits being exceeded\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"max_lr\": ContinuousParameter(1e-05, 1e-3, 'Logarithmic'),\n",
    "    \"freeze_layers\": CategoricalParameter([2, 8, 12]),\n",
    "    \"epochs\": CategoricalParameter([10, 15])\n",
    "}\n",
    "\n",
    "objective_metric_name = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"}]\n",
    "hsc = HyperbandStrategyConfig(max_resource=30, min_resource=1)\n",
    "sc = StrategyConfig(hyperband_strategy_config=hsc)\n",
    "\n",
    "with mlflow.start_run(run_name=sagemaker.utils.name_from_base(\"HPO\")) as run:\n",
    "    tuner = HyperparameterTuner(\n",
    "        geneformer_estimator,\n",
    "        objective_metric_name,\n",
    "        hyperparameter_ranges,\n",
    "        metric_definitions,\n",
    "        max_jobs=36,\n",
    "        max_parallel_jobs=6,\n",
    "        objective_type=objective_type,\n",
    "        strategy='Hyperband',\n",
    "        strategy_config=sc,\n",
    "        early_stopping_type='Off' # set to 'Off' to use hyperband internal early stopping\n",
    "    )\n",
    "    tuner.fit({'train': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/train/pbmc3k_train.h5ad\",\n",
    "               'test': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/test/pbmc3k_test.h5ad\",\n",
    "                 'labels': f\"s3://{S3_BUCKET}/{S3_PREFIX}/{processing_job_name}/class_labels/pbmc3k_celltype_labels.pkl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "595be0d3-e8f9-4706-9555-c71105032e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>max_lr</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"15\"</td>\n",
       "      <td>\"12\"</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>geneformerft-240927-0539-012-1b04da5d</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>2024-09-27 05:58:43+00:00</td>\n",
       "      <td>2024-09-27 06:16:43+00:00</td>\n",
       "      <td>1080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"10\"</td>\n",
       "      <td>\"12\"</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>geneformerft-240927-0539-003-4c2dca82</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>2024-09-27 05:39:58+00:00</td>\n",
       "      <td>2024-09-27 05:57:46+00:00</td>\n",
       "      <td>1068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"10\"</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>geneformerft-240927-0539-020-d100c82e</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>1.7518</td>\n",
       "      <td>2024-09-27 06:12:35+00:00</td>\n",
       "      <td>2024-09-27 06:23:14+00:00</td>\n",
       "      <td>639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"10\"</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>geneformerft-240927-0539-004-79641a86</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>1.7543</td>\n",
       "      <td>2024-09-27 05:40:04+00:00</td>\n",
       "      <td>2024-09-27 05:50:12+00:00</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"10\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>geneformerft-240927-0539-015-bea7d1e6</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>1.7643</td>\n",
       "      <td>2024-09-27 06:02:02+00:00</td>\n",
       "      <td>2024-09-27 06:12:00+00:00</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs freeze_layers    max_lr                        TrainingJobName  \\\n",
       "24   \"15\"          \"12\"  0.000546  geneformerft-240927-0539-012-1b04da5d   \n",
       "33   \"10\"          \"12\"  0.000396  geneformerft-240927-0539-003-4c2dca82   \n",
       "16   \"10\"           \"2\"  0.000707  geneformerft-240927-0539-020-d100c82e   \n",
       "32   \"10\"           \"2\"  0.000549  geneformerft-240927-0539-004-79641a86   \n",
       "21   \"10\"           \"8\"  0.000431  geneformerft-240927-0539-015-bea7d1e6   \n",
       "\n",
       "   TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "24           Stopped               0.4162 2024-09-27 05:58:43+00:00   \n",
       "33           Stopped               0.4598 2024-09-27 05:39:58+00:00   \n",
       "16           Stopped               1.7518 2024-09-27 06:12:35+00:00   \n",
       "32           Stopped               1.7543 2024-09-27 05:40:04+00:00   \n",
       "21           Stopped               1.7643 2024-09-27 06:02:02+00:00   \n",
       "\n",
       "             TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "24 2024-09-27 06:16:43+00:00                      1080.0  \n",
       "33 2024-09-27 05:57:46+00:00                      1068.0  \n",
       "16 2024-09-27 06:23:14+00:00                       639.0  \n",
       "32 2024-09-27 05:50:12+00:00                       608.0  \n",
       "21 2024-09-27 06:12:00+00:00                       598.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_job_name = \"geneformerft-240927-0539\"\n",
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "full_df.sort_values(by=[\"FinalObjectiveValue\"], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d10ef-bdb4-4f50-b718-075d509f72f7",
   "metadata": {},
   "source": [
    "# 4. Deploy a trained model as an inference endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b282acb-9254-400f-8d63-f9d5508ce73e",
   "metadata": {},
   "source": [
    "Deploy a the trained LR model using an inference script providing:\n",
    "1. custom preprocessing to read h5ad file from s3, subset the data on genes in the trained model, normalize and transform the counts\n",
    "2. use the trained logistic regression model to predict cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5eaab842-72fa-4274-ac97-f57ee0eb4464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 9ft5dcngdd-algo-1-4534h\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,430 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,433 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,434 INFO - sagemaker-containers - nginx config: \n",
      "9ft5dcngdd-algo-1-4534h  | worker_processes auto;\n",
      "9ft5dcngdd-algo-1-4534h  | daemon off;\n",
      "9ft5dcngdd-algo-1-4534h  | pid /tmp/nginx.pid;\n",
      "9ft5dcngdd-algo-1-4534h  | error_log  /dev/stderr;\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  | worker_rlimit_nofile 4096;\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  | events {\n",
      "9ft5dcngdd-algo-1-4534h  |   worker_connections 2048;\n",
      "9ft5dcngdd-algo-1-4534h  | }\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  | http {\n",
      "9ft5dcngdd-algo-1-4534h  |   include /etc/nginx/mime.types;\n",
      "9ft5dcngdd-algo-1-4534h  |   default_type application/octet-stream;\n",
      "9ft5dcngdd-algo-1-4534h  |   access_log /dev/stdout combined;\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |   upstream gunicorn {\n",
      "9ft5dcngdd-algo-1-4534h  |     server unix:/tmp/gunicorn.sock;\n",
      "9ft5dcngdd-algo-1-4534h  |   }\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |   server {\n",
      "9ft5dcngdd-algo-1-4534h  |     listen 8080 deferred;\n",
      "9ft5dcngdd-algo-1-4534h  |     client_max_body_size 0;\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |     keepalive_timeout 3;\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "9ft5dcngdd-algo-1-4534h  |       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "9ft5dcngdd-algo-1-4534h  |       proxy_set_header Host $http_host;\n",
      "9ft5dcngdd-algo-1-4534h  |       proxy_redirect off;\n",
      "9ft5dcngdd-algo-1-4534h  |       proxy_read_timeout 60s;\n",
      "9ft5dcngdd-algo-1-4534h  |       proxy_pass http://gunicorn;\n",
      "9ft5dcngdd-algo-1-4534h  |     }\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |     location / {\n",
      "9ft5dcngdd-algo-1-4534h  |       return 404 \"{}\";\n",
      "9ft5dcngdd-algo-1-4534h  |     }\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  |   }\n",
      "9ft5dcngdd-algo-1-4534h  | }\n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  | \n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,644 INFO - sagemaker-containers - Module scrna_inference does not provide a setup.py. \n",
      "9ft5dcngdd-algo-1-4534h  | Generating setup.py\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,644 INFO - sagemaker-containers - Generating setup.cfg\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,644 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:35,644 INFO - sagemaker-containers - Installing module with the following command:\n",
      "9ft5dcngdd-algo-1-4534h  | /miniconda3/bin/python -m pip install . -r requirements.txt\n",
      "9ft5dcngdd-algo-1-4534h  | Processing /opt/ml/code\n",
      "9ft5dcngdd-algo-1-4534h  |   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hCollecting anndata (from -r requirements.txt (line 1))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading anndata-0.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting sagemaker (from -r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading sagemaker-2.232.1-py3-none-any.whl.metadata (16 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: pandas!=2.0.1,>=1.1.1 in /miniconda3/lib/python3.8/site-packages (from anndata->-r requirements.txt (line 1)) (1.1.3)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: numpy>=1.16.5 in /miniconda3/lib/python3.8/site-packages (from anndata->-r requirements.txt (line 1)) (1.24.1)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: scipy>1.4 in /miniconda3/lib/python3.8/site-packages (from anndata->-r requirements.txt (line 1)) (1.8.0)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting h5py>=3 (from anndata->-r requirements.txt (line 1))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting natsort (from anndata->-r requirements.txt (line 1))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting packaging>=20 (from anndata->-r requirements.txt (line 1))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting attrs<24,>=23.1.0 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting boto3<2.0,>=1.34.142 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading boto3-1.35.29-py3-none-any.whl.metadata (6.6 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting cloudpickle==2.2.1 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting docker (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting google-pasta (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting jsonschema (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pathos (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting platformdirs (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: protobuf<5.0,>=3.12 in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 2)) (3.20.2)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: psutil in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 2)) (5.7.2)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pyyaml~=6.0 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 2)) (2.32.3)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading sagemaker_core-1.0.9-py3-none-any.whl.metadata (4.9 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting schema (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting smdebug-rulesconfig==1.0.1 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting tblib<4,>=1.7.0 (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting tqdm (from sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.26.19)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting botocore<1.36.0,>=1.35.29 (from boto3<2.0,>=1.34.142->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading botocore-1.35.29-py3-none-any.whl.metadata (5.6 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.34.142->sagemaker->-r requirements.txt (line 2)) (1.0.1)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.34.142->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas!=2.0.1,>=1.1.1->anndata->-r requirements.txt (line 1)) (2.8.1)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas!=2.0.1,>=1.1.1->anndata->-r requirements.txt (line 1)) (2024.1)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pydantic<3.0.0,>=1.7.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting rich<14.0.0,>=13.0.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting importlib-resources>=1.4.0 (from jsonschema->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting referencing>=0.28.4 (from jsonschema->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting rpds-py>=0.7.1 (from jsonschema->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading rpds_py-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: charset-normalizer<4,>=2 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (3.3.2)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (3.7)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (2023.7.22)\n",
      "9ft5dcngdd-algo-1-4534h  | Requirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from google-pasta->sagemaker->-r requirements.txt (line 2)) (1.15.0)\n",
      "9ft5dcngdd-algo-1-4534h  | 2024/09/28 20:50:39 [crit] 27#27: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "9ft5dcngdd-algo-1-4534h  | 172.18.0.1 - - [28/Sep/2024:20:50:39 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"python-urllib3/2.2.2\"\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting ppft>=1.7.6.8 (from pathos->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting dill>=0.3.8 (from pathos->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pox>=0.3.4 (from pathos->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting multiprocess>=0.70.16 (from pathos->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pydantic_core-2.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting typing-extensions>=4.6.1 (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting pygments<3.0.0,>=2.13.0 (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker->-r requirements.txt (line 2))\n",
      "9ft5dcngdd-algo-1-4534h  |   Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading anndata-0.9.2-py3-none-any.whl (104 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading sagemaker-2.232.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading boto3-1.35.29-py3-none-any.whl (139 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.5/746.5 kB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading sagemaker_core-1.0.9-py3-none-any.whl (384 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading botocore-1.35.29-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m217.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pydantic_core-2.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m151.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading rpds_py-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m139.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "9ft5dcngdd-algo-1-4534h  | Building wheels for collected packages: scrna-inference\n",
      "9ft5dcngdd-algo-1-4534h  |   Building wheel for scrna-inference (setup.py) ... \u001b[?25ldone\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[?25h  Created wheel for scrna-inference: filename=scrna_inference-1.0.0-py2.py3-none-any.whl size=8471 sha256=f1c1d71abc41f5520dc70c492755367c4941328194164f7befca6e60f91089df\n",
      "9ft5dcngdd-algo-1-4534h  |   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-nam2acau/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "9ft5dcngdd-algo-1-4534h  | Successfully built scrna-inference\n",
      "9ft5dcngdd-algo-1-4534h  | Installing collected packages: scrna-inference, schema, zipp, typing-extensions, tqdm, tblib, smdebug-rulesconfig, rpds-py, pyyaml, pygments, ppft, pox, platformdirs, pkgutil-resolve-name, packaging, natsort, mock, mdurl, h5py, google-pasta, dill, cloudpickle, attrs, referencing, pydantic-core, multiprocess, markdown-it-py, importlib-resources, importlib-metadata, docker, botocore, annotated-types, s3transfer, rich, pydantic, pathos, jsonschema-specifications, anndata, jsonschema, boto3, sagemaker-core, sagemaker\n",
      "9ft5dcngdd-algo-1-4534h  |   Attempting uninstall: botocore\n",
      "9ft5dcngdd-algo-1-4534h  |     Found existing installation: botocore 1.31.85\n",
      "9ft5dcngdd-algo-1-4534h  |     Uninstalling botocore-1.31.85:\n",
      "9ft5dcngdd-algo-1-4534h  |       Successfully uninstalled botocore-1.31.85\n",
      "9ft5dcngdd-algo-1-4534h  | 2024/09/28 20:50:44 [crit] 27#27: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "9ft5dcngdd-algo-1-4534h  | 172.18.0.1 - - [28/Sep/2024:20:50:44 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"python-urllib3/2.2.2\"\n",
      "9ft5dcngdd-algo-1-4534h  |   Attempting uninstall: s3transfer\n",
      "9ft5dcngdd-algo-1-4534h  |     Found existing installation: s3transfer 0.7.0\n",
      "9ft5dcngdd-algo-1-4534h  |     Uninstalling s3transfer-0.7.0:\n",
      "9ft5dcngdd-algo-1-4534h  |       Successfully uninstalled s3transfer-0.7.0\n",
      "9ft5dcngdd-algo-1-4534h  |   Attempting uninstall: boto3\n",
      "9ft5dcngdd-algo-1-4534h  |     Found existing installation: boto3 1.28.57\n",
      "9ft5dcngdd-algo-1-4534h  |     Uninstalling boto3-1.28.57:\n",
      "9ft5dcngdd-algo-1-4534h  |       Successfully uninstalled boto3-1.28.57\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker-sklearn-container 2.0 requires boto3==1.28.57, but you have boto3 1.35.29 which is incompatible.\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker-sklearn-container 2.0 requires botocore<1.32.0,>=1.31.57, but you have botocore 1.35.29 which is incompatible.\u001b[0m\u001b[31m\n",
      "9ft5dcngdd-algo-1-4534h  | \u001b[0mSuccessfully installed anndata-0.9.2 annotated-types-0.7.0 attrs-23.2.0 boto3-1.35.29 botocore-1.35.29 cloudpickle-2.2.1 dill-0.3.8 docker-7.1.0 google-pasta-0.2.0 h5py-3.11.0 importlib-metadata-6.11.0 importlib-resources-6.4.5 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 mock-4.0.3 multiprocess-0.70.16 natsort-8.4.0 packaging-24.1 pathos-0.3.2 pkgutil-resolve-name-1.3.10 platformdirs-4.3.6 pox-0.3.4 ppft-1.7.6.8 pydantic-2.9.2 pydantic-core-2.23.4 pygments-2.18.0 pyyaml-6.0.2 referencing-0.35.1 rich-13.8.1 rpds-py-0.20.0 s3transfer-0.10.2 sagemaker-2.232.1 sagemaker-core-1.0.9 schema-0.7.7 scrna-inference-1.0.0 smdebug-rulesconfig-1.0.1 tblib-3.0.0 tqdm-4.66.5 typing-extensions-4.12.2 zipp-3.20.2\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | <sagemaker.session.Session object at 0x7ff39bbc8460>\n",
      "9ft5dcngdd-algo-1-4534h  | <sagemaker.session.Session object at 0x7ff39a974b50>\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [60] [INFO] Starting gunicorn 20.0.4\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [60] [INFO] Listening at: unix:/tmp/gunicorn.sock (60)\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [60] [INFO] Using worker: gevent\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [62] [INFO] Booting worker with pid: 62\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [63] [INFO] Booting worker with pid: 63\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [64] [INFO] Booting worker with pid: 64\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [65] [INFO] Booting worker with pid: 65\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [66] [INFO] Booting worker with pid: 66\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [67] [INFO] Booting worker with pid: 67\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [83] [INFO] Booting worker with pid: 83\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [84] [INFO] Booting worker with pid: 84\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [85] [INFO] Booting worker with pid: 85\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [86] [INFO] Booting worker with pid: 86\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [102] [INFO] Booting worker with pid: 102\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [103] [INFO] Booting worker with pid: 103\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [119] [INFO] Booting worker with pid: 119\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [120] [INFO] Booting worker with pid: 120\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [136] [INFO] Booting worker with pid: 136\n",
      "9ft5dcngdd-algo-1-4534h  | [2024-09-28 20:50:48 +0000] [137] [INFO] Booting worker with pid: 137\n",
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:50:49,620 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | <sagemaker.session.Session object at 0x7f581b394c10>\n",
      "9ft5dcngdd-algo-1-4534h  | model_dir: ['model.tar.gz', 'model.joblib', 'feature_names.joblib']\n",
      "9ft5dcngdd-algo-1-4534h  | 172.18.0.1 - - [28/Sep/2024:20:50:51 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/2.2.2\"\n",
      "!"
     ]
    }
   ],
   "source": [
    "model_data = \"s3://sagemaker-us-west-2-851725420776/scrnaseq-fm-finetune/trained_models/baseline-LR-2024-09-27-20-38-47-755/output/model.tar.gz\"\n",
    "lr_model = SKLearnModel(model_data, \n",
    "            sagemaker_execution_role, \n",
    "            entry_point=\"scrna_inference.py\", \n",
    "            framework_version=\"1.2-1\",\n",
    "            py_version=\"py3\",\n",
    "            source_dir=\"scripts/inference\",\n",
    "            name=\"scRNASeq-celltype-lr-clf\"\n",
    "            )\n",
    "predictor = lr_model.deploy(instance_type=\"local\", #\"ml.m5.xlarge\", \n",
    "                            initial_instance_count=1,\n",
    "                           endpoint_name='scRNASeq-celltype-lr-clf')\n",
    "\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = CSVDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "601f57c6-5d30-47bb-8248-ccfeb6b569cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9ft5dcngdd-algo-1-4534h  | 2024-09-28 20:51:21,739 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "9ft5dcngdd-algo-1-4534h  | <sagemaker.session.Session object at 0x7f581b3d93a0>\n",
      "9ft5dcngdd-algo-1-4534h  | model_dir: ['model.tar.gz', 'model.joblib', 'feature_names.joblib']\n",
      "9ft5dcngdd-algo-1-4534h  | s3://sagemaker-us-west-2-851725420776/scrnaseq-fm-finetune/sc-preprocess/test\n",
      "9ft5dcngdd-algo-1-4534h  | ['pbmc3k_test.h5ad']\n",
      "9ft5dcngdd-algo-1-4534h  | /tmp/09282024205122/pbmc3k_test.h5ad\n",
      "9ft5dcngdd-algo-1-4534h  | /tmp/09282024205122 removed successfully!\n",
      "9ft5dcngdd-algo-1-4534h  | 172.18.0.1 - - [28/Sep/2024:20:51:23 +0000] \"POST /invocations HTTP/1.1\" 200 540 \"-\" \"python-urllib3/2.2.2\"\n"
     ]
    }
   ],
   "source": [
    "predicted_value = predictor.predict(\"s3://sagemaker-us-west-2-851725420776/scrnaseq-fm-finetune/sc-preprocess/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d05ff628-0023-4607-bd61-9c8de2635bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['4'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['4'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['4'],\n",
       " ['0'],\n",
       " ['6'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['6'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['5'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['4'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['4'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['4'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['6'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['4'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['6'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['7'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['6'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['6'],\n",
       " ['3'],\n",
       " ['5'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['6'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['0'],\n",
       " ['1'],\n",
       " ['6'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['4'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['6'],\n",
       " ['3'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['0'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['4'],\n",
       " ['3'],\n",
       " ['0'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['3'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['2'],\n",
       " ['5'],\n",
       " ['2'],\n",
       " ['1'],\n",
       " ['3'],\n",
       " ['2'],\n",
       " ['4']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
