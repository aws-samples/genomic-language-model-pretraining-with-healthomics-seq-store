{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dfbb7c-2280-4b01-949a-91238a892d0b",
   "metadata": {},
   "source": [
    "### 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82308943-5300-4cc0-856c-879e1a6f24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pip\n",
    "%pip install -qU sagemaker boto3 awscli boto3 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e8d899-38ef-4e5b-b798-782d97c6144e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from time import strftime\n",
    "from functools import partial\n",
    "import importlib\n",
    "\n",
    "import utilities as u\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc08ea8e-787f-42ae-bdba-4f3d8ba9c044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.215.0', '1.34.84')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__, boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46afa5b6-7d8e-4d4e-9be7-bedaf774694b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed SageMaker role is arn:aws:iam::111918798052:role/DevelopmentRole\n",
      "S3_DATA_URI s3://sagemaker-us-east-1-111918798052/data/\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "omics = boto3.client(\"omics\")\n",
    "\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "\n",
    "EXPERIMENT_NAME = \"hyenaDNA-pretraining-v2\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")\n",
    "\n",
    "S3_DATA_URI = f\"s3://{S3_BUCKET}/data/\"\n",
    "print(f\"S3_DATA_URI {S3_DATA_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd25e8-4256-49b5-97ef-b98ed7f0657e",
   "metadata": {},
   "source": [
    "### 1. Read the data from AWS HealthOmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0bebb2c-f925-4532-8c03-60195f26d657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_store_id = \"4308389581\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4de9f99-49cd-425c-b724-b27ed95ad750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://111918798052-4308389-m7r4grkrg7nkpmf5swnjwf1iqsdieuse1b-s3alias/111918798052/sequenceStore/4308389581/',\n",
       " 'arn:aws:s3:us-east-1:559620149354:accesspoint/111918798052-4308389581',\n",
       " 'arn:aws:kms:us-east-1:559620149354:key/ef42c6a8-5692-4a6c-9a66-a2d1058a9a41')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_store_info = omics.get_sequence_store(id=seq_store_id)\n",
    "s3_uri = seq_store_info[\"s3Access\"][\"s3Uri\"]\n",
    "s3_arn = seq_store_info[\"s3Access\"][\"s3AccessPointArn\"]\n",
    "key_arn = seq_store_info[\"sseConfig\"][\"keyArn\"]\n",
    "s3_uri, s3_arn, key_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120bb71-a43e-4e15-bc36-800ae4c320ed",
   "metadata": {},
   "source": [
    "For this notebook to access the objects in the above S3 access point, `s3uri`, you must add a policy\n",
    "to this notebook's execution role (`SAGEMAKER_EXECUTION_ROLE`). The output of the following cell is the policy that\n",
    "you should attach to this role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63c953ee-7029-4562-b008-76b8f7594e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"S3DirectAccess\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"s3:GetObject\",\n",
      "        \"s3:ListBucket\"\n",
      "      ],\n",
      "      \"Resource\": \"*\",\n",
      "      \"Condition\": {\n",
      "        \"StringEquals\": {\n",
      "          \"s3:DataAccessPointArn\": \"arn:aws:s3:us-east-1:559620149354:accesspoint/111918798052-4308389581\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Sid\": \"DefaultSequenceStoreKMSDecrypt\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": \"kms:Decrypt\",\n",
      "      \"Resource\": \"arn:aws:kms:us-east-1:559620149354:key/ef42c6a8-5692-4a6c-9a66-a2d1058a9a41\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        { \n",
    "            \"Sid\": \"S3DirectAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [ \n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ], \n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"s3:DataAccessPointArn\": s3_arn\n",
    "                } \n",
    "            }\n",
    "        },\n",
    "        { \n",
    "            \"Sid\": \"DefaultSequenceStoreKMSDecrypt\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"kms:Decrypt\",\n",
    "            \"Resource\": key_arn\n",
    "        }\n",
    "    ] \n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f09ee-167c-409f-8242-7cbf98672968",
   "metadata": {},
   "source": [
    "#### 1.1 Load the data from S3 to the local disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d3a09d-e518-4c0d-a8cd-ff26b05ea7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = Path(\"/home/sagemaker-user/hyena/tmp\")\n",
    "# !aws s3 cp --recursive {s3_uri}readSet/ {str(data_dir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb148d5b-b950-4ee4-810e-75a56e97565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://111918798052-4308389-m7r4grkrg7nkpmf5swnjwf1iqsdieuse1b-s3alias/111918798052/sequenceStore/4308389581/readSet/'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_DATA_URI = f\"{s3_uri}readSet/\"\n",
    "S3_DATA_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2147dc-1d22-48dd-be39-18578895912e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Uncompress the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc128743-c478-4d92-9b75-59ef8b45c490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fastq_files = u.convert_directory(data_dir, suffix=\".fq.gz\",\n",
    "#                                   convertor=partial(u.gunzip_file,\n",
    "#                                                     suffix=\".gz\"),\n",
    "#                                   delete_orig_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e252fc-cc2b-4474-8404-444027392e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3 Convert each FASTQ into an equivalent FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2930a3a5-6283-475c-9282-fdc567992590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importlib.reload(u)\n",
    "# fasta_files = u.convert_directory(data_dir, suffix=\".fq\",\n",
    "#                                   convertor=u.convert_fastq_to_fasta,\n",
    "#                                   delete_orig_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeadcec-beab-40ae-ab4b-df3d80aaebee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.4 Re-jigger the directory hierachy to match what HyenaDNA needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f65d3f-f552-4382-8199-285770dad83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove the readSet dir segments\n",
    "# for child in data_dir.rglob(\"**/*\"):\n",
    "#     if child.is_file():\n",
    "#         path = str(child).split(\"/\")\n",
    "#         new_path = path[:-2] + path[-1:]\n",
    "#         target = child.rename(Path(\"/\".join(new_path)))\n",
    "#         print(f\"Moved {child} to {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3efa8-4645-418d-9861-16c3d4738a60",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.5 Move the results back to S3 for the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d10352-e2a1-4fe0-9514-e440ce39a6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!aws s3 cp --recursive {str(data_dir)} {S3_DATA_URI}/mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4d0b7-0eb9-4757-aa89-aec2ca107115",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a68d1b-edb1-49ee-acae-076bdecff096",
   "metadata": {},
   "source": [
    "### 2.1 Define the training container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7e3deae-0de2-499e-a60a-c76aaef138ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker\"\n",
    "pytorch_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a3e14-2cab-472a-96d9-808c39c4f8c8",
   "metadata": {},
   "source": [
    "#### 2.2 Define the training job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe0c7f6-0a53-483a-80ae-793ad58d7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'LongSafari/hyenadna-small-32k-seqlen-hf'\n",
    "TRAINING_JOB_NAME = 'hyenaDNA-pretraining'\n",
    "\n",
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"species\" : \"mouse\",\n",
    "    \"epochs\": 150,\n",
    "    \"model_checkpoint\": MODEL_ID,\n",
    "    \"max_length\": 32_000,\n",
    "    \"batch_size\": 4, \n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"weight_decay\" : 0.1,\n",
    "    \"log_level\" : \"INFO\",\n",
    "    \"log_interval\" : 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178423a-828b-4101-b540-5efe22b5e223",
   "metadata": {},
   "source": [
    "#### 2.3 Define Metrics to track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad98da5-1d11-4eb4-8718-2e4cb4834872",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"Epoch: ([0-9.]*)\"},\n",
    "    {\"Name\": \"step\", \"Regex\": \"Step: ([0-9.]*)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"Train Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"train_perplexity\", \"Regex\": \"Train Perplexity: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"Eval Average Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_perplexity\", \"Regex\": \"Eval Perplexity: ([0-9.e-]*)\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9636d-1707-42ee-aa77-3f63c095285c",
   "metadata": {},
   "source": [
    "#### 2.4 Define the tensorboard configurations to track the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d22067bf-c6b5-478d-b8ca-65a0bd487768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "LOG_DIR=\"/opt/ml/output/tensorboard\"\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://\", S3_BUCKET, \"sagemaker-output\", \"training\", TRAINING_JOB_NAME\n",
    ")\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=os.path.join(output_path, 'tensorboard'),\n",
    "    container_local_output_path=LOG_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18fb5e-e1cf-447b-84fa-eb80b347c9e1",
   "metadata": {},
   "source": [
    "#### 2.4 Define Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcd8126d-605c-40c6-bce1-a68602f80e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyenaDNA_estimator = PyTorch(\n",
    "    base_job_name=TRAINING_JOB_NAME,\n",
    "    entry_point=\"train_hf_accelerate.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=pytorch_image_uri,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"genomics-model-pretraining\"}],\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04af1c-82ce-44ca-bce7-76d9776c6d95",
   "metadata": {},
   "source": [
    "#### 2.5 Start Training with Distributed Data Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2b5544d-cffb-4a1a-bbe5-5d260c31bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: hyenaDNA-pretraining-2024-04-15-23-27-26-942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 23:27:27 Starting - Starting the training job...\n",
      "2024-04-15 23:27:38 Pending - Training job waiting for capacity...\n",
      "2024-04-15 23:28:03 Pending - Preparing the instances for training...\n",
      "2024-04-15 23:28:48 Downloading - Downloading input data...\n",
      "2024-04-15 23:29:03 Downloading - Downloading the training image............\n",
      "2024-04-15 23:31:24 Training - Training image download completed. Training in progress........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:27,683 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:27,736 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:27,746 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:27,747 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:27,748 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:28,996 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting s3torchconnector (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnector-1.2.3.tar.gz (55 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 6.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.26.1 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.3/100.3 kB 13.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting biopython==1.73 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading biopython-1.73.tar.gz (15.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 67.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pyfaidx==0.8.1.1 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading pyfaidx-0.8.1.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.28.0 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard==2.16.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.16.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (3.13.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (4.66.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (68.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (6.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 7)) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 7)) (2.2.0)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from accelerate==0.28.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (1.62.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (3.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (0.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 8)) (3.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mCollecting s3torchconnectorclient>=1.2.3 (from s3torchconnector->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnectorclient-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->-r requirements.txt (line 4)) (2024.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->-r requirements.txt (line 4)) (4.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 7)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 7)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 7)) (3.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.16.2->-r requirements.txt (line 8)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 7)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 105.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyfaidx-0.8.1.1-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.1/290.1 kB 34.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 388.9/388.9 kB 48.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.0/774.0 kB 63.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnectorclient-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 104.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 79.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 101.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: biopython, s3torchconnector\u001b[0m\n",
      "\u001b[34mBuilding wheel for biopython (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for biopython (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for biopython: filename=biopython-1.73-cp310-cp310-linux_x86_64.whl size=2171090 sha256=c2760510a5b34e90e3796577671cbfc092d6c044b0451643a1cff77cfbe6da5e\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/23/52/b9/1339217891a98d1331331b3d9159dae6f9116e40715a56a950\u001b[0m\n",
      "\u001b[34mBuilding wheel for s3torchconnector (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for s3torchconnector (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for s3torchconnector: filename=s3torchconnector-1.2.3-py3-none-any.whl size=61036 sha256=9415f269197f0c4224ecc834a67268274b20d5dc3af321b68298f48119c994ff\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/38/94/ff/8eb2fafd1ec4eedbaf3e155715960acdb9d2c1a1c96dfa062c\u001b[0m\n",
      "\u001b[34mSuccessfully built biopython s3torchconnector\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, safetensors, s3torchconnectorclient, regex, biopython, pyfaidx, huggingface-hub, transformers, s3torchconnector, accelerate\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.22.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.22.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.22.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.28.0 biopython-1.73 huggingface-hub-0.22.2 pyfaidx-0.8.1.1 regex-2023.12.25 s3torchconnector-1.2.3 s3torchconnectorclient-1.2.3 safetensors-0.4.3 tokenizers-0.13.3 transformers-4.26.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,734 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,734 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,808 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,873 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,884 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,938 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-15 23:32:50,949 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"data\": \"/opt/ml/input/data/data\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 4,\n",
      "        \"epochs\": 150,\n",
      "        \"learning_rate\": 0.0006,\n",
      "        \"log_interval\": 100,\n",
      "        \"log_level\": \"INFO\",\n",
      "        \"max_length\": 32000,\n",
      "        \"model_checkpoint\": \"LongSafari/hyenadna-small-32k-seqlen-hf\",\n",
      "        \"species\": \"mouse\",\n",
      "        \"weight_decay\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"data\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"hyenaDNA-pretraining-2024-04-15-23-27-26-942\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-15-23-27-26-942/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_hf_accelerate\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_hf_accelerate.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":4,\"epochs\":150,\"learning_rate\":0.0006,\"log_interval\":100,\"log_level\":\"INFO\",\"max_length\":32000,\"model_checkpoint\":\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"species\":\"mouse\",\"weight_decay\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_hf_accelerate.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.12xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"data\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_hf_accelerate\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-15-23-27-26-942/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.12xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"data\":\"/opt/ml/input/data/data\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":4,\"epochs\":150,\"learning_rate\":0.0006,\"log_interval\":100,\"log_level\":\"INFO\",\"max_length\":32000,\"model_checkpoint\":\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"species\":\"mouse\",\"weight_decay\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"hyenaDNA-pretraining-2024-04-15-23-27-26-942\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-15-23-27-26-942/source/sourcedir.tar.gz\",\"module_name\":\"train_hf_accelerate\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_hf_accelerate.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"4\",\"--epochs\",\"150\",\"--learning_rate\",\"0.0006\",\"--log_interval\",\"100\",\"--log_level\",\"INFO\",\"--max_length\",\"32000\",\"--model_checkpoint\",\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"--species\",\"mouse\",\"--weight_decay\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATA=/opt/ml/input/data/data\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=150\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0006\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_LEVEL=INFO\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LENGTH=32000\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_CHECKPOINT=LongSafari/hyenadna-small-32k-seqlen-hf\u001b[0m\n",
      "\u001b[34mSM_HP_SPECIES=mouse\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 4 train_hf_accelerate.py --batch_size 4 --epochs 150 --learning_rate 0.0006 --log_interval 100 --log_level INFO --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --species mouse --weight_decay 0.1\u001b[0m\n",
      "\u001b[34m[2024-04-15 23:32:52,061] torch.distributed.run: [WARNING] \u001b[0m\n",
      "\u001b[34m[2024-04-15 23:32:52,061] torch.distributed.run: [WARNING] *****************************************\u001b[0m\n",
      "\u001b[34m[2024-04-15 23:32:52,061] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m[2024-04-15 23:32:52,061] torch.distributed.run: [WARNING] *****************************************\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:01 - INFO - __main__ - Starting training.......\u001b[0m\n",
      "\u001b[34mStatrted the pre-processing process\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:02 - INFO - __main__ - Starting training.......\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:02 - INFO - __main__ - Starting training.......\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:02 - INFO - __main__ - Starting training.......\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/1040759226/chr12.fq.gz -> /opt/ml/input/data/data/1040759226/chr12.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/1040759226/chr12.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4815912818/chrX.fq.gz -> /opt/ml/input/data/data/4815912818/chrX.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4815912818/chrX.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/7048177625/chr3.fq.gz -> /opt/ml/input/data/data/7048177625/chr3.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/7048177625/chr3.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4164737562/chr9.fq.gz -> /opt/ml/input/data/data/4164737562/chr9.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4164737562/chr9.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4552296085/chr11.fq.gz -> /opt/ml/input/data/data/4552296085/chr11.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4552296085/chr11.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/7039739896/chr13.fq.gz -> /opt/ml/input/data/data/7039739896/chr13.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/7039739896/chr13.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2677481661/chr8.fq.gz -> /opt/ml/input/data/data/2677481661/chr8.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2677481661/chr8.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/6849506425/chr2.fq.gz -> /opt/ml/input/data/data/6849506425/chr2.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/6849506425/chr2.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4291333584/chr10.fq.gz -> /opt/ml/input/data/data/4291333584/chr10.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4291333584/chr10.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/8761700955/chr7.fq.gz -> /opt/ml/input/data/data/8761700955/chr7.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/8761700955/chr7.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4019662486/chr5.fq.gz -> /opt/ml/input/data/data/4019662486/chr5.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4019662486/chr5.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5628991692/chr19.fq.gz -> /opt/ml/input/data/data/5628991692/chr19.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5628991692/chr19.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2063114856/chr16.fq.gz -> /opt/ml/input/data/data/2063114856/chr16.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2063114856/chr16.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4399289471/chr1.fq.gz -> /opt/ml/input/data/data/4399289471/chr1.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4399289471/chr1.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/6611795136/chr18.fq.gz -> /opt/ml/input/data/data/6611795136/chr18.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/6611795136/chr18.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/8963750725/chr15.fq.gz -> /opt/ml/input/data/data/8963750725/chr15.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/8963750725/chr15.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5719009676/chr4.fq.gz -> /opt/ml/input/data/data/5719009676/chr4.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5719009676/chr4.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/9274193512/chr6.fq.gz -> /opt/ml/input/data/data/9274193512/chr6.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/9274193512/chr6.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2043193651/chr17.fq.gz -> /opt/ml/input/data/data/2043193651/chr17.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2043193651/chr17.fq.gz\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5832638637/chr14.fq.gz -> /opt/ml/input/data/data/5832638637/chr14.fq\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5832638637/chr14.fq.gz\u001b[0m\n",
      "\u001b[34mDone\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/1040759226/chr12.fq -> /opt/ml/input/data/data/1040759226/chr12.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/1040759226/chr12.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4815912818/chrX.fq -> /opt/ml/input/data/data/4815912818/chrX.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4815912818/chrX.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/7048177625/chr3.fq -> /opt/ml/input/data/data/7048177625/chr3.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/7048177625/chr3.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4164737562/chr9.fq -> /opt/ml/input/data/data/4164737562/chr9.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4164737562/chr9.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4552296085/chr11.fq -> /opt/ml/input/data/data/4552296085/chr11.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4552296085/chr11.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/7039739896/chr13.fq -> /opt/ml/input/data/data/7039739896/chr13.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/7039739896/chr13.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2677481661/chr8.fq -> /opt/ml/input/data/data/2677481661/chr8.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2677481661/chr8.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/6849506425/chr2.fq -> /opt/ml/input/data/data/6849506425/chr2.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/6849506425/chr2.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4291333584/chr10.fq -> /opt/ml/input/data/data/4291333584/chr10.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4291333584/chr10.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/8761700955/chr7.fq -> /opt/ml/input/data/data/8761700955/chr7.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/8761700955/chr7.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4019662486/chr5.fq -> /opt/ml/input/data/data/4019662486/chr5.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4019662486/chr5.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5628991692/chr19.fq -> /opt/ml/input/data/data/5628991692/chr19.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5628991692/chr19.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2063114856/chr16.fq -> /opt/ml/input/data/data/2063114856/chr16.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2063114856/chr16.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/4399289471/chr1.fq -> /opt/ml/input/data/data/4399289471/chr1.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/4399289471/chr1.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/6611795136/chr18.fq -> /opt/ml/input/data/data/6611795136/chr18.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/6611795136/chr18.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/8963750725/chr15.fq -> /opt/ml/input/data/data/8963750725/chr15.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/8963750725/chr15.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5719009676/chr4.fq -> /opt/ml/input/data/data/5719009676/chr4.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5719009676/chr4.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/9274193512/chr6.fq -> /opt/ml/input/data/data/9274193512/chr6.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/9274193512/chr6.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/2043193651/chr17.fq -> /opt/ml/input/data/data/2043193651/chr17.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/2043193651/chr17.fq\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/data/5832638637/chr14.fq -> /opt/ml/input/data/data/5832638637/chr14.fa\u001b[0m\n",
      "\u001b[34mDeleted /opt/ml/input/data/data/5832638637/chr14.fq\u001b[0m\n",
      "\u001b[34mDone\u001b[0m\n",
      "\u001b[34mCompleted the pre-processing of the data\u001b[0m\n",
      "\u001b[34mNCCL version 2.19.4+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:143:467 [0] configure_nvls_option:293 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:145:469 [2] configure_nvls_option:293 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:144:468 [1] configure_nvls_option:293 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:146:470 [3] configure_nvls_option:293 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:45 - INFO - __main__ - Accelerate State: Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 4\u001b[0m\n",
      "\u001b[34mProcess index: 0\u001b[0m\n",
      "\u001b[34mLocal process index: 0\u001b[0m\n",
      "\u001b[34mDevice: cuda:0\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:45 - INFO - __main__ - Is Main Process: True\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:45 - INFO - __main__ - Local Process Index: 0\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:45 - INFO - __main__ - Device: cuda:0\u001b[0m\n",
      "\u001b[34m[HyenaDNA Training]04/15/2024 23:33:45 - INFO - __main__ - Number of Processes: 4\u001b[0m\n",
      "\u001b[34mExplicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\u001b[0m\n",
      "\u001b[34mExplicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\u001b[0m\n",
      "\u001b[34mExplicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\u001b[0m\n",
      "\u001b[34mExplicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 207, in <module>\u001b[0m\n",
      "\u001b[34mmain(args)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 183, in main\n",
      "    train_dataset, test_dataset = get_dataset(tokenizer, args.max_length)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 59, in get_dataset\n",
      "    train_dataset = SpeciesDataset(\n",
      "  File \"/opt/ml/code/species_dataset.py\", line 170, in __init__\u001b[0m\n",
      "\u001b[34mself.fastas[spec][chromosome] = Fasta(file_path, sequence_always_upper=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 1090, in __init__\u001b[0m\n",
      "\u001b[34mself.faidx = Faidx(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 505, in __init__\u001b[0m\n",
      "\u001b[34mself.build_index()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 685, in build_index\u001b[0m\n",
      "\u001b[34mraise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 654, in build_index\u001b[0m\n",
      "\u001b[34mraise FastaIndexingError(\u001b[0m\n",
      "\u001b[34mpyfaidx.FastaIndexingError: The FASTA file /opt/ml/input/data/data/mouse/chr2.fa does not contain a valid sequence. Check that sequence definition lines start with '>'.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 207, in <module>\u001b[0m\n",
      "\u001b[34mmain(args)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 183, in main\n",
      "    train_dataset, test_dataset = get_dataset(tokenizer, args.max_length)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 59, in get_dataset\u001b[0m\n",
      "\u001b[34mtrain_dataset = SpeciesDataset(\n",
      "  File \"/opt/ml/code/species_dataset.py\", line 170, in __init__\n",
      "    self.fastas[spec][chromosome] = Fasta(file_path, sequence_always_upper=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 1090, in __init__\u001b[0m\n",
      "\u001b[34mself.faidx = Faidx(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 505, in __init__\u001b[0m\n",
      "\u001b[34mself.build_index()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 685, in build_index\u001b[0m\n",
      "\u001b[34mraise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 654, in build_index\u001b[0m\n",
      "\u001b[34mraise FastaIndexingError(\u001b[0m\n",
      "\u001b[34mpyfaidx.FastaIndexingError\u001b[0m\n",
      "\u001b[34m: The FASTA file /opt/ml/input/data/data/mouse/chr2.fa does not contain a valid sequence. Check that sequence definition lines start with '>'.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 207, in <module>\u001b[0m\n",
      "\u001b[34mmain(args)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 183, in main\u001b[0m\n",
      "\u001b[34mtrain_dataset, test_dataset = get_dataset(tokenizer, args.max_length)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 59, in get_dataset\n",
      "    train_dataset = SpeciesDataset(\n",
      "  File \"/opt/ml/code/species_dataset.py\", line 170, in __init__\u001b[0m\n",
      "\u001b[34mself.fastas[spec][chromosome] = Fasta(file_path, sequence_always_upper=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 1090, in __init__\u001b[0m\n",
      "\u001b[34mself.faidx = Faidx(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 505, in __init__\u001b[0m\n",
      "\u001b[34mself.build_index()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 685, in build_index\u001b[0m\n",
      "\u001b[34mraise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 654, in build_index\n",
      "    raise FastaIndexingError(\u001b[0m\n",
      "\u001b[34mpyfaidx.FastaIndexingError: The FASTA file /opt/ml/input/data/data/mouse/chr2.fa does not contain a valid sequence. Check that sequence definition lines start with '>'.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 207, in <module>\u001b[0m\n",
      "\u001b[34mmain(args)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 183, in main\n",
      "    train_dataset, test_dataset = get_dataset(tokenizer, args.max_length)\n",
      "  File \"/opt/ml/code/train_hf_accelerate.py\", line 59, in get_dataset\n",
      "    train_dataset = SpeciesDataset(\n",
      "  File \"/opt/ml/code/species_dataset.py\", line 170, in __init__\u001b[0m\n",
      "\u001b[34mself.fastas[spec][chromosome] = Fasta(file_path, sequence_always_upper=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 1090, in __init__\u001b[0m\n",
      "\u001b[34mself.faidx = Faidx(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 505, in __init__\u001b[0m\n",
      "\u001b[34mself.build_index()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 685, in build_index\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 654, in build_index\u001b[0m\n",
      "\u001b[34mraise FastaIndexingError(\u001b[0m\n",
      "\u001b[34mpyfaidx.FastaIndexingError: The FASTA file /opt/ml/input/data/data/mouse/chr2.fa does not contain a valid sequence. Check that sequence definition lines start with '>'.\u001b[0m\n",
      "\u001b[34m[2024-04-15 23:33:52,123] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 143) of binary: /opt/conda/bin/python\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/bin/torchrun\", line 33, in <module>\u001b[0m\n",
      "\u001b[34msys.exit(load_entry_point('torch==2.2.0', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\u001b[0m\n",
      "\u001b[34mreturn f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 812, in main\u001b[0m\n",
      "\u001b[34mrun(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 803, in run\u001b[0m\n",
      "\u001b[34melastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\u001b[0m\n",
      "\u001b[34mraise ChildFailedError(\u001b[0m\n",
      "\u001b[34mtorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \u001b[0m\n",
      "\u001b[34m============================================================\u001b[0m\n",
      "\u001b[34mtrain_hf_accelerate.py FAILED\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mFailures:\u001b[0m\n",
      "\u001b[34m[1]:\n",
      "  time      : 2024-04-15_23:33:52\n",
      "  host      : algo-1\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 144)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "\u001b[34m[2]:\n",
      "  time      : 2024-04-15_23:33:52\n",
      "  host      : algo-1\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 145)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "\u001b[34m[3]:\n",
      "  time      : 2024-04-15_23:33:52\n",
      "  host      : algo-1\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 146)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mRoot Cause (first observed failure):\u001b[0m\n",
      "\u001b[34m[0]:\n",
      "  time      : 2024-04-15_23:33:52\n",
      "  host      : algo-1\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 143)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "\u001b[34m============================================================\u001b[0m\n",
      "\u001b[34m2024-04-15 23:33:52,362 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:33:52,362 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-15 23:33:52,362 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2024-04-15 23:33:52,362 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"torchrun --nnodes 1 --nproc_per_node 4 train_hf_accelerate.py --batch_size 4 --epochs 150 --learning_rate 0.0006 --log_interval 100 --log_level INFO --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --species mouse --weight_decay 0.1\"\u001b[0m\n",
      "\u001b[34m2024-04-15 23:33:52,363 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2024-04-15 23:34:13 Uploading - Uploading generated training model\n",
      "2024-04-15 23:34:13 Failed - Instances not retained as a result of warmpool resource limits being exceeded\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the UpdateTrialComponent operation: 1 validation error detected: Value 'Error for Training job hyenaDNA-pretraining-2024-04-15-23-27-26-942: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"torchrun --nnodes 1 --nproc_per_node 4 train_hf_accelerate.py --batch_size 4 --epochs 150 --learning_rate 0.0006 --log_interval 100 --log_level INFO --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --species mouse --weight_decay 0.1\", exit code: 1' at 'status.message' failed to satisfy constraint: Member must satisfy regular expression pattern: .*",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Run(\n\u001b[1;32m      2\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mEXPERIMENT_NAME,\n\u001b[1;32m      3\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker_session,\n\u001b[1;32m      4\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mhyenaDNA_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingInput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43ms3_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS3_DATA_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:2680\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2680\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5760\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5740\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5741\u001b[0m \n\u001b[1;32m   5742\u001b[0m \u001b[38;5;124;03mIf the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5758\u001b[0m \u001b[38;5;124;03m    exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5759\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 5760\u001b[0m \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7989\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 7989\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:8042\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8037\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8038\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8039\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8040\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8041\u001b[0m     )\n\u001b[0;32m-> 8042\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8043\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8044\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8045\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8046\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job hyenaDNA-pretraining-2024-04-15-23-27-26-942: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"torchrun --nnodes 1 --nproc_per_node 4 train_hf_accelerate.py --batch_size 4 --epochs 150 --learning_rate 0.0006 --log_interval 100 --log_level INFO --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --species mouse --weight_decay 0.1\", exit code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Run(\n\u001b[1;32m      2\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mEXPERIMENT_NAME,\n\u001b[1;32m      3\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker_session,\n\u001b[1;32m      4\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m      5\u001b[0m     hyenaDNA_estimator\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      6\u001b[0m         {\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: TrainingInput(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/experiments/run.py:769\u001b[0m, in \u001b[0;36mRun.__exit__\u001b[0;34m(self, exc_type, exc_value, exc_traceback)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_component\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m _api_types\u001b[38;5;241m.\u001b[39mTrialComponentStatus(\n\u001b[1;32m    766\u001b[0m         primary_status\u001b[38;5;241m=\u001b[39m_TrialComponentStatusType\u001b[38;5;241m.\u001b[39mCompleted\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    767\u001b[0m     )\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/experiments/run.py:549\u001b[0m, in \u001b[0;36mRun.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Persist any data saved locally.\"\"\"\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# Update the trial component with additions from the Run object\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trial_component\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# Create Lineage entities for the artifacts\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lineage_artifact_tracker\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/experiments/trial_component.py:122\u001b[0m, in \u001b[0;36m_TrialComponent.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the state of this TrialComponent to SageMaker.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_api\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boto_update_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boto_update_members\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/apiutils/_base_types.py:227\u001b[0m, in \u001b[0;36mRecord._invoke_api\u001b[0;34m(self, boto_method, boto_method_members)\u001b[0m\n\u001b[1;32m    225\u001b[0m api_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_boto(api_values)\n\u001b[1;32m    226\u001b[0m api_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39msagemaker_client, boto_method)\n\u001b[0;32m--> 227\u001b[0m api_boto_response \u001b[38;5;241m=\u001b[39m \u001b[43mapi_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mapi_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_boto(api_boto_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the UpdateTrialComponent operation: 1 validation error detected: Value 'Error for Training job hyenaDNA-pretraining-2024-04-15-23-27-26-942: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"torchrun --nnodes 1 --nproc_per_node 4 train_hf_accelerate.py --batch_size 4 --epochs 150 --learning_rate 0.0006 --log_interval 100 --log_level INFO --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --species mouse --weight_decay 0.1\", exit code: 1' at 'status.message' failed to satisfy constraint: Member must satisfy regular expression pattern: .*"
     ]
    }
   ],
   "source": [
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    hyenaDNA_estimator.fit(\n",
    "        {\n",
    "            \"data\": TrainingInput(\n",
    "                s3_data=S3_DATA_URI, input_mode=\"File\"\n",
    "            ),\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5efe1b4b-f7d5-402c-93ed-0844a64fd581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hyenaDNA-pretraining-2024-04-15-23-08-08-173'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_job_name = hyenaDNA_estimator.latest_training_job.name\n",
    "training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa472a6e-7d94-4322-b9b7-90d9bfc9c92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59941ec0-9bb4-44f6-994d-eaa77b2adb10",
   "metadata": {},
   "source": [
    "### 5. Training Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e66b6-92ce-4f8c-bc75-e884ee71b98a",
   "metadata": {},
   "source": [
    "* In our training process we had pushed the training resulsts to Tensorboard. You can see them using SageMaker tensorboad application. Execuate following cell to get link to the the tensorboard application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e743bb7b-6791-45fe-b678-4c9bee380e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.interactive_apps.base_interactive_app:A presigned domain URL was generated. This is sensitive and should not be shared with others.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://studio-d-xgpxwyumgsdh.studio.us-east-1.sagemaker.aws/auth?token=eyJhbGciOiJIUzI1NiJ9.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.O_gqU_jziurfXLGz1ZveCVkFcBLBAszCqyXDLCvBL1A&redirect=TensorBoard&state=L3RlbnNvcmJvYXJkL2RlZmF1bHQvZGF0YS9wbHVnaW4vc2FnZW1ha2VyX2RhdGFfbWFuYWdlci9hZGRfZm9sZGVyX29yX2pvYj9SZWRpcmVjdD1UcnVlJk5hbWU9aHllbmFETkEtcHJldHJhaW5pbmctMjAyNC0wNC0xMS0wMS0xMS01MS0zODg='"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.interactive_apps.tensorboard import TensorBoardApp\n",
    "\n",
    "user_profile = \"shamika\"\n",
    "\n",
    "with open(\"/opt/ml/metadata/resource-metadata.json\", \"r\") as f:\n",
    "    app_metadata = json.loads(f.read())\n",
    "    sm_user_profile_name = app_metadata[\"SpaceName\"]\n",
    "    sm_domain_id = app_metadata[\"DomainId\"]\n",
    "\n",
    "tb_app = TensorBoardApp(REGION_NAME)\n",
    "tb_app.get_app_url(\n",
    "    training_job_name=training_job_name,\n",
    "    create_presigned_domain_url=True,           \n",
    "    domain_id=sm_domain_id,                 \n",
    "    user_profile_name=user_profile, \n",
    "    open_in_default_web_browser=False,\n",
    "    optional_create_presigned_url_kwargs={} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23d90b-f961-4f82-aa0c-46f7a6124c3a",
   "metadata": {},
   "source": [
    "### 6. Deploy trained model to an realtime endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "93e65ac9-4ebf-4866-8578-8d8706fe1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-04-06 17:23:11 Starting - Starting the training job\n",
      "2024-04-06 17:23:11 Pending - Preparing the instances for training\n",
      "2024-04-06 17:23:11 Downloading - Downloading the training image\n",
      "2024-04-06 17:23:11 Training - Training image download completed. Training in progress.\n",
      "2024-04-06 17:23:11 Uploading - Uploading generated training model\n",
      "2024-04-06 17:23:11 Completed - Instances not retained as a result of warmpool resource limits being exceeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "#training_job_name = \"hyenaDNA-pretraining-2024-04-06-06-23-26-412\"\n",
    "attached_estimator = Estimator.attach(training_job_name)\n",
    "\n",
    "model_data = attached_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "7f72c1f3-f658-4009-8fdd-c7e4d8bf548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to create a real-time endpoint\n",
    "endpoint_name = 'hyenaDNA-mouse-pretrained-ep'  \n",
    "pytorch_deployment_uri = f\"763104351884.dkr.ecr.{REGION}.amazonaws.com/pytorch-inference:2.2.0-gpu-py310-cu118-ubuntu20.04-sagemaker\"\n",
    "\n",
    "hyenaDNAModel = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    image_uri=pytorch_deployment_uri,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    name=endpoint_name,\n",
    "    env = {\n",
    "        'MMS_MAX_REQUEST_SIZE': '2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '900',\n",
    "        'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4808b94a-3079-40c9-bbe1-3fa596250803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz), script artifact (scripts/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-111918798052/hyenaDNA-mouse-pretrained-ep-v8/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: hyenaDNA-mouse-pretrained-ep-v8\n",
      "INFO:sagemaker:Creating endpoint-config with name hyenaDNA-mouse-pretrained-real-ep-v8\n",
      "INFO:sagemaker:Creating endpoint with name hyenaDNA-mouse-pretrained-real-ep-v8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "real_time_endpoint_name = \"hyenaDNA-mouse-pretrained-real-ep-v8\"\n",
    "env = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'7200', \n",
    "    'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "    'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "    'MMS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "    'MMS_MAX_REQUEST_SIZE':'2000000000'\n",
    "}\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "realtime_predictor = hyenaDNAModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.8xlarge\",\n",
    "    endpoint_name=real_time_endpoint_name,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477dc76d-980c-4a21-8be7-0feba1ecf108",
   "metadata": {},
   "source": [
    "### 7. Test the realtime endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd3233-f291-46e6-8818-138178857abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = [sample_genome_data[0]\n",
    "realtime_predictor.serializer = JSONSerializer()\n",
    "realtime_predictor.deserializer = JSONDeserializer()\n",
    "realtime_predictor.predict(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53aedd-ce70-4e15-8ccd-7c0a08fecc24",
   "metadata": {},
   "source": [
    "#### 7. Cleanup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9045b-1e15-41c9-85dc-775233388ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
