{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dfbb7c-2280-4b01-949a-91238a892d0b",
   "metadata": {},
   "source": [
    "### 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82308943-5300-4cc0-856c-879e1a6f24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.77 which is incompatible.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.1.2 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q --upgrade sagemaker boto3 awscli boto3 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e8d899-38ef-4e5b-b798-782d97c6144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46afa5b6-7d8e-4d4e-9be7-bedaf774694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed SageMaker role is arn:aws:iam::111918798052:role/DevelopmentRole\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "\n",
    "EXPERIMENT_NAME = \"hyenaDNA-pretraining\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd25e8-4256-49b5-97ef-b98ed7f0657e",
   "metadata": {},
   "source": [
    "### 1. Read the data from AWS HealthOmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0bebb2c-f925-4532-8c03-60195f26d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://shamika-hcls/datasources/genomics-data/species'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uri = \"s3://shamika-hcls/datasources/genomics-data/species\"\n",
    "data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4d0b7-0eb9-4757-aa89-aec2ca107115",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a68d1b-edb1-49ee-acae-076bdecff096",
   "metadata": {},
   "source": [
    "### 2.1 Define the training container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e3deae-0de2-499e-a60a-c76aaef138ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker\"\n",
    "pytorch_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a3e14-2cab-472a-96d9-808c39c4f8c8",
   "metadata": {},
   "source": [
    "#### 2.2 Define the training job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe0c7f6-0a53-483a-80ae-793ad58d7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'LongSafari/hyenadna-small-32k-seqlen-hf'\n",
    "\n",
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"epochs\": 10,\n",
    "    \"model_checkpoint\": MODEL_ID,\n",
    "    \"max_length\": 32_000,\n",
    "    \"batch_size\": 8, \n",
    "    \"logging_steps\": 2,\n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"weight_decay\" : 0.1,\n",
    "    \"log_level\" : \"INFO\",\n",
    "    \"log_interval\" : 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178423a-828b-4101-b540-5efe22b5e223",
   "metadata": {},
   "source": [
    "#### 2.3 Define Metrics to track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ad98da5-1d11-4eb4-8718-2e4cb4834872",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"Epoch: ([0-9.]*)\"},\n",
    "    {\"Name\": \"step\", \"Regex\": \"Step: ([0-9.]*)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"Training Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"train_perplexity\", \"Regex\": \"Training Perplexity: ([0-9.e-]*)\"},\n",
    "    {\n",
    "        \"Name\": \"train_samples_per_second\",\n",
    "        \"Regex\": \"Training Samples/sec: ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"train_tokens_per_second\",\n",
    "        \"Regex\": \"Training Tokens/sec: ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"Eval Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_perplexity\", \"Regex\": \"Eval Perplexity: ([0-9.e-]*)\"},\n",
    "    {\n",
    "        \"Name\": \"eval_samples_per_second\",\n",
    "        \"Regex\": \"Eval Samples/sec: ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\"Name\": \"eval_tokens_per_second\", \"Regex\": \"Eval Tokens/sec: ([0-9.e-]*)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18fb5e-e1cf-447b-84fa-eb80b347c9e1",
   "metadata": {},
   "source": [
    "#### 2.4 Define Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd8126d-605c-40c6-bce1-a68602f80e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyenaDNA_estimator = PyTorch(\n",
    "    base_job_name=\"hyenaDNA-pretraining\",\n",
    "    entry_point=\"train_hf.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    instance_type=\"ml.g5.8xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=pytorch_image_uri,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-benchmarking\"}],\n",
    "    keep_alive_period_in_seconds=1800\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04af1c-82ce-44ca-bce7-76d9776c6d95",
   "metadata": {},
   "source": [
    "#### 2.5 Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5544d-cffb-4a1a-bbe5-5d260c31bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: hyenaDNA-pretraining-2024-04-04-07-32-31-797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-04 07:32:32 Starting - Starting the training job...\n",
      "2024-04-04 07:32:50 Pending - Training job waiting for capacity...\n",
      "2024-04-04 07:33:05 Pending - Preparing the instances for training...\n",
      "2024-04-04 07:33:50 Downloading - Downloading input data...\n",
      "2024-04-04 07:34:15 Downloading - Downloading the training image...............\n",
      "2024-04-04 07:36:41 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:43,894 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:43,913 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:43,923 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:43,924 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:43,924 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-04 07:37:45,180 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting s3torchconnector (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnector-1.2.2.tar.gz (55 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.6/55.6 kB 7.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.26.1 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.3/100.3 kB 16.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting biopython==1.73 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading biopython-1.73.tar.gz (15.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 88.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pyfaidx==0.8.1.1 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading pyfaidx-0.8.1.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (3.13.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (4.66.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (68.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (6.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from s3torchconnector->-r requirements.txt (line 3)) (2.2.0)\u001b[0m\n",
      "\u001b[34mCollecting s3torchconnectorclient>=1.2.2 (from s3torchconnector->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnectorclient-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->-r requirements.txt (line 4)) (2024.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->-r requirements.txt (line 4)) (4.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->s3torchconnector->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->s3torchconnector->-r requirements.txt (line 3)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->s3torchconnector->-r requirements.txt (line 3)) (3.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->pyfaidx==0.8.1.1->-r requirements.txt (line 6)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->s3torchconnector->-r requirements.txt (line 3)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->s3torchconnector->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 126.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyfaidx-0.8.1.1-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 388.9/388.9 kB 47.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.0/774.0 kB 70.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading s3torchconnectorclient-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 109.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 124.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: biopython, s3torchconnector\u001b[0m\n",
      "\u001b[34mBuilding wheel for biopython (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for biopython (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for biopython: filename=biopython-1.73-cp310-cp310-linux_x86_64.whl size=2171090 sha256=d76ccde04f8219f1e59965e9245a80efe9b91afdfb4d4cb2939fb03f3192bec8\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/23/52/b9/1339217891a98d1331331b3d9159dae6f9116e40715a56a950\u001b[0m\n",
      "\u001b[34mBuilding wheel for s3torchconnector (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for s3torchconnector (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for s3torchconnector: filename=s3torchconnector-1.2.2-py3-none-any.whl size=60742 sha256=b88405218f09b0d0ffa9cfa491c336b4314c8087e3728708f515c3b487261d51\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/d4/a9/6c/e8e9b0ee760a732d8145e3072bc61c380d273cd82a6c9d98f0\u001b[0m\n",
      "\u001b[34mSuccessfully built biopython s3torchconnector\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, s3torchconnectorclient, regex, biopython, pyfaidx, huggingface-hub, transformers, s3torchconnector\u001b[0m\n",
      "\u001b[34mSuccessfully installed biopython-1.73 huggingface-hub-0.22.2 pyfaidx-0.8.1.1 regex-2023.12.25 s3torchconnector-1.2.2 s3torchconnectorclient-1.2.2 tokenizers-0.13.3 transformers-4.26.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:05,974 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:05,974 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:06,016 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:06,047 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:06,057 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:06,077 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 07:38:06,088 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.8xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.8xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"epochs\": 10,\n",
      "        \"learning_rate\": 0.0006,\n",
      "        \"log_interval\": 100,\n",
      "        \"log_level\": \"INFO\",\n",
      "        \"logging_steps\": 2,\n",
      "        \"max_length\": 32000,\n",
      "        \"model_checkpoint\": \"LongSafari/hyenadna-small-32k-seqlen-hf\",\n",
      "        \"weight_decay\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"hyenaDNA-pretraining-2024-04-04-07-32-31-797\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-04-07-32-31-797/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_hf\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_hf.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":8,\"epochs\":10,\"learning_rate\":0.0006,\"log_interval\":100,\"log_level\":\"INFO\",\"logging_steps\":2,\"max_length\":32000,\"model_checkpoint\":\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"weight_decay\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_hf.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.8xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.8xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.8xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_hf\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-04-07-32-31-797/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.8xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.8xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":8,\"epochs\":10,\"learning_rate\":0.0006,\"log_interval\":100,\"log_level\":\"INFO\",\"logging_steps\":2,\"max_length\":32000,\"model_checkpoint\":\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"weight_decay\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"hyenaDNA-pretraining-2024-04-04-07-32-31-797\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-04-07-32-31-797/source/sourcedir.tar.gz\",\"module_name\":\"train_hf\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_hf.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"8\",\"--epochs\",\"10\",\"--learning_rate\",\"0.0006\",\"--log_interval\",\"100\",\"--log_level\",\"INFO\",\"--logging_steps\",\"2\",\"--max_length\",\"32000\",\"--model_checkpoint\",\"LongSafari/hyenadna-small-32k-seqlen-hf\",\"--weight_decay\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0006\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_LEVEL=INFO\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LENGTH=32000\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_CHECKPOINT=LongSafari/hyenadna-small-32k-seqlen-hf\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 1 train_hf.py --batch_size 8 --epochs 10 --learning_rate 0.0006 --log_interval 100 --log_level INFO --logging_steps 2 --max_length 32000 --model_checkpoint LongSafari/hyenadna-small-32k-seqlen-hf --weight_decay 0.1\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_hf.py\", line 157, in <module>\u001b[0m\n",
      "\u001b[34margs = parse_arguments()\n",
      "  File \"/opt/ml/code/train_hf.py\", line 38, in parse_arguments\n",
      "    parser.add_argument(\"--data_dir\", type=str, default=os.environ[\"SM_CHANNEL_DATA\"], help=\"Path to dataset.\")\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.10/os.py\", line 680, in __getitem__\u001b[0m\n",
      "\u001b[34mraise KeyError(key) from None\u001b[0m\n",
      "\u001b[34mKeyError: 'SM_CHANNEL_DATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    hyenaDNA_estimator.fit(\n",
    "        {\n",
    "            \"training\": TrainingInput(\n",
    "                s3_data=data_uri, input_mode=\"File\"\n",
    "            ),\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c15a7-5252-4d92-b277-59924c5a165c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd36a40-e7ac-4ac0-a881-4edfdbc14a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
