{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dfbb7c-2280-4b01-949a-91238a892d0b",
   "metadata": {},
   "source": [
    "### 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82308943-5300-4cc0-856c-879e1a6f24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.80 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q --upgrade sagemaker boto3 awscli boto3 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e8d899-38ef-4e5b-b798-782d97c6144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from time import strftime\n",
    "\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46afa5b6-7d8e-4d4e-9be7-bedaf774694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed SageMaker role is arn:aws:iam::111918798052:role/DevelopmentRole\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "\n",
    "EXPERIMENT_NAME = \"hyenaDNA-pretraining\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd25e8-4256-49b5-97ef-b98ed7f0657e",
   "metadata": {},
   "source": [
    "### 1. Read the data from AWS HealthOmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bebb2c-f925-4532-8c03-60195f26d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_store_id = \"4308389581\"\n",
    "\n",
    "!aws omics get-sequence-store --id {seq_store_id} > /tmp/seq-store.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb730083-8bdf-4ffe-a4df-f85d9b14a018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://111918798052-4308389-m7r4grkrg7nkpmf5swnjwf1iqsdieuse1b-s3alias/111918798052/sequenceStore/4308389581/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_store_info = json.loads(Path(\"/tmp/seq-store.json\").read_text())\n",
    "s3AccessPoint = seq_store_info[\"s3Access\"][\"s3Uri\"]\n",
    "s3AccessPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a09d-e518-4c0d-a8cd-ff26b05ea7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab4d0b7-0eb9-4757-aa89-aec2ca107115",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a68d1b-edb1-49ee-acae-076bdecff096",
   "metadata": {},
   "source": [
    "### 2.1 Define the training container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e3deae-0de2-499e-a60a-c76aaef138ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker\"\n",
    "pytorch_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a3e14-2cab-472a-96d9-808c39c4f8c8",
   "metadata": {},
   "source": [
    "#### 2.2 Define the training job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfe0c7f6-0a53-483a-80ae-793ad58d7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'LongSafari/hyenadna-small-32k-seqlen-hf'\n",
    "\n",
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"species\" : \"mouse\",\n",
    "    \"epochs\": 200,\n",
    "    \"model_checkpoint\": MODEL_ID,\n",
    "    \"max_length\": 32_000,\n",
    "    \"batch_size\": 8, \n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"weight_decay\" : 0.1,\n",
    "    \"log_level\" : \"INFO\",\n",
    "    \"log_interval\" : 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178423a-828b-4101-b540-5efe22b5e223",
   "metadata": {},
   "source": [
    "#### 2.3 Define Metrics to track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ad98da5-1d11-4eb4-8718-2e4cb4834872",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"Epoch: ([0-9.]*)\"},\n",
    "    {\"Name\": \"step\", \"Regex\": \"Step: ([0-9.]*)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"Train Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"train_perplexity\", \"Regex\": \"Train perplexity: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"Eval Average Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_perplexity\", \"Regex\": \"Eval perplexity: ([0-9.e-]*)\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18fb5e-e1cf-447b-84fa-eb80b347c9e1",
   "metadata": {},
   "source": [
    "#### 2.4 Define Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcd8126d-605c-40c6-bce1-a68602f80e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyenaDNA_estimator = PyTorch(\n",
    "    base_job_name=\"hyenaDNA-pretraining\",\n",
    "    entry_point=\"train_hf.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    instance_type=\"ml.g5.8xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=pytorch_image_uri,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"genomics-model-pretraining\"}],\n",
    "    keep_alive_period_in_seconds=1800\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04af1c-82ce-44ca-bce7-76d9776c6d95",
   "metadata": {},
   "source": [
    "#### 2.5 Start Training with Distributed Data Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f2b5544d-cffb-4a1a-bbe5-5d260c31bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: hyenaDNA-pretraining-2024-04-09-03-59-01-633\n"
     ]
    }
   ],
   "source": [
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    hyenaDNA_estimator.fit(\n",
    "        {\n",
    "            \"data\": TrainingInput(\n",
    "                s3_data=data_uri, input_mode=\"File\"\n",
    "            ),\n",
    "        },\n",
    "        wait=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59941ec0-9bb4-44f6-994d-eaa77b2adb10",
   "metadata": {},
   "source": [
    "### 5. Training Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce2c0f-6ca5-43b1-91b1-158c5a30ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c23d90b-f961-4f82-aa0c-46f7a6124c3a",
   "metadata": {},
   "source": [
    "### 6. Deploy to an Endpoint and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e65ac9-4ebf-4866-8578-8d8706fe1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-04-06 17:23:11 Starting - Starting the training job\n",
      "2024-04-06 17:23:11 Pending - Preparing the instances for training\n",
      "2024-04-06 17:23:11 Downloading - Downloading the training image\n",
      "2024-04-06 17:23:11 Training - Training image download completed. Training in progress.\n",
      "2024-04-06 17:23:11 Uploading - Uploading generated training model\n",
      "2024-04-06 17:23:11 Completed - Instances not retained as a result of warmpool resource limits being exceeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "training_job_name = \"hyenaDNA-pretraining-2024-04-06-06-23-26-412\"\n",
    "attached_estimator = Estimator.attach(training_job_name)\n",
    "\n",
    "model_data = attached_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b6aceaf-d94c-4310-94bc-aaa226872526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LongSafari/hyenadna-small-32k-seqlen-hf'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f72c1f3-f658-4009-8fdd-c7e4d8bf548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to create a real-time endpoint\n",
    "endpoint_name = 'hyenaDNA-mouse-pretrained-ep'  \n",
    "\n",
    "hyenaDNAModel = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    framework_version=\"2.1\",\n",
    "    py_version=\"py310\",\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    name=endpoint_name,\n",
    "    env={\n",
    "        'SAGEMAKER_MODEL_SERVER_TIMEOUT':'3600', \n",
    "        'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'MMS_MAX_REQUEST_SIZE':'2000000000'\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac44aa8-836d-4ae2-92e5-222e2031ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = hyenaDNAModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    env={\n",
    "        'SAGEMAKER_MODEL_SERVER_TIMEOUT':'3600', \n",
    "        'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'MMS_MAX_REQUEST_SIZE':'2000000000'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33816d67-a515-4bf4-9148-e847472700b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3 import s3_path_join\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "async_endpoint_name = \"hyenaDNA-mouse-pretrained-aync-ep\"\n",
    "\n",
    "# create async endpoint configuration\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path= s3_path_join(\n",
    "        \"s3://\", S3_BUCKET, \"async_inference/output\"\n",
    "    ),  # Where our results will be stored\n",
    "    # Add nofitication SNS if needed\n",
    "    notification_config={\n",
    "        # \"SuccessTopic\": \"PUT YOUR SUCCESS SNS TOPIC ARN\",\n",
    "        # \"ErrorTopic\": \"PUT YOUR ERROR SNS TOPIC ARN\",\n",
    "    },  #  Notification configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "28a3ff8e-161f-478b-aeb1-b7b471c43a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz), script artifact (scripts/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-111918798052/hyenaDNA-mouse-pretrained-ep/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: hyenaDNA-mouse-pretrained-ep\n",
      "WARNING:sagemaker:Using already existing model: hyenaDNA-mouse-pretrained-ep\n",
      "INFO:sagemaker:Creating endpoint-config with name hyenaDNA-mouse-pretrained-aync-ep\n",
      "INFO:sagemaker:Creating endpoint with name hyenaDNA-mouse-pretrained-aync-ep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "env = {\"MODEL_SERVER_WORKERS\": \"1\"}\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "async_predictor = hyenaDNAModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    async_inference_config=async_config,\n",
    "    endpoint_name=async_endpoint_name,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88ffdc2a-d678-481d-89ca-d3ca63e62cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(\"./sample_mouse_data.json\", S3_BUCKET, \"async_inference/input/sample_mouse_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e2a37b81-bf36-4e36-a08e-66832606000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Assuming async_predictor is your deployed predictor object\n",
    "async_predictor.serializer = JSONSerializer()\n",
    "async_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95168a52-4f57-48e2-9a28-cd352e08c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = async_predictor.predict_async([sample_genome_data[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ec21e85-0120-4dc4-9791-ad83e2c61228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.async_inference.async_inference_response.AsyncInferenceResponse object at 0x7f7fbc3bdab0>\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"s3://\", S3_BUCKET, \"async_inference/input/sample_mouse_data.json\"\n",
    "    # \"language\": \"pl\"\n",
    "}\n",
    "\n",
    "res = async_predictor.predict_async(data=data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8fc782c2-3797-42c0-bcd2-e742b65d6a98",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NumpyDeserializer cannot read content type binary/octet-stream.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/async_inference/async_inference_response.py:116\u001b[0m, in \u001b[0;36mAsyncInferenceResponse._get_result_from_s3_output_failure_paths\u001b[0;34m(self, output_path, failure_path)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor_async\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_async\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Since it is async inference, get_results is looking for the output_path\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If the inference completed, you'll get the results from the output path. Otherwise, you'll get error that the output_path file doesn't exist\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/async_inference/async_inference_response.py:82\u001b[0m, in \u001b[0;36mAsyncInferenceResponse.get_result\u001b[0;34m(self, waiter_config)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m waiter_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result_from_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfailure_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_async\u001b[38;5;241m.\u001b[39m_wait_for_output(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailure_path, waiter_config\n\u001b[1;32m     86\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/async_inference/async_inference_response.py:92\u001b[0m, in \u001b[0;36mAsyncInferenceResponse._get_result_from_s3\u001b[0;34m(self, output_path, failure_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve output based on the presense of failure_path\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failure_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result_from_s3_output_failure_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfailure_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_from_s3_output_path(output_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/async_inference/async_inference_response.py:125\u001b[0m, in \u001b[0;36mAsyncInferenceResponse._get_result_from_s3_output_failure_paths\u001b[0;34m(self, output_path, failure_path)\u001b[0m\n\u001b[1;32m    121\u001b[0m     failure_bucket, failure_key \u001b[38;5;241m=\u001b[39m parse_s3_url(failure_path)\n\u001b[1;32m    122\u001b[0m     failure_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_async\u001b[38;5;241m.\u001b[39ms3_client\u001b[38;5;241m.\u001b[39mget_object(\n\u001b[1;32m    123\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mfailure_bucket, Key\u001b[38;5;241m=\u001b[39mfailure_key\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m     failure_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor_async\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfailure_response\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AsyncInferenceModelError(message\u001b[38;5;241m=\u001b[39mfailure_response)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:219\u001b[0m, in \u001b[0;36mPredictor._handle_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    217\u001b[0m response_body \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    218\u001b[0m content_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/base_deserializers.py:239\u001b[0m, in \u001b[0;36mNumpyDeserializer.deserialize\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     stream\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m cannot read content type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, content_type))\n",
      "\u001b[0;31mValueError\u001b[0m: NumpyDeserializer cannot read content type binary/octet-stream."
     ]
    }
   ],
   "source": [
    "# Since it is async inference, get_results is looking for the output_path\n",
    "# If the inference completed, you'll get the results from the output path. Otherwise, you'll get error that the output_path file doesn't exist\n",
    "res.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "14a4d059-1467-4083-9943-3c81b11c85c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_genome_data = []\n",
    "with open(\"./sample_mouse_data.json\", 'r') as file:\n",
    "    for line in file:\n",
    "        sample_genome_data.append(json.loads(line))\n",
    "len(sample_genome_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "344b655c-072a-4256-81a2-6e2753860eeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"{\n  \"code\": 500,\n  \"type\": \"InternalServerException\",\n  \"message\": \"Worker died.\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/hyenaDNA-mouse-pretrained-ep-2024-04-09-17-38-25-169 in account 111918798052 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m predictor\u001b[38;5;241m.\u001b[39mserializer \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mserializers\u001b[38;5;241m.\u001b[39mJSONSerializer()\n\u001b[1;32m      2\u001b[0m predictor\u001b[38;5;241m.\u001b[39mdeserializer \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mdeserializers\u001b[38;5;241m.\u001b[39mJSONDeserializer()\n\u001b[0;32m----> 4\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_genome_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"{\n  \"code\": 500,\n  \"type\": \"InternalServerException\",\n  \"message\": \"Worker died.\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/hyenaDNA-mouse-pretrained-ep-2024-04-09-17-38-25-169 in account 111918798052 for more information."
     ]
    }
   ],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "prediction = predictor.predict([sample_genome_data[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11346c4e-2cb0-4dfd-a8b0-fc8e610612de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "972e4f9d-195e-449f-97bb-4ee413dab929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_genome_data = []\n",
    "with open(\"./sample_mouse_data.json\", 'r') as file:\n",
    "    for line in file:\n",
    "        sample_genome_data.append(json.loads(line))\n",
    "len(sample_genome_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85086cb5-da99-48cd-974d-700e3a1dbc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_genome_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b823bda1-fa84-44c6-b13a-8672a85a06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = sample_genome_data[0]\n",
    "output = sample_genome_data[0]\n",
    "schema = SchemaBuilder(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f65cc09c-4dc7-4df5-877b-e290f16bf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sagemaker.serve import InferenceSpec\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# custom inference spec\n",
    "class HyenaDNAInfSpec(InferenceSpec):\n",
    "    def invoke(self, input_object: object, model: object):       \n",
    "        with torch.no_grad():\n",
    "            output = model(input_object)\n",
    "        return output\n",
    "        \n",
    "    def load(self, model_dir: str):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID, \n",
    "            torch_dtype=torch.bfloat16, \n",
    "            device_map=\"auto\", \n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        checkpoint = torch.load(model_dir + '/checkpoint.pt', map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "spec = HyenaDNAInfSpec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6bffc38-c16a-42f2-9096-8cbb9015d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serve.mode.function_pointers import Mode\n",
    "model_builder = ModelBuilder(\n",
    "    mode=Mode.SAGEMAKER_ENDPOINT,  # you can change it to Mode.LOCAL_CONTAINER for local testing\n",
    "    model_path=model_data,\n",
    "    inference_spec=spec,\n",
    "    schema_builder=schema,\n",
    "    role_arn= SAGEMAKER_EXECUTION_ROLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d717366-cf85-48ce-b46f-e258b87638c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: WARNING:     model_path provided with no image_uri. Attempting to autodetect the image                    by loading the model using inference_spec.load()...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 's3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz/checkpoint.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/serve/builder/model_builder.py:656\u001b[0m, in \u001b[0;36mModelBuilder.build\u001b[0;34m(self, mode, role_arn, sagemaker_session)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_validations()\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_server \u001b[38;5;241m==\u001b[39m ModelServer\u001b[38;5;241m.\u001b[39mTORCHSERVE:\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_for_torchserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_server \u001b[38;5;241m==\u001b[39m ModelServer\u001b[38;5;241m.\u001b[39mTRITON:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_for_triton()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/serve/builder/model_builder.py:553\u001b[0m, in \u001b[0;36mModelBuilder._build_for_torchserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build the model for torchserve\"\"\"\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_model_inference_spec()\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_detect_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecret_key \u001b[38;5;241m=\u001b[39m prepare_for_torchserve(\n\u001b[1;32m    556\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path,\n\u001b[1;32m    557\u001b[0m     shared_libs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_libs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m     inference_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_spec,\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_mode()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/serve/builder/model_builder.py:330\u001b[0m, in \u001b[0;36mModelBuilder._auto_detect_container\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_spec:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# TODO: this won't work for larger image.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# Fail and let the customer include the image uri\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path provided with no image_uri. Attempting to autodetect the image\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124m            by loading the model using inference_spec.load()...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_uri \u001b[38;5;241m=\u001b[39m auto_detect_container(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mboto_region_name,\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_type,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot detect required model or inference spec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m, in \u001b[0;36mHyenaDNAInfSpec.load\u001b[0;34m(self, model_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_dir: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     15\u001b[0m         MODEL_ID, \n\u001b[1;32m     16\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, \n\u001b[1;32m     17\u001b[0m         device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     18\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[0;32m---> 20\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/checkpoint.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 's3://sagemaker-us-east-1-111918798052/hyenaDNA-pretraining-2024-04-06-06-23-26-412/output/model.tar.gz/checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "model = model_builder.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a50c9e-8238-4863-825b-49c7079767c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
