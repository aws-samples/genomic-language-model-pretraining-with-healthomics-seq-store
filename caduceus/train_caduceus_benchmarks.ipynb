{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1245dc01-ebf2-4c08-8fd4-02f35048150b",
   "metadata": {},
   "source": [
    "# Fine-Tune the Caduceus Model for Genomic Benchmark Tasks\n",
    "\n",
    "In this scenario, we will be fine-tuning a pre-trained [Caduceus](https://caduceus-dna.github.io/) model (Schiff, Y. et al., 2024) for a range of DNA sequence classification tasks published on Genomic Benchmarks (Grešová, K., Martinek, V., Čechák, D. et al., 2023).\n",
    "\n",
    "Like HyenaDNA, Caduceus is a State Space Model (SSM), allowing for highly efficient training of long context windows. SSM's have been shown to exceed the performance of attention-based models like DNABERT with orders of magnitude fewer parameters.\n",
    "\n",
    "Caduceus is based on (1) a bi-directional implementation of the Mamba block (BiMamba). Mamba's *selective state space* implementation has shown promising scaling performance compared to Transformers. (2) The Caduceus model also introduces a novel module to enforce **Reverse Complement (RC) Equivariance** (MambaDNA). \n",
    "\n",
    "![Caduceus Comparison](https://caduceus-dna.github.io/static/images/caducues_comparison.png)\n",
    "\n",
    "At this time, Caduceus represented the state of the art performance on all of the Genomic Benchmark tasks - even surpassing HyenaDNA.\n",
    "\n",
    "![Results](https://caduceus-dna.github.io/static/images/experiments/nt_benchmark.png)\n",
    "\n",
    "In this notebook, we will attempt to replicate some of the results from the paper by fine-tuning a smaller, pre-trained variant of Caduceus (with an added classification head) on a range of Genomic Benchmark tasks. There are (3) key ideas to look out for in this SageMaker Training Job.\n",
    "\n",
    "1. **AWS HealthOmics Integration (Optional)** - If you followed the [`load_genomic_benchmarks_to_omics.ipynb`](load_genomic_benchmarks_to_omics.ipynb) notebook, you can access those read sets as fine-tuning training data. This demonstrates a workflow for HCLS organizations who may have proprietary DNA sequence datasets that they wish to use to train their own models. Otherwise, the benchmark datasets will be loaded directly from HuggingFace.\n",
    "2. **Distributed Training with Distributed Data Parallel (DDP)** - the training script is setup to run DDP in multi-GPU instances. In this scenario, the full model weights are loaded onto each GPU, but the dataset is partitioned. At each step, the nodes share their gradients, all-reduce fashion.\n",
    "3. **Parameter Efficient Fine-Tuning (PEFT)** - you can also choose to run the fine-tuning via PEFT, which significantly limits how many of the parameters will actually be learnable during fine-tuning (in our case, only about 9-10% of the parameters will be trainable). This greatly reduces memory requirements and speeds up performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69465a-6e0e-440b-949c-781b4a6a64a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "REGION_NAME = sess.boto_region_name\n",
    "S3_BUCKET = sess.default_bucket()\n",
    "ACCOUNT_ID = sess.account_id()\n",
    "\n",
    "print(role, S3_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91672fcf-724b-452e-85ab-fe005ee70898",
   "metadata": {},
   "source": [
    "## 1. (Optional) Integration with AWS HealthOmics\n",
    "\n",
    "**Note: This step is not required in order to run the fine-tuning job for Genomic Benchmarks datasets. If you do not want to use HealthOmics to store the sequences, we will alternatively load them directly from [HuggingFace](https://huggingface.co/katarinagresova).**\n",
    "\n",
    "If you followed the optional [`load_genomic_benchmarks_to_omics.ipynb`](load_genomic_benchmarks_to_omics.ipynb) notebook, you can access those read sets as fine-tuning training data.\n",
    "\n",
    "At runtime, the FASTQ read sets will be loaded from the sequence store and parsed into a [`datasets.Dataset`](https://huggingface.co/docs/datasets/en/index). \n",
    "\n",
    "If this is the case, there is one additional step required to ensure that the SageMaker Execution role has the appropriate access to the read sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c6815-1a4a-49db-9b93-ebf00368d093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optional - get from create_omics_dataset.ipynb or replace with None\n",
    "# SEQUENCE_STORE_ID = 9757315158\n",
    "SEQUENCE_STORE_ID = None  # to load datasets directly from HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2555c-a818-46b6-a82f-62f5d492e876",
   "metadata": {},
   "source": [
    "If you have a sequence store ID and have loaded in the readsets for the benchmarks, the output of the following cell is the policy that you should attach to the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07672-4dda-48fd-85e8-9e765ba7512b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using Omics, make sure that the execution role has access to GetReadSet and ListReadSets\n",
    "\n",
    "if SEQUENCE_STORE_ID:\n",
    "    omics_policy = json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"omics:GetReadSet\", \n",
    "                    \"omics:ListReadSets\",\n",
    "                ],\n",
    "                \"Resource\": f\"arn:aws:omics:{REGION_NAME}:767398100082:sequenceStore/{SEQUENCE_STORE_ID}/readSet/*\"\n",
    "            },\n",
    "        ]\n",
    "    }, indent=2)\n",
    "    print(omics_policy)\n",
    "    print(sagemaker.get_execution_role())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9b246-b6a9-4733-97f9-bb1a7b8c57ac",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "The [training script](scripts/train_caduceus_dist.py) can be configured for any of the Benchmark tasks with a range of different hyperparameters. \n",
    "\n",
    "Feel free to experiment with different learning rates/schedulers, pre-trained model variants, and PEFT configurations. \n",
    "\n",
    "Below is a table of the accuracies I was able to produce on some of the tasks, compared to HyenaDNA and DNABERT.\n",
    "\n",
    "|           Task           | Caduceus-1.93M | HyenaDNA-6.6M [1]\t| DNABERT-110M [2] |\n",
    "| ------------------------ | -------------- | ------------- | ------------ |\n",
    "| Human vs. Worm\t       | 0.964\t        | 0.966\t        | 0.965        |\n",
    "| Human Enhancers Cohn\t   | 0.747\t        | 0.742\t        | 0.740        |\n",
    "| Human Enhancers Ensembl  | 0.874\t        | 0.892\t        | 0.857        | \n",
    "| Human Nontata Promoters  | 0.905\t        | 0.966\t        | 0.856        | \n",
    "| Mouse Enhancers          | 0.723\t        | 0.851\t        | 0.669        | \n",
    "\n",
    "Even with the PEFT configuration and when using the smaller 1.93M variant of Caduceus, we are generally able to match or exceed the HyenaDNA results. **Perhaps even more exciting is that we beat the DNABERT results - a model with >50x as many parameters!**\n",
    "\n",
    "[[1] Nguyen, et. al, 2023](https://arxiv.org/pdf/2306.15794)\n",
    "\n",
    "[[2] Zhou, et. al, 2023](https://arxiv.org/pdf/2306.15006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ce1c7-3927-4254-84b3-756b29ec7b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "task_config = {\n",
    "    \"demo_human_or_worm\": {\"epochs\": 4},\n",
    "    \"dummy_mouse_enhancers_ensembl\": {\"epochs\": 100},\n",
    "    \"human_enhancers_cohn\": {\"epochs\": 20},\n",
    "    \"human_enhancers_ensembl\": {\"epochs\": 25},\n",
    "    \"human_nontata_promoters\": {\"epochs\": 25},\n",
    "    \"human_ocr_ensembl\": {\"epochs\": 5},\n",
    "}\n",
    "\n",
    "task = \"dummy_mouse_enhancers_ensembl\"\n",
    "\n",
    "print(f\"TASK: {task}\")\n",
    "\n",
    "# hyperparameters which are passed to the training job\n",
    "hyperparameters = {\n",
    "    \"epochs\": task_config[task][\"epochs\"],\n",
    "    \"per_device_train_batch_size\": 128,\n",
    "    # \"model_name\": \"kuleshov-group/caduceus-ps_seqlen-1k_d_model-118_n_layer-4_lr-8e-3\",  # tiny ~0.47M \n",
    "    # \"model_name\": \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\",       # large ~7.73M\n",
    "    \"model_name\": \"kuleshov-group/caduceus-ps_seqlen-1k_d_model-256_n_layer-4_lr-8e-3\",  # small ~1.93M  \n",
    "    \"benchmark_name\": task,\n",
    "    \"peft\": True,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"sequence_store_id\": SEQUENCE_STORE_ID,\n",
    "    \"region\": REGION_NAME,\n",
    "}\n",
    "\n",
    "now_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "LOG_DIR = \"/opt/ml/output/tensorboard\"\n",
    "TRAINING_JOB_NAME = f\"caduceus-{hyperparameters['benchmark_name'].replace('_', '-')}-{now_str}\"\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://\", S3_BUCKET, \"sagemaker-output\", \"training\", TRAINING_JOB_NAME\n",
    ")\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=os.path.join(output_path, 'tensorboard'),\n",
    "    container_local_output_path=LOG_DIR\n",
    ")\n",
    "\n",
    "image_uri = pytorch_image_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker\"\n",
    "\n",
    "# create the Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_caduceus_dist.py\",\n",
    "    source_dir='./scripts',\n",
    "    instance_type=\"ml.g5.12xlarge\",  # multi-GPU to take advantage of data parallel\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c7437-b54b-45a9-9796-a22b80882ca6",
   "metadata": {},
   "source": [
    "\n",
    "By default, the `estimator.fit()` method below will stream the job logs to the notebook synchronously, but you can submit the job asynchronously by setting `wait=False`, e.g. \n",
    "\n",
    "`estimator.fit(..., wait=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ec917-3a0a-4777-b7f1-b5658aa7695d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the training job synchronously\n",
    "estimator.fit(job_name=TRAINING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57014d15-80ae-494c-a9f0-da97ef4e7231",
   "metadata": {},
   "source": [
    "For monitoring results, the job has been configured to log performance metrics to [TensorBoard](https://docs.aws.amazon.com/sagemaker/latest/dg/tensorboard-on-sagemaker.html). \n",
    "\n",
    "![TensorBoard](images/tensorboard.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
