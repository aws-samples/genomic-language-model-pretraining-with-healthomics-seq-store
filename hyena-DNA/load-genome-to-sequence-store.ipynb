{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9bb7c3-a88a-4be2-8922-67887ff3692f",
   "metadata": {},
   "source": [
    "# Load a genome to the HealthOmics Sequence Store\n",
    "---\n",
    "This notebook demonstrates how to download a public genome to a HealthOmics sequence store. This is \n",
    "in preparation for later pretraining of a genomic language model (HyenaDNA).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. In order to download and process the data you should make sure that this notebook has access to at least\n",
    "64Gb of disc storage.\n",
    "2. The notebook needs to have permissions to access S3. To add these permissions, follow [these instructions](https://docs.aws.amazon.com/omics/latest/dev/manage-reference-store.html). You\n",
    "can see what your notebook's execution role by running this: `print(sagemaker.get_execution_role())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a580f6-a975-49b1-88c5-dba78ca02f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -qU transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e1443-b300-4702-9caa-78c70a500e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib\n",
    "from functools import partial\n",
    "from time import sleep\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith(\"/hyena-DNA\"):\n",
    "    repo_base = cwd.rpartition(\"/\")[0]\n",
    "elif cwd.endswith(\"healthomics-seq-store\"):\n",
    "    repo_base = cwd\n",
    "else:\n",
    "    raise Exception(f\"port me: {cwd}\")\n",
    "print(f\"repo base: {repo_base}\")\n",
    "!cp {repo_base}/utilities.py {repo_base}/evo-model/scripts\n",
    "sys.path.append(repo_base)\n",
    "import utilities as u\n",
    "# to reload the utilities without restarting the kernel, use this: importlib.reload(u)\n",
    "\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d59a1f-bef8-41d0-95b3-2c44d01f9194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_store_name = \"mouse genome\"\n",
    "# This is where we upload the compressed FASTQ files:\n",
    "bucket_name = \"sgh-misc\"\n",
    "prefix = \"data/mouse/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5672e55-ac2a-4da6-bc4a-ebf6a91f4357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import_job_role_arn = \"arn:aws:iam::111918798052:role/OmicsImportRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9796c7-ed01-4cdd-bf1b-7c35e2bf9eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omics = boto3.client(\"omics\")\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e7e06-f587-459b-9797-ca4fea9592df",
   "metadata": {},
   "source": [
    "First, we download a [mouse reference genome](https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_921998355.2/)\n",
    "from Genbank onto the local disk (this should take less than a minute with a broadband connection). There should\n",
    "be one (compressed) FASTA file per chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd6bbd-a541-4e8d-a532-ce7accecd60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -P ~/mouse/ -r -nH --cut-dirs=11 --no-parent ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/vertebrate_mammalian/Mus_musculus/latest_assembly_versions/GCA_921998355.2_A_J_v3/GCA_921998355.2_A_J_v3_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822dd0f-7a0d-4669-bb20-b34ab3ef1807",
   "metadata": {},
   "source": [
    "If the above command finishes successfully then you should be able to verify the results\n",
    "and see something similar to this:\n",
    "```bash\n",
    "sh-4.2$ ls -l ~/mouse\n",
    "total 703768\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 36522179 Jul 19  2022 chr10.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 34213890 Jul 19  2022 chr11.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 32615588 Jul 19  2022 chr12.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 32962659 Jul 19  2022 chr13.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 32646782 Jul 19  2022 chr14.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 29093156 Jul 19  2022 chr15.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 27225255 Jul 19  2022 chr16.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 26229898 Jul 19  2022 chr17.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 25313610 Jul 19  2022 chr18.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 16757414 Jul 19  2022 chr19.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 55286326 Jul 19  2022 chr1.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 50752623 Jul 19  2022 chr2.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 44959307 Jul 19  2022 chr3.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 42502452 Jul 19  2022 chr4.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 41498510 Jul 19  2022 chr5.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 41907927 Jul 19  2022 chr6.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 38157680 Jul 19  2022 chr7.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 35790409 Jul 19  2022 chr8.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 34764818 Jul 19  2022 chr9.fna.gz\n",
    "-rw-rw-r-- 1 ec2-user ec2-user 41422059 Jul 19  2022 chrX.fna.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ce7e9-a169-4f61-bb0b-aa808e49a50e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = Path.home() / \"SageMaker\" / \"mouse\"\n",
    "if not data.exists():\n",
    "    data = Path.home() / \"mouse\"\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240fa82-efcf-4aa7-ba92-e0ffe597733e",
   "metadata": {},
   "source": [
    "Next, we uncompress the compressed FASTA (\".fna.gz\") files to create FASTA (\".fna\") files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f3553-be5f-4821-8da3-a37a6774d568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasta_files = u.convert_directory(data, suffix=\".fna.gz\",\n",
    "                                  convertor=partial(u.gunzip_file,\n",
    "                                                    suffix=\".gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b500d-c455-4318-abec-3065e44ed5c8",
   "metadata": {},
   "source": [
    "Now, we convert those FASTA files into FASTQ files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779df81-64b9-4a62-88ec-d8a7019f0e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fastq_files = u.convert_directory(data, suffix=\".fna\",\n",
    "                                  convertor=u.convert_fasta_file_to_fastq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a162d-a25e-4615-80c3-1da2e1e8c75a",
   "metadata": {},
   "source": [
    "And then we compress these FASTA files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a85d9-5e6c-4200-8fb6-bd57587c14e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compressed_fq_files = u.convert_directory(data, suffix=\".fq\",\n",
    "                                          convertor=u.gzip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3139c2-e178-4853-9e91-d910c499dea1",
   "metadata": {},
   "source": [
    "Next, we upload the files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24828b8-287e-4bfe-b1cb-bb2f8b33a2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_uris = []\n",
    "for file in compressed_fq_files:\n",
    "    key = f\"{prefix}{file.name}\"\n",
    "    s3.upload_file(file, bucket_name, key)\n",
    "    s3_uri = f\"s3://{bucket_name}/{key}\"\n",
    "    print(s3_uri)\n",
    "    s3_uris.append(s3_uri)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d706b1-816e-4f2c-a496-2ebd5c6d450d",
   "metadata": {},
   "source": [
    "Next, we create a sequence store in HealthOmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2027da-1b7d-4b09-8d98-605a95cd5b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_store_resp = omics.create_sequence_store(\n",
    "    name=sequence_store_name,\n",
    "    description=\"GCA_921998355.2_A_J_v3\"\n",
    ")\n",
    "seq_store_id = seq_store_resp[\"id\"]\n",
    "print(f\"Sequence store ID: {seq_store_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2c752-3fbb-41cf-ba2b-002f4a435c2b",
   "metadata": {},
   "source": [
    "Next, we load our FASTQ files into this new sequence store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d8c8d-12ff-4bae-bfcf-68d7fdeac2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import_job_resp = omics.start_read_set_import_job(\n",
    "    sequenceStoreId=seq_store_id,\n",
    "    roleArn=import_job_role_arn,\n",
    "    sources=[\n",
    "        {\n",
    "            \"sourceFiles\": {\"source1\": s3_uri},\n",
    "            \"sourceFileType\": \"FASTQ\",\n",
    "            \"subjectId\": \"N/A\",\n",
    "            \"sampleId\": \"N/A\",\n",
    "        }\n",
    "        for s3_uri in s3_uris\n",
    "    ]\n",
    ")\n",
    "import_job_id = import_job_resp[\"id\"]\n",
    "print(f\"Import job ID: {import_job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d34a7-b1df-4fb5-9dda-5c630a34aba7",
   "metadata": {},
   "source": [
    "We now wait for these read sets to be imported into the sequence store. This typically takes about an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c044d-53c4-40a8-a0c1-2f6ac66d1b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "while True:\n",
    "    job_list_response = omics.list_read_set_import_jobs(maxResults=100,\n",
    "                                                        sequenceStoreId=seq_store_id)\n",
    "    import_jobs = [job for job in job_list_response[\"importJobs\"] if job[\"id\"] == import_job_id]\n",
    "    [status] = [job[\"status\"] for job in import_jobs] # filtered on job id, so should only be one\n",
    "    print(f\"Status of import job {import_job_id} is {status}\")\n",
    "    if status not in {\"SUBMITTED\", \"IN_PROGRESS\"}:\n",
    "        break\n",
    "    sleep(5*60)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b3e49-4a6e-45ae-994a-2587f0ca90f4",
   "metadata": {},
   "source": [
    "## Integration with the training notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bc750-97db-4448-8689-d814a48fa4da",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, check your AWS CLI version, it must be >= 2.15.20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa03b8b-992a-43bd-aaa3-a3e6e7fd3c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!/usr/local/bin/aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4684297-961d-47ec-9e21-1de9f428cff8",
   "metadata": {},
   "source": [
    "If your version of `aws-cli` is 1.X then go [here](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) to see how to upgrade to 2.X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8350229-a598-4f56-afac-07a9e285a7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!/usr/local/bin/aws omics get-sequence-store --id {seq_store_id} > /tmp/seq-store.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81b237-2680-449f-9262-26edfa52c43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_store_info = json.loads(Path(\"/tmp/seq-store.json\").read_text())\n",
    "s3AccessPoint = seq_store_info[\"s3Access\"][\"s3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d0234-8660-460c-888a-9f261db83da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Sequence store ID: {seq_store_id}\")\n",
    "print(f\"This sequence store's s3 access point: {s3AccessPoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26700d-b72c-4003-ba71-628a669ad215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
